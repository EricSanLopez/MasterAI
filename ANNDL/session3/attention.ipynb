{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i1KfYGFRRWP"
      },
      "source": [
        "## Artificial Neural Networks and Deep Learning  \n",
        "##Assignment 3.3 - Self-attention and Transformers\n",
        "\n",
        "Prof. Dr. Ir. Johan A. K. Suykens     \n",
        "\n",
        "In this file, we first understand the self-attention mechanism by implementing it both with ``NumPy`` and ``PyTorch``.\n",
        "Then, we implement a 6-layer Vision Transformer (ViT) and train it on the MNIST dataset.\n",
        "\n",
        "All training will be conducted on a single T4 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlTJbgaaRTct"
      },
      "outputs": [],
      "source": [
        "# Please first load your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qu6w5GLkRezN",
        "outputId": "0daf73db-927d-4cf6-fb14-838b783f2248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May  5 14:32:12 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Please go to Edit > Notebook settings > Hardware accelerator > choose \"T4 GPU\"\n",
        "# Now check if you have loaded the GPU successfully\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-sUz1A9SzVH"
      },
      "source": [
        "# Self-attention Mechanism\n",
        "Self-attention is the core mechanism in Transformer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6ol1XZtiPpk"
      },
      "source": [
        "## Self-attention with NumPy\n",
        "To have a better understanding of it, we first manually implement self-attention mechanism with ``numpy``. You can check the dimension of each variable during the matrix computation.\n",
        "\n",
        "Feel free to change the dimensions of each variable and see how the output dimension will change accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AgWIgp51RgC3",
        "outputId": "916d6b5e-2b62-4a5f-d7d9-74f962915cbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The attention outputs are\n",
            " [[-1.61863     2.7844908  -0.91642446 ...  2.18249428  2.47293919\n",
            "  -1.82993738]\n",
            " [-1.61863     2.7844908  -0.91642446 ...  2.18249428  2.47293919\n",
            "  -1.82993738]\n",
            " [-1.61863     2.7844908  -0.91642446 ...  2.18249428  2.47293919\n",
            "  -1.82993738]\n",
            " ...\n",
            " [-1.61863     2.7844908  -0.91642446 ...  2.18249428  2.47293919\n",
            "  -1.82993738]\n",
            " [-1.61863     2.7844908  -0.91642446 ...  2.18249428  2.47293919\n",
            "  -1.82993738]\n",
            " [-1.61863     2.7844908  -0.91642446 ...  2.18249428  2.47293919\n",
            "  -1.82993738]]\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from numpy.random import randn\n",
        "\n",
        "# I. Define the input data X\n",
        "# X consists out of 32 samples, each sample has dimensionality 256\n",
        "n = 32\n",
        "d = 256\n",
        "X = randn(n, d) # (32, 256)\n",
        "\n",
        "# II. Generate the projection weights\n",
        "Wq = randn(d, d) #(256, 256)\n",
        "Wk = randn(d, d)\n",
        "Wv = randn(d, d)\n",
        "\n",
        "# III. Project X to find its query, keys and values vectors\n",
        "Q = np.dot(X, Wq) # (32, 256)\n",
        "K = np.dot(X, Wk)\n",
        "V = np.dot(X, Wv)\n",
        "\n",
        "# IV. Compute the self-attention score, denoted by A\n",
        "# A = softmax(QK^T / \\sqrt{d})\n",
        "# Define the softmax function\n",
        "def softmax(z):\n",
        "    z = np.clip(z, 100, -100) # clip in case softmax explodes\n",
        "    tmp = np.exp(z)\n",
        "    res = np.exp(z) / np.sum(tmp, axis=1)\n",
        "    return res\n",
        "\n",
        "A = softmax(np.dot(Q, K.transpose())/math.sqrt(d)) #(32, 32)\n",
        "\n",
        "# V. Compute the self-attention output\n",
        "# outputs = A * V\n",
        "outputs = np.dot(A, V) #(32, 256)\n",
        "\n",
        "print(\"The attention outputs are\\n {}\".format(outputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iozM1k4khO0B"
      },
      "source": [
        "## Self-attention with PyTorch\n",
        "Now, we implement self-attention with ``PyTorch``, which is commonly used when building Transformers.\n",
        "\n",
        "Feel free to change the dimensions of each variable and see how the output dimension will change accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qng07v8xdaPj",
        "outputId": "f12d8171-1f84-4f08-dc43-fa977c0da800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape:torch.Size([32, 20, 128]) \n",
            " Q.shape:torch.Size([32, 20, 64]) \n",
            " K.shape:torch.Size([32, 20, 64]) \n",
            " V.shape:torch.Size([32, 20, 32])\n",
            "attention matrix:  torch.Size([32, 20, 20])\n",
            "attention outputs:  torch.Size([32, 20, 32])\n",
            "tensor([[[-0.2012,  0.0361, -0.2771,  ...,  0.0593,  0.1849, -0.2348],\n",
            "         [-0.1910,  0.0571, -0.2515,  ...,  0.0931,  0.1622, -0.2577],\n",
            "         [-0.0693,  0.0872, -0.2442,  ...,  0.0319,  0.2204, -0.2084],\n",
            "         ...,\n",
            "         [-0.1353,  0.0258, -0.2646,  ...,  0.0674,  0.1297, -0.2350],\n",
            "         [-0.1040,  0.1042, -0.3023,  ...,  0.0234,  0.0933, -0.3487],\n",
            "         [-0.1450,  0.0278, -0.2788,  ...,  0.0490,  0.1309, -0.1918]],\n",
            "\n",
            "        [[ 0.1055,  0.0957,  0.0789,  ..., -0.0527,  0.1576,  0.1550],\n",
            "         [ 0.1538,  0.0214, -0.0481,  ...,  0.0121,  0.0562,  0.0941],\n",
            "         [ 0.0642,  0.1360, -0.0200,  ..., -0.0777,  0.1175,  0.1415],\n",
            "         ...,\n",
            "         [ 0.0991,  0.0681, -0.0440,  ..., -0.0869,  0.0892,  0.1008],\n",
            "         [ 0.0012,  0.0357, -0.1250,  ..., -0.0616,  0.1268,  0.0826],\n",
            "         [ 0.1062,  0.0770, -0.0067,  ..., -0.0571,  0.0896,  0.1111]],\n",
            "\n",
            "        [[ 0.0383, -0.0458,  0.0172,  ..., -0.0244,  0.4817,  0.1963],\n",
            "         [ 0.0343,  0.0073,  0.0941,  ..., -0.0721,  0.3676,  0.1409],\n",
            "         [ 0.0123,  0.0868,  0.0738,  ...,  0.0485,  0.4572,  0.1352],\n",
            "         ...,\n",
            "         [-0.0009,  0.0461,  0.0710,  ...,  0.0585,  0.3796,  0.0566],\n",
            "         [ 0.0158, -0.0138,  0.0269,  ..., -0.0407,  0.2669,  0.0863],\n",
            "         [-0.0612,  0.0160,  0.0517,  ...,  0.1412,  0.2508,  0.1047]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.0674,  0.0218,  0.1889,  ..., -0.0764, -0.0223,  0.3919],\n",
            "         [ 0.1361, -0.0586,  0.0830,  ..., -0.0688, -0.0185,  0.4851],\n",
            "         [ 0.0010,  0.0221,  0.0300,  ..., -0.1103, -0.0723,  0.3787],\n",
            "         ...,\n",
            "         [ 0.0270,  0.0328,  0.0169,  ..., -0.1336, -0.0553,  0.3699],\n",
            "         [ 0.0488, -0.0499,  0.1144,  ..., -0.0725, -0.0334,  0.3023],\n",
            "         [ 0.0345,  0.0508,  0.0975,  ..., -0.1313, -0.0475,  0.3660]],\n",
            "\n",
            "        [[-0.1414,  0.2370,  0.2239,  ..., -0.0299,  0.1437,  0.1599],\n",
            "         [ 0.0049,  0.1657,  0.1612,  ...,  0.0555,  0.1139,  0.2350],\n",
            "         [-0.0620,  0.1322,  0.2849,  ...,  0.0393,  0.1802,  0.1199],\n",
            "         ...,\n",
            "         [-0.0237,  0.0953,  0.2937,  ...,  0.0500,  0.2755,  0.1241],\n",
            "         [-0.0702,  0.1973,  0.2971,  ...,  0.0388,  0.2209,  0.2644],\n",
            "         [-0.0284,  0.1042,  0.2113,  ..., -0.0361,  0.1803,  0.1198]],\n",
            "\n",
            "        [[-0.0573,  0.2435,  0.0236,  ..., -0.1587, -0.0326, -0.0057],\n",
            "         [-0.1136,  0.2125,  0.0591,  ..., -0.1812, -0.0280,  0.0383],\n",
            "         [ 0.0218,  0.2215,  0.0823,  ..., -0.2051, -0.0403,  0.1159],\n",
            "         ...,\n",
            "         [ 0.0025,  0.2247,  0.0184,  ..., -0.2338,  0.0615,  0.0497],\n",
            "         [-0.0934,  0.1767,  0.0130,  ..., -0.2534,  0.0584, -0.0385],\n",
            "         [-0.0323,  0.2646,  0.0571,  ..., -0.1811, -0.0568, -0.0089]]],\n",
            "       grad_fn=<BmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, dim_input, dim_q, dim_v):\n",
        "        '''\n",
        "        dim_input: the dimension of each sample\n",
        "        dim_q: dimension of Q matrix, should be equal to dim_k\n",
        "        dim_v: dimension of V matrix, also the  dimension of the attention output\n",
        "        '''\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        self.dim_input = dim_input\n",
        "        self.dim_q = dim_q\n",
        "        self.dim_k = dim_q\n",
        "        self.dim_v = dim_v\n",
        "\n",
        "        # Define the linear projection\n",
        "        self.linear_q = nn.Linear(self.dim_input, self.dim_q, bias=False)\n",
        "        self.linear_k = nn.Linear(self.dim_input, self.dim_k, bias=False)\n",
        "        self.linear_v = nn.Linear(self.dim_input, self.dim_v, bias=False)\n",
        "        self._norm_fact = 1 / math.sqrt(self.dim_k)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, n, dim_q = x.shape\n",
        "\n",
        "        q = self.linear_q(x) # (batchsize, seq_len, dim_q)\n",
        "        k = self.linear_k(x) # (batchsize, seq_len, dim_k)\n",
        "        v = self.linear_v(x) # (batchsize, seq_len, dim_v)\n",
        "        print(f'x.shape:{x.shape} \\n Q.shape:{q.shape} \\n K.shape:{k.shape} \\n V.shape:{v.shape}')\n",
        "\n",
        "        dist = torch.bmm(q, k.transpose(1,2)) * self._norm_fact\n",
        "        dist = torch.softmax(dist, dim=-1)\n",
        "        print('attention matrix: ', dist.shape)\n",
        "\n",
        "        outputs = torch.bmm(dist, v)\n",
        "        print('attention outputs: ', outputs.shape)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "batch_size = 32 # number of samples in a batch\n",
        "dim_input = 128 # dimension of each item in the sample sequence\n",
        "seq_len = 20 # sequence length for each sample\n",
        "x = torch.randn(batch_size, seq_len, dim_input)\n",
        "self_attention = SelfAttention(dim_input, dim_q = 64, dim_v = 32)\n",
        "\n",
        "attention = self_attention(x)\n",
        "\n",
        "print(attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZaAFL8MS2Ng"
      },
      "source": [
        "# Transformers\n",
        "In this section, we implement a 6-layer Vision Transformer (ViT) and trained it on the MNIST dataset.\n",
        "We consider the classification tasks.\n",
        "First, we load the MNIST dataset as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rZ-eIaeZjWjL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import datasets, utils\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "def get_mnist_loader(batch_size=100, shuffle=True):\n",
        "    \"\"\"\n",
        "\n",
        "    :return: train_loader, test_loader\n",
        "    \"\"\"\n",
        "    train_dataset = MNIST(root='../data',\n",
        "                          train=True,\n",
        "                          transform=torchvision.transforms.ToTensor(),\n",
        "                          download=True)\n",
        "    test_dataset = MNIST(root='../data',\n",
        "                         train=False,\n",
        "                         transform=torchvision.transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=shuffle)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=False)\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C06IoPIjePg",
        "outputId": "288d1cc6-bab9-4986-86d7-d2db43f885c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n"
          ]
        }
      ],
      "source": [
        "# This package is needed to build the transformer\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx9eZrMpmA2z"
      },
      "source": [
        "## Build ViT from scratch\n",
        "Recall that each Transformer block include 2 modules: the self-attention module, the feedforward module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Vr6d7IWfjpxY"
      },
      "outputs": [],
      "source": [
        "from einops import rearrange\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=8):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = dim ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
        "        self.to_out = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x, mask = None):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x)\n",
        "        q, k, v = rearrange(qkv, 'b n (qkv h d) -> qkv b h n d', qkv=3, h=h)\n",
        "\n",
        "        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\n",
        "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n",
        "            mask = mask[:, None, :] * mask[:, :, None]\n",
        "            dots.masked_fill_(~mask, float('-inf'))\n",
        "            del mask\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = torch.einsum('bhij,bhjd->bhid', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out =  self.to_out(out)\n",
        "        return out\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, mlp_dim):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                Residual(PreNorm(dim, Attention(dim, heads = heads))),\n",
        "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim)))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x, mask=mask)\n",
        "            x = ff(x)\n",
        "        return x\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels=3):\n",
        "        super().__init__()\n",
        "        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        patch_dim = channels * patch_size ** 2\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.transformer = Transformer(dim, depth, heads, mlp_dim)\n",
        "\n",
        "        self.to_cls_token = nn.Identity()\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.Linear(dim, mlp_dim),\n",
        "            nn.GELU(), # Gaussian Error Linear Units is another type of activation function\n",
        "            nn.Linear(mlp_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img, mask=None):\n",
        "        p = self.patch_size\n",
        "\n",
        "        x = rearrange(img, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=p, p2=p)\n",
        "        x = self.patch_to_embedding(x)\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(img.shape[0], -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.pos_embedding\n",
        "        x = self.transformer(x, mask)\n",
        "\n",
        "        x = self.to_cls_token(x[:, 0])\n",
        "        return self.mlp_head(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTawNC64mhBO"
      },
      "source": [
        "## Training and test function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rKJ4tjCjjycH"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def train_epoch(model, optimizer, data_loader, loss_history):\n",
        "    total_samples = len(data_loader.dataset)\n",
        "    model.train()\n",
        "\n",
        "    for i, (data, target) in enumerate(data_loader):\n",
        "        data = data.cuda()\n",
        "        target = target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = F.log_softmax(model(data), dim=1)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(total_samples) +\n",
        "                  ' (' + '{:3.0f}'.format(100 * i / len(data_loader)) + '%)]  Loss: ' +\n",
        "                  '{:6.4f}'.format(loss.item()))\n",
        "            loss_history.append(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vph2CrNxj6ZZ"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, loss_history):\n",
        "    model.eval()\n",
        "\n",
        "    total_samples = len(data_loader.dataset)\n",
        "    correct_samples = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    # We do not need to remember the gradients when testing\n",
        "    # This will help reduce memory\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "            output = F.log_softmax(model(data), dim=1)\n",
        "            loss = F.nll_loss(output, target, reduction='sum')\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct_samples += pred.eq(target).sum()\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    loss_history.append(avg_loss)\n",
        "    print('\\nAverage test loss: ' + '{:.4f}'.format(avg_loss) +\n",
        "          '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\n",
        "          '{:5}'.format(total_samples) + ' (' +\n",
        "          '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRYys50km0-E"
      },
      "source": [
        "## Let's start training!\n",
        "Here, you can change the ViT structure by changing the hyper-parametrs inside ``ViT`` function.\n",
        "The default settings are with 6 layers, 8 heads for the multi-head attention mechanism and embedding dimension of 64.\n",
        "You can also increase the number of epochs to obtain better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rVLJLLDuj7yQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# You can change the architecture here\n",
        "model = ViT(image_size=28, patch_size=7, num_classes=10, channels=1,\n",
        "            dim=64, depth=6, heads=8, mlp_dim=128)\n",
        "model = model.cuda()\n",
        "# We also print the network architecture\n",
        "model\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_loss_history, test_loss_history = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Vlt3tk-MkDB9",
        "outputId": "13b6e037-62fa-4e24-d531-e0cedc9f99c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 495kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.55MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.42MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3259\n",
            "[12800/60000 ( 21%)]  Loss: 1.0017\n",
            "[25600/60000 ( 43%)]  Loss: 0.3386\n",
            "[38400/60000 ( 64%)]  Loss: 0.2360\n",
            "[51200/60000 ( 85%)]  Loss: 0.1861\n",
            "\n",
            "Average test loss: 0.1779  Accuracy: 9427/10000 (94.27%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.0850\n",
            "[12800/60000 ( 21%)]  Loss: 0.1713\n",
            "[25600/60000 ( 43%)]  Loss: 0.0594\n",
            "[38400/60000 ( 64%)]  Loss: 0.1821\n",
            "[51200/60000 ( 85%)]  Loss: 0.1840\n",
            "\n",
            "Average test loss: 0.1370  Accuracy: 9566/10000 (95.66%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1887\n",
            "[12800/60000 ( 21%)]  Loss: 0.0165\n",
            "[25600/60000 ( 43%)]  Loss: 0.0711\n",
            "[38400/60000 ( 64%)]  Loss: 0.0727\n",
            "[51200/60000 ( 85%)]  Loss: 0.0744\n",
            "\n",
            "Average test loss: 0.0898  Accuracy: 9719/10000 (97.19%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0354\n",
            "[12800/60000 ( 21%)]  Loss: 0.0284\n",
            "[25600/60000 ( 43%)]  Loss: 0.0210\n",
            "[38400/60000 ( 64%)]  Loss: 0.0799\n",
            "[51200/60000 ( 85%)]  Loss: 0.0781\n",
            "\n",
            "Average test loss: 0.0839  Accuracy: 9761/10000 (97.61%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0890\n",
            "[12800/60000 ( 21%)]  Loss: 0.0442\n",
            "[25600/60000 ( 43%)]  Loss: 0.0334\n",
            "[38400/60000 ( 64%)]  Loss: 0.0455\n",
            "[51200/60000 ( 85%)]  Loss: 0.0171\n",
            "\n",
            "Average test loss: 0.0725  Accuracy: 9765/10000 (97.65%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0428\n",
            "[12800/60000 ( 21%)]  Loss: 0.0642\n",
            "[25600/60000 ( 43%)]  Loss: 0.0275\n",
            "[38400/60000 ( 64%)]  Loss: 0.0542\n",
            "[51200/60000 ( 85%)]  Loss: 0.0921\n",
            "\n",
            "Average test loss: 0.0941  Accuracy: 9734/10000 (97.34%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.1009\n",
            "[12800/60000 ( 21%)]  Loss: 0.0366\n",
            "[25600/60000 ( 43%)]  Loss: 0.0124\n",
            "[38400/60000 ( 64%)]  Loss: 0.0077\n",
            "[51200/60000 ( 85%)]  Loss: 0.0164\n",
            "\n",
            "Average test loss: 0.0856  Accuracy: 9736/10000 (97.36%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.1259\n",
            "[12800/60000 ( 21%)]  Loss: 0.0145\n",
            "[25600/60000 ( 43%)]  Loss: 0.0195\n",
            "[38400/60000 ( 64%)]  Loss: 0.1008\n",
            "[51200/60000 ( 85%)]  Loss: 0.0911\n",
            "\n",
            "Average test loss: 0.0750  Accuracy: 9761/10000 (97.61%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0345\n",
            "[12800/60000 ( 21%)]  Loss: 0.0147\n",
            "[25600/60000 ( 43%)]  Loss: 0.0218\n",
            "[38400/60000 ( 64%)]  Loss: 0.0189\n",
            "[51200/60000 ( 85%)]  Loss: 0.0103\n",
            "\n",
            "Average test loss: 0.0592  Accuracy: 9830/10000 (98.30%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0109\n",
            "[12800/60000 ( 21%)]  Loss: 0.0111\n",
            "[25600/60000 ( 43%)]  Loss: 0.0279\n",
            "[38400/60000 ( 64%)]  Loss: 0.0072\n",
            "[51200/60000 ( 85%)]  Loss: 0.0121\n",
            "\n",
            "Average test loss: 0.0711  Accuracy: 9778/10000 (97.78%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0235\n",
            "[12800/60000 ( 21%)]  Loss: 0.0147\n",
            "[25600/60000 ( 43%)]  Loss: 0.0164\n",
            "[38400/60000 ( 64%)]  Loss: 0.0477\n",
            "[51200/60000 ( 85%)]  Loss: 0.0048\n",
            "\n",
            "Average test loss: 0.0655  Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0067\n",
            "[12800/60000 ( 21%)]  Loss: 0.0217\n",
            "[25600/60000 ( 43%)]  Loss: 0.0214\n",
            "[38400/60000 ( 64%)]  Loss: 0.0102\n",
            "[51200/60000 ( 85%)]  Loss: 0.0016\n",
            "\n",
            "Average test loss: 0.0671  Accuracy: 9818/10000 (98.18%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0079\n",
            "[12800/60000 ( 21%)]  Loss: 0.0017\n",
            "[25600/60000 ( 43%)]  Loss: 0.0275\n",
            "[38400/60000 ( 64%)]  Loss: 0.0164\n",
            "[51200/60000 ( 85%)]  Loss: 0.0116\n",
            "\n",
            "Average test loss: 0.0587  Accuracy: 9846/10000 (98.46%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0096\n",
            "[12800/60000 ( 21%)]  Loss: 0.0500\n",
            "[25600/60000 ( 43%)]  Loss: 0.0127\n",
            "[38400/60000 ( 64%)]  Loss: 0.0212\n",
            "[51200/60000 ( 85%)]  Loss: 0.0181\n",
            "\n",
            "Average test loss: 0.0652  Accuracy: 9830/10000 (98.30%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0063\n",
            "[12800/60000 ( 21%)]  Loss: 0.0269\n",
            "[25600/60000 ( 43%)]  Loss: 0.0032\n",
            "[38400/60000 ( 64%)]  Loss: 0.0010\n",
            "[51200/60000 ( 85%)]  Loss: 0.0121\n",
            "\n",
            "Average test loss: 0.0613  Accuracy: 9849/10000 (98.49%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0387\n",
            "[12800/60000 ( 21%)]  Loss: 0.0150\n",
            "[25600/60000 ( 43%)]  Loss: 0.0069\n",
            "[38400/60000 ( 64%)]  Loss: 0.0154\n",
            "[51200/60000 ( 85%)]  Loss: 0.0064\n",
            "\n",
            "Average test loss: 0.0665  Accuracy: 9839/10000 (98.39%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0018\n",
            "[12800/60000 ( 21%)]  Loss: 0.0031\n",
            "[25600/60000 ( 43%)]  Loss: 0.0084\n",
            "[38400/60000 ( 64%)]  Loss: 0.0029\n",
            "[51200/60000 ( 85%)]  Loss: 0.0378\n",
            "\n",
            "Average test loss: 0.0790  Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0170\n",
            "[12800/60000 ( 21%)]  Loss: 0.0034\n",
            "[25600/60000 ( 43%)]  Loss: 0.0022\n",
            "[38400/60000 ( 64%)]  Loss: 0.0036\n",
            "[51200/60000 ( 85%)]  Loss: 0.0050\n",
            "\n",
            "Average test loss: 0.0639  Accuracy: 9848/10000 (98.48%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0019\n",
            "[12800/60000 ( 21%)]  Loss: 0.0016\n",
            "[25600/60000 ( 43%)]  Loss: 0.0015\n",
            "[38400/60000 ( 64%)]  Loss: 0.0405\n",
            "[51200/60000 ( 85%)]  Loss: 0.0019\n",
            "\n",
            "Average test loss: 0.0661  Accuracy: 9853/10000 (98.53%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0028\n",
            "[12800/60000 ( 21%)]  Loss: 0.0049\n",
            "[25600/60000 ( 43%)]  Loss: 0.0008\n",
            "[38400/60000 ( 64%)]  Loss: 0.0010\n",
            "[51200/60000 ( 85%)]  Loss: 0.0034\n",
            "\n",
            "Average test loss: 0.0700  Accuracy: 9843/10000 (98.43%)\n",
            "\n",
            "Execution time: 277.57 seconds\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "train_loader, test_loader = get_mnist_loader(batch_size=128, shuffle=True)\n",
        "\n",
        "# Gradually reduce the learning rate while training\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "    print('Epoch:', epoch,'LR:', scheduler.get_last_lr())\n",
        "    train_epoch(model, optimizer, train_loader, train_loss_history)\n",
        "    evaluate(model, test_loader, test_loss_history)\n",
        "    scheduler.step()\n",
        "\n",
        "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XicoRf8_nUTK",
        "outputId": "0ba1fcce-f21a-4382-e1ec-70f1ad7ae7fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[25600/60000 ( 43%)]  Loss: 0.0170\n",
            "[38400/60000 ( 64%)]  Loss: 0.0510\n",
            "[51200/60000 ( 85%)]  Loss: 0.0190\n",
            "\n",
            "Average test loss: 0.0707  Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0061\n",
            "[12800/60000 ( 21%)]  Loss: 0.0398\n",
            "[25600/60000 ( 43%)]  Loss: 0.0092\n",
            "[38400/60000 ( 64%)]  Loss: 0.0062\n",
            "[51200/60000 ( 85%)]  Loss: 0.0246\n",
            "\n",
            "Average test loss: 0.0814  Accuracy: 9787/10000 (97.87%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0399\n",
            "[12800/60000 ( 21%)]  Loss: 0.0314\n",
            "[25600/60000 ( 43%)]  Loss: 0.0571\n",
            "[38400/60000 ( 64%)]  Loss: 0.0017\n",
            "[51200/60000 ( 85%)]  Loss: 0.0110\n",
            "\n",
            "Average test loss: 0.0688  Accuracy: 9810/10000 (98.10%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0386\n",
            "[12800/60000 ( 21%)]  Loss: 0.0129\n",
            "[25600/60000 ( 43%)]  Loss: 0.0364\n",
            "[38400/60000 ( 64%)]  Loss: 0.0049\n",
            "[51200/60000 ( 85%)]  Loss: 0.0141\n",
            "\n",
            "Average test loss: 0.0784  Accuracy: 9794/10000 (97.94%)\n",
            "\n",
            "Execution time: 380.16 seconds\n",
            "dim 32 depth 12 heads 8 mlp_dim 128\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3421\n",
            "[12800/60000 ( 21%)]  Loss: 1.2827\n",
            "[25600/60000 ( 43%)]  Loss: 0.5995\n",
            "[38400/60000 ( 64%)]  Loss: 0.6331\n",
            "[51200/60000 ( 85%)]  Loss: 0.3544\n",
            "\n",
            "Average test loss: 0.3260  Accuracy: 8968/10000 (89.68%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.4087\n",
            "[12800/60000 ( 21%)]  Loss: 0.2736\n",
            "[25600/60000 ( 43%)]  Loss: 0.3327\n",
            "[38400/60000 ( 64%)]  Loss: 0.3568\n",
            "[51200/60000 ( 85%)]  Loss: 0.2094\n",
            "\n",
            "Average test loss: 0.2009  Accuracy: 9373/10000 (93.73%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.3074\n",
            "[12800/60000 ( 21%)]  Loss: 0.1454\n",
            "[25600/60000 ( 43%)]  Loss: 0.1410\n",
            "[38400/60000 ( 64%)]  Loss: 0.2022\n",
            "[51200/60000 ( 85%)]  Loss: 0.1059\n",
            "\n",
            "Average test loss: 0.1732  Accuracy: 9449/10000 (94.49%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.2463\n",
            "[12800/60000 ( 21%)]  Loss: 0.1198\n",
            "[25600/60000 ( 43%)]  Loss: 0.1074\n",
            "[38400/60000 ( 64%)]  Loss: 0.1404\n",
            "[51200/60000 ( 85%)]  Loss: 0.0976\n",
            "\n",
            "Average test loss: 0.1188  Accuracy: 9634/10000 (96.34%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.1007\n",
            "[12800/60000 ( 21%)]  Loss: 0.0641\n",
            "[25600/60000 ( 43%)]  Loss: 0.1127\n",
            "[38400/60000 ( 64%)]  Loss: 0.2511\n",
            "[51200/60000 ( 85%)]  Loss: 0.1268\n",
            "\n",
            "Average test loss: 0.1422  Accuracy: 9557/10000 (95.57%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0900\n",
            "[12800/60000 ( 21%)]  Loss: 0.0957\n",
            "[25600/60000 ( 43%)]  Loss: 0.1259\n",
            "[38400/60000 ( 64%)]  Loss: 0.1190\n",
            "[51200/60000 ( 85%)]  Loss: 0.0500\n",
            "\n",
            "Average test loss: 0.1080  Accuracy: 9661/10000 (96.61%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0477\n",
            "[12800/60000 ( 21%)]  Loss: 0.1236\n",
            "[25600/60000 ( 43%)]  Loss: 0.0799\n",
            "[38400/60000 ( 64%)]  Loss: 0.0257\n",
            "[51200/60000 ( 85%)]  Loss: 0.0970\n",
            "\n",
            "Average test loss: 0.0935  Accuracy: 9704/10000 (97.04%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0708\n",
            "[12800/60000 ( 21%)]  Loss: 0.1104\n",
            "[25600/60000 ( 43%)]  Loss: 0.0282\n",
            "[38400/60000 ( 64%)]  Loss: 0.0724\n",
            "[51200/60000 ( 85%)]  Loss: 0.0520\n",
            "\n",
            "Average test loss: 0.0779  Accuracy: 9757/10000 (97.57%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0252\n",
            "[12800/60000 ( 21%)]  Loss: 0.0417\n",
            "[25600/60000 ( 43%)]  Loss: 0.0250\n",
            "[38400/60000 ( 64%)]  Loss: 0.0369\n",
            "[51200/60000 ( 85%)]  Loss: 0.0680\n",
            "\n",
            "Average test loss: 0.0920  Accuracy: 9697/10000 (96.97%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0711\n",
            "[12800/60000 ( 21%)]  Loss: 0.0351\n",
            "[25600/60000 ( 43%)]  Loss: 0.1018\n",
            "[38400/60000 ( 64%)]  Loss: 0.0366\n",
            "[51200/60000 ( 85%)]  Loss: 0.0456\n",
            "\n",
            "Average test loss: 0.0748  Accuracy: 9766/10000 (97.66%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0721\n",
            "[12800/60000 ( 21%)]  Loss: 0.0204\n",
            "[25600/60000 ( 43%)]  Loss: 0.0924\n",
            "[38400/60000 ( 64%)]  Loss: 0.0411\n",
            "[51200/60000 ( 85%)]  Loss: 0.0782\n",
            "\n",
            "Average test loss: 0.0839  Accuracy: 9735/10000 (97.35%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0446\n",
            "[12800/60000 ( 21%)]  Loss: 0.0333\n",
            "[25600/60000 ( 43%)]  Loss: 0.0223\n",
            "[38400/60000 ( 64%)]  Loss: 0.0194\n",
            "[51200/60000 ( 85%)]  Loss: 0.0553\n",
            "\n",
            "Average test loss: 0.0830  Accuracy: 9731/10000 (97.31%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0515\n",
            "[12800/60000 ( 21%)]  Loss: 0.0142\n",
            "[25600/60000 ( 43%)]  Loss: 0.0412\n",
            "[38400/60000 ( 64%)]  Loss: 0.0472\n",
            "[51200/60000 ( 85%)]  Loss: 0.0115\n",
            "\n",
            "Average test loss: 0.0798  Accuracy: 9756/10000 (97.56%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0193\n",
            "[12800/60000 ( 21%)]  Loss: 0.0392\n",
            "[25600/60000 ( 43%)]  Loss: 0.0370\n",
            "[38400/60000 ( 64%)]  Loss: 0.0693\n",
            "[51200/60000 ( 85%)]  Loss: 0.0729\n",
            "\n",
            "Average test loss: 0.0711  Accuracy: 9783/10000 (97.83%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0928\n",
            "[12800/60000 ( 21%)]  Loss: 0.0472\n",
            "[25600/60000 ( 43%)]  Loss: 0.0184\n",
            "[38400/60000 ( 64%)]  Loss: 0.0219\n",
            "[51200/60000 ( 85%)]  Loss: 0.0294\n",
            "\n",
            "Average test loss: 0.0664  Accuracy: 9810/10000 (98.10%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0177\n",
            "[12800/60000 ( 21%)]  Loss: 0.0025\n",
            "[25600/60000 ( 43%)]  Loss: 0.0209\n",
            "[38400/60000 ( 64%)]  Loss: 0.0042\n",
            "[51200/60000 ( 85%)]  Loss: 0.0203\n",
            "\n",
            "Average test loss: 0.0711  Accuracy: 9781/10000 (97.81%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0201\n",
            "[12800/60000 ( 21%)]  Loss: 0.0502\n",
            "[25600/60000 ( 43%)]  Loss: 0.0051\n",
            "[38400/60000 ( 64%)]  Loss: 0.0052\n",
            "[51200/60000 ( 85%)]  Loss: 0.0318\n",
            "\n",
            "Average test loss: 0.0747  Accuracy: 9790/10000 (97.90%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0114\n",
            "[12800/60000 ( 21%)]  Loss: 0.0065\n",
            "[25600/60000 ( 43%)]  Loss: 0.0060\n",
            "[38400/60000 ( 64%)]  Loss: 0.0078\n",
            "[51200/60000 ( 85%)]  Loss: 0.0254\n",
            "\n",
            "Average test loss: 0.0659  Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0167\n",
            "[12800/60000 ( 21%)]  Loss: 0.0027\n",
            "[25600/60000 ( 43%)]  Loss: 0.0136\n",
            "[38400/60000 ( 64%)]  Loss: 0.0159\n",
            "[51200/60000 ( 85%)]  Loss: 0.0166\n",
            "\n",
            "Average test loss: 0.0660  Accuracy: 9819/10000 (98.19%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0234\n",
            "[12800/60000 ( 21%)]  Loss: 0.0043\n",
            "[25600/60000 ( 43%)]  Loss: 0.0016\n",
            "[38400/60000 ( 64%)]  Loss: 0.0287\n",
            "[51200/60000 ( 85%)]  Loss: 0.0470\n",
            "\n",
            "Average test loss: 0.0752  Accuracy: 9812/10000 (98.12%)\n",
            "\n",
            "Execution time: 379.18 seconds\n",
            "dim 32 depth 12 heads 8 mlp_dim 256\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3370\n",
            "[12800/60000 ( 21%)]  Loss: 1.3722\n",
            "[25600/60000 ( 43%)]  Loss: 0.9972\n",
            "[38400/60000 ( 64%)]  Loss: 0.7265\n",
            "[51200/60000 ( 85%)]  Loss: 0.5728\n",
            "\n",
            "Average test loss: 0.4030  Accuracy: 8786/10000 (87.86%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.3724\n",
            "[12800/60000 ( 21%)]  Loss: 0.5988\n",
            "[25600/60000 ( 43%)]  Loss: 0.2954\n",
            "[38400/60000 ( 64%)]  Loss: 0.2393\n",
            "[51200/60000 ( 85%)]  Loss: 0.1870\n",
            "\n",
            "Average test loss: 0.2626  Accuracy: 9169/10000 (91.69%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1955\n",
            "[12800/60000 ( 21%)]  Loss: 0.0857\n",
            "[25600/60000 ( 43%)]  Loss: 0.1275\n",
            "[38400/60000 ( 64%)]  Loss: 0.0450\n",
            "[51200/60000 ( 85%)]  Loss: 0.1010\n",
            "\n",
            "Average test loss: 0.1781  Accuracy: 9433/10000 (94.33%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1952\n",
            "[12800/60000 ( 21%)]  Loss: 0.2170\n",
            "[25600/60000 ( 43%)]  Loss: 0.0770\n",
            "[38400/60000 ( 64%)]  Loss: 0.0743\n",
            "[51200/60000 ( 85%)]  Loss: 0.0487\n",
            "\n",
            "Average test loss: 0.1203  Accuracy: 9609/10000 (96.09%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0862\n",
            "[12800/60000 ( 21%)]  Loss: 0.1115\n",
            "[25600/60000 ( 43%)]  Loss: 0.0860\n",
            "[38400/60000 ( 64%)]  Loss: 0.0778\n",
            "[51200/60000 ( 85%)]  Loss: 0.0391\n",
            "\n",
            "Average test loss: 0.1039  Accuracy: 9659/10000 (96.59%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.1196\n",
            "[12800/60000 ( 21%)]  Loss: 0.0948\n",
            "[25600/60000 ( 43%)]  Loss: 0.1224\n",
            "[38400/60000 ( 64%)]  Loss: 0.0835\n",
            "[51200/60000 ( 85%)]  Loss: 0.0538\n",
            "\n",
            "Average test loss: 0.1104  Accuracy: 9676/10000 (96.76%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.1555\n",
            "[12800/60000 ( 21%)]  Loss: 0.0713\n",
            "[25600/60000 ( 43%)]  Loss: 0.0534\n",
            "[38400/60000 ( 64%)]  Loss: 0.1463\n",
            "[51200/60000 ( 85%)]  Loss: 0.0596\n",
            "\n",
            "Average test loss: 0.1018  Accuracy: 9696/10000 (96.96%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.1485\n",
            "[12800/60000 ( 21%)]  Loss: 0.1104\n",
            "[25600/60000 ( 43%)]  Loss: 0.1034\n",
            "[38400/60000 ( 64%)]  Loss: 0.0860\n",
            "[51200/60000 ( 85%)]  Loss: 0.0268\n",
            "\n",
            "Average test loss: 0.1119  Accuracy: 9659/10000 (96.59%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0606\n",
            "[12800/60000 ( 21%)]  Loss: 0.0513\n",
            "[25600/60000 ( 43%)]  Loss: 0.0432\n",
            "[38400/60000 ( 64%)]  Loss: 0.0359\n",
            "[51200/60000 ( 85%)]  Loss: 0.0769\n",
            "\n",
            "Average test loss: 0.0778  Accuracy: 9758/10000 (97.58%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0280\n",
            "[12800/60000 ( 21%)]  Loss: 0.0384\n",
            "[25600/60000 ( 43%)]  Loss: 0.0826\n",
            "[38400/60000 ( 64%)]  Loss: 0.1095\n",
            "[51200/60000 ( 85%)]  Loss: 0.0615\n",
            "\n",
            "Average test loss: 0.0723  Accuracy: 9773/10000 (97.73%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0446\n",
            "[12800/60000 ( 21%)]  Loss: 0.0383\n",
            "[25600/60000 ( 43%)]  Loss: 0.1132\n",
            "[38400/60000 ( 64%)]  Loss: 0.0449\n",
            "[51200/60000 ( 85%)]  Loss: 0.0866\n",
            "\n",
            "Average test loss: 0.0785  Accuracy: 9772/10000 (97.72%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0585\n",
            "[12800/60000 ( 21%)]  Loss: 0.0369\n",
            "[25600/60000 ( 43%)]  Loss: 0.0234\n",
            "[38400/60000 ( 64%)]  Loss: 0.0331\n",
            "[51200/60000 ( 85%)]  Loss: 0.0319\n",
            "\n",
            "Average test loss: 0.0956  Accuracy: 9725/10000 (97.25%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0850\n",
            "[12800/60000 ( 21%)]  Loss: 0.0254\n",
            "[25600/60000 ( 43%)]  Loss: 0.0145\n",
            "[38400/60000 ( 64%)]  Loss: 0.0203\n",
            "[51200/60000 ( 85%)]  Loss: 0.0462\n",
            "\n",
            "Average test loss: 0.0698  Accuracy: 9787/10000 (97.87%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0615\n",
            "[12800/60000 ( 21%)]  Loss: 0.0102\n",
            "[25600/60000 ( 43%)]  Loss: 0.0068\n",
            "[38400/60000 ( 64%)]  Loss: 0.0135\n",
            "[51200/60000 ( 85%)]  Loss: 0.0495\n",
            "\n",
            "Average test loss: 0.0735  Accuracy: 9777/10000 (97.77%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0931\n",
            "[12800/60000 ( 21%)]  Loss: 0.0799\n",
            "[25600/60000 ( 43%)]  Loss: 0.0446\n",
            "[38400/60000 ( 64%)]  Loss: 0.0364\n",
            "[51200/60000 ( 85%)]  Loss: 0.0239\n",
            "\n",
            "Average test loss: 0.0722  Accuracy: 9774/10000 (97.74%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.1194\n",
            "[12800/60000 ( 21%)]  Loss: 0.0182\n",
            "[25600/60000 ( 43%)]  Loss: 0.0323\n",
            "[38400/60000 ( 64%)]  Loss: 0.0084\n",
            "[51200/60000 ( 85%)]  Loss: 0.0156\n",
            "\n",
            "Average test loss: 0.0673  Accuracy: 9822/10000 (98.22%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0132\n",
            "[12800/60000 ( 21%)]  Loss: 0.0195\n",
            "[25600/60000 ( 43%)]  Loss: 0.0411\n",
            "[38400/60000 ( 64%)]  Loss: 0.0094\n",
            "[51200/60000 ( 85%)]  Loss: 0.0040\n",
            "\n",
            "Average test loss: 0.0982  Accuracy: 9728/10000 (97.28%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0048\n",
            "[12800/60000 ( 21%)]  Loss: 0.0161\n",
            "[25600/60000 ( 43%)]  Loss: 0.0679\n",
            "[38400/60000 ( 64%)]  Loss: 0.0060\n",
            "[51200/60000 ( 85%)]  Loss: 0.0290\n",
            "\n",
            "Average test loss: 0.0831  Accuracy: 9768/10000 (97.68%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0191\n",
            "[12800/60000 ( 21%)]  Loss: 0.0044\n",
            "[25600/60000 ( 43%)]  Loss: 0.0010\n",
            "[38400/60000 ( 64%)]  Loss: 0.0303\n",
            "[51200/60000 ( 85%)]  Loss: 0.0294\n",
            "\n",
            "Average test loss: 0.0649  Accuracy: 9826/10000 (98.26%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0116\n",
            "[12800/60000 ( 21%)]  Loss: 0.0411\n",
            "[25600/60000 ( 43%)]  Loss: 0.0023\n",
            "[38400/60000 ( 64%)]  Loss: 0.0254\n",
            "[51200/60000 ( 85%)]  Loss: 0.0164\n",
            "\n",
            "Average test loss: 0.0763  Accuracy: 9826/10000 (98.26%)\n",
            "\n",
            "Execution time: 383.05 seconds\n",
            "dim 32 depth 12 heads 8 mlp_dim 512\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3111\n",
            "[12800/60000 ( 21%)]  Loss: 1.3658\n",
            "[25600/60000 ( 43%)]  Loss: 0.8162\n",
            "[38400/60000 ( 64%)]  Loss: 0.6576\n",
            "[51200/60000 ( 85%)]  Loss: 0.5253\n",
            "\n",
            "Average test loss: 0.4245  Accuracy: 8569/10000 (85.69%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.3555\n",
            "[12800/60000 ( 21%)]  Loss: 0.1707\n",
            "[25600/60000 ( 43%)]  Loss: 0.2950\n",
            "[38400/60000 ( 64%)]  Loss: 0.2565\n",
            "[51200/60000 ( 85%)]  Loss: 0.2800\n",
            "\n",
            "Average test loss: 0.2048  Accuracy: 9361/10000 (93.61%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.2835\n",
            "[12800/60000 ( 21%)]  Loss: 0.1455\n",
            "[25600/60000 ( 43%)]  Loss: 0.2120\n",
            "[38400/60000 ( 64%)]  Loss: 0.1666\n",
            "[51200/60000 ( 85%)]  Loss: 0.1677\n",
            "\n",
            "Average test loss: 0.2030  Accuracy: 9382/10000 (93.82%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1865\n",
            "[12800/60000 ( 21%)]  Loss: 0.2157\n",
            "[25600/60000 ( 43%)]  Loss: 0.2036\n",
            "[38400/60000 ( 64%)]  Loss: 0.1297\n",
            "[51200/60000 ( 85%)]  Loss: 0.1025\n",
            "\n",
            "Average test loss: 0.1480  Accuracy: 9547/10000 (95.47%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.1297\n",
            "[12800/60000 ( 21%)]  Loss: 0.1242\n",
            "[25600/60000 ( 43%)]  Loss: 0.1944\n",
            "[38400/60000 ( 64%)]  Loss: 0.1222\n",
            "[51200/60000 ( 85%)]  Loss: 0.0833\n",
            "\n",
            "Average test loss: 0.1337  Accuracy: 9571/10000 (95.71%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.1181\n",
            "[12800/60000 ( 21%)]  Loss: 0.1159\n",
            "[25600/60000 ( 43%)]  Loss: 0.0979\n",
            "[38400/60000 ( 64%)]  Loss: 0.0714\n",
            "[51200/60000 ( 85%)]  Loss: 0.1302\n",
            "\n",
            "Average test loss: 0.1079  Accuracy: 9654/10000 (96.54%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0195\n",
            "[12800/60000 ( 21%)]  Loss: 0.0454\n",
            "[25600/60000 ( 43%)]  Loss: 0.0898\n",
            "[38400/60000 ( 64%)]  Loss: 0.0628\n",
            "[51200/60000 ( 85%)]  Loss: 0.0356\n",
            "\n",
            "Average test loss: 0.1145  Accuracy: 9649/10000 (96.49%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0522\n",
            "[12800/60000 ( 21%)]  Loss: 0.0713\n",
            "[25600/60000 ( 43%)]  Loss: 0.0673\n",
            "[38400/60000 ( 64%)]  Loss: 0.0722\n",
            "[51200/60000 ( 85%)]  Loss: 0.0798\n",
            "\n",
            "Average test loss: 0.0870  Accuracy: 9729/10000 (97.29%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0467\n",
            "[12800/60000 ( 21%)]  Loss: 0.0660\n",
            "[25600/60000 ( 43%)]  Loss: 0.0908\n",
            "[38400/60000 ( 64%)]  Loss: 0.0507\n",
            "[51200/60000 ( 85%)]  Loss: 0.1278\n",
            "\n",
            "Average test loss: 0.0737  Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0379\n",
            "[12800/60000 ( 21%)]  Loss: 0.0299\n",
            "[25600/60000 ( 43%)]  Loss: 0.0853\n",
            "[38400/60000 ( 64%)]  Loss: 0.0378\n",
            "[51200/60000 ( 85%)]  Loss: 0.0369\n",
            "\n",
            "Average test loss: 0.0950  Accuracy: 9734/10000 (97.34%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0749\n",
            "[12800/60000 ( 21%)]  Loss: 0.0711\n",
            "[25600/60000 ( 43%)]  Loss: 0.0380\n",
            "[38400/60000 ( 64%)]  Loss: 0.0218\n",
            "[51200/60000 ( 85%)]  Loss: 0.0153\n",
            "\n",
            "Average test loss: 0.0710  Accuracy: 9780/10000 (97.80%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0612\n",
            "[12800/60000 ( 21%)]  Loss: 0.0201\n",
            "[25600/60000 ( 43%)]  Loss: 0.1251\n",
            "[38400/60000 ( 64%)]  Loss: 0.0071\n",
            "[51200/60000 ( 85%)]  Loss: 0.0247\n",
            "\n",
            "Average test loss: 0.0762  Accuracy: 9786/10000 (97.86%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0496\n",
            "[12800/60000 ( 21%)]  Loss: 0.0397\n",
            "[25600/60000 ( 43%)]  Loss: 0.0545\n",
            "[38400/60000 ( 64%)]  Loss: 0.0190\n",
            "[51200/60000 ( 85%)]  Loss: 0.0135\n",
            "\n",
            "Average test loss: 0.0849  Accuracy: 9754/10000 (97.54%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.1749\n",
            "[12800/60000 ( 21%)]  Loss: 0.0430\n",
            "[25600/60000 ( 43%)]  Loss: 0.0362\n",
            "[38400/60000 ( 64%)]  Loss: 0.0175\n",
            "[51200/60000 ( 85%)]  Loss: 0.0459\n",
            "\n",
            "Average test loss: 0.0733  Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0251\n",
            "[12800/60000 ( 21%)]  Loss: 0.0265\n",
            "[25600/60000 ( 43%)]  Loss: 0.0044\n",
            "[38400/60000 ( 64%)]  Loss: 0.0152\n",
            "[51200/60000 ( 85%)]  Loss: 0.0316\n",
            "\n",
            "Average test loss: 0.0895  Accuracy: 9761/10000 (97.61%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0707\n",
            "[12800/60000 ( 21%)]  Loss: 0.0540\n",
            "[25600/60000 ( 43%)]  Loss: 0.0173\n",
            "[38400/60000 ( 64%)]  Loss: 0.0099\n",
            "[51200/60000 ( 85%)]  Loss: 0.0103\n",
            "\n",
            "Average test loss: 0.0747  Accuracy: 9806/10000 (98.06%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0063\n",
            "[12800/60000 ( 21%)]  Loss: 0.0047\n",
            "[25600/60000 ( 43%)]  Loss: 0.0074\n",
            "[38400/60000 ( 64%)]  Loss: 0.0076\n",
            "[51200/60000 ( 85%)]  Loss: 0.0760\n",
            "\n",
            "Average test loss: 0.0759  Accuracy: 9788/10000 (97.88%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0286\n",
            "[12800/60000 ( 21%)]  Loss: 0.0014\n",
            "[25600/60000 ( 43%)]  Loss: 0.0582\n",
            "[38400/60000 ( 64%)]  Loss: 0.0040\n",
            "[51200/60000 ( 85%)]  Loss: 0.0178\n",
            "\n",
            "Average test loss: 0.0676  Accuracy: 9826/10000 (98.26%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0239\n",
            "[12800/60000 ( 21%)]  Loss: 0.0060\n",
            "[25600/60000 ( 43%)]  Loss: 0.0338\n",
            "[38400/60000 ( 64%)]  Loss: 0.0347\n",
            "[51200/60000 ( 85%)]  Loss: 0.0055\n",
            "\n",
            "Average test loss: 0.0717  Accuracy: 9820/10000 (98.20%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0018\n",
            "[12800/60000 ( 21%)]  Loss: 0.0093\n",
            "[25600/60000 ( 43%)]  Loss: 0.0110\n",
            "[38400/60000 ( 64%)]  Loss: 0.0065\n",
            "[51200/60000 ( 85%)]  Loss: 0.1015\n",
            "\n",
            "Average test loss: 0.0818  Accuracy: 9794/10000 (97.94%)\n",
            "\n",
            "Execution time: 385.28 seconds\n",
            "dim 32 depth 12 heads 16 mlp_dim 128\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3470\n",
            "[12800/60000 ( 21%)]  Loss: 1.4282\n",
            "[25600/60000 ( 43%)]  Loss: 0.9001\n",
            "[38400/60000 ( 64%)]  Loss: 0.6048\n",
            "[51200/60000 ( 85%)]  Loss: 0.5868\n",
            "\n",
            "Average test loss: 0.5144  Accuracy: 8330/10000 (83.30%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.5255\n",
            "[12800/60000 ( 21%)]  Loss: 0.4516\n",
            "[25600/60000 ( 43%)]  Loss: 0.4866\n",
            "[38400/60000 ( 64%)]  Loss: 0.1921\n",
            "[51200/60000 ( 85%)]  Loss: 0.3471\n",
            "\n",
            "Average test loss: 0.2140  Accuracy: 9360/10000 (93.60%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.2175\n",
            "[12800/60000 ( 21%)]  Loss: 0.1926\n",
            "[25600/60000 ( 43%)]  Loss: 0.3702\n",
            "[38400/60000 ( 64%)]  Loss: 0.1930\n",
            "[51200/60000 ( 85%)]  Loss: 0.1951\n",
            "\n",
            "Average test loss: 0.2072  Accuracy: 9366/10000 (93.66%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.2103\n",
            "[12800/60000 ( 21%)]  Loss: 0.1418\n",
            "[25600/60000 ( 43%)]  Loss: 0.1520\n",
            "[38400/60000 ( 64%)]  Loss: 0.2880\n",
            "[51200/60000 ( 85%)]  Loss: 0.1596\n",
            "\n",
            "Average test loss: 0.1701  Accuracy: 9465/10000 (94.65%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.1915\n",
            "[12800/60000 ( 21%)]  Loss: 0.1344\n",
            "[25600/60000 ( 43%)]  Loss: 0.1577\n",
            "[38400/60000 ( 64%)]  Loss: 0.1213\n",
            "[51200/60000 ( 85%)]  Loss: 0.2262\n",
            "\n",
            "Average test loss: 0.1283  Accuracy: 9582/10000 (95.82%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.1159\n",
            "[12800/60000 ( 21%)]  Loss: 0.1169\n",
            "[25600/60000 ( 43%)]  Loss: 0.0569\n",
            "[38400/60000 ( 64%)]  Loss: 0.1690\n",
            "[51200/60000 ( 85%)]  Loss: 0.0994\n",
            "\n",
            "Average test loss: 0.1338  Accuracy: 9598/10000 (95.98%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.1154\n",
            "[12800/60000 ( 21%)]  Loss: 0.0494\n",
            "[25600/60000 ( 43%)]  Loss: 0.1158\n",
            "[38400/60000 ( 64%)]  Loss: 0.0896\n",
            "[51200/60000 ( 85%)]  Loss: 0.1288\n",
            "\n",
            "Average test loss: 0.1129  Accuracy: 9657/10000 (96.57%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0689\n",
            "[12800/60000 ( 21%)]  Loss: 0.0792\n",
            "[25600/60000 ( 43%)]  Loss: 0.1635\n",
            "[38400/60000 ( 64%)]  Loss: 0.0556\n",
            "[51200/60000 ( 85%)]  Loss: 0.1673\n",
            "\n",
            "Average test loss: 0.0907  Accuracy: 9708/10000 (97.08%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0686\n",
            "[12800/60000 ( 21%)]  Loss: 0.0411\n",
            "[25600/60000 ( 43%)]  Loss: 0.1085\n",
            "[38400/60000 ( 64%)]  Loss: 0.0089\n",
            "[51200/60000 ( 85%)]  Loss: 0.1921\n",
            "\n",
            "Average test loss: 0.0988  Accuracy: 9692/10000 (96.92%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0722\n",
            "[12800/60000 ( 21%)]  Loss: 0.0795\n",
            "[25600/60000 ( 43%)]  Loss: 0.0637\n",
            "[38400/60000 ( 64%)]  Loss: 0.0795\n",
            "[51200/60000 ( 85%)]  Loss: 0.1400\n",
            "\n",
            "Average test loss: 0.1097  Accuracy: 9668/10000 (96.68%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0670\n",
            "[12800/60000 ( 21%)]  Loss: 0.0977\n",
            "[25600/60000 ( 43%)]  Loss: 0.0419\n",
            "[38400/60000 ( 64%)]  Loss: 0.0989\n",
            "[51200/60000 ( 85%)]  Loss: 0.1432\n",
            "\n",
            "Average test loss: 0.0930  Accuracy: 9720/10000 (97.20%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0247\n",
            "[12800/60000 ( 21%)]  Loss: 0.0748\n",
            "[25600/60000 ( 43%)]  Loss: 0.0484\n",
            "[38400/60000 ( 64%)]  Loss: 0.1403\n",
            "[51200/60000 ( 85%)]  Loss: 0.0548\n",
            "\n",
            "Average test loss: 0.0791  Accuracy: 9765/10000 (97.65%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0232\n",
            "[12800/60000 ( 21%)]  Loss: 0.0669\n",
            "[25600/60000 ( 43%)]  Loss: 0.0591\n",
            "[38400/60000 ( 64%)]  Loss: 0.0600\n",
            "[51200/60000 ( 85%)]  Loss: 0.0437\n",
            "\n",
            "Average test loss: 0.0914  Accuracy: 9724/10000 (97.24%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0160\n",
            "[12800/60000 ( 21%)]  Loss: 0.0188\n",
            "[25600/60000 ( 43%)]  Loss: 0.0452\n",
            "[38400/60000 ( 64%)]  Loss: 0.0680\n",
            "[51200/60000 ( 85%)]  Loss: 0.0110\n",
            "\n",
            "Average test loss: 0.0848  Accuracy: 9746/10000 (97.46%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0776\n",
            "[12800/60000 ( 21%)]  Loss: 0.0301\n",
            "[25600/60000 ( 43%)]  Loss: 0.0717\n",
            "[38400/60000 ( 64%)]  Loss: 0.0098\n",
            "[51200/60000 ( 85%)]  Loss: 0.1031\n",
            "\n",
            "Average test loss: 0.0794  Accuracy: 9776/10000 (97.76%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0071\n",
            "[12800/60000 ( 21%)]  Loss: 0.0102\n",
            "[25600/60000 ( 43%)]  Loss: 0.0576\n",
            "[38400/60000 ( 64%)]  Loss: 0.0267\n",
            "[51200/60000 ( 85%)]  Loss: 0.0375\n",
            "\n",
            "Average test loss: 0.0858  Accuracy: 9750/10000 (97.50%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0089\n",
            "[12800/60000 ( 21%)]  Loss: 0.0300\n",
            "[25600/60000 ( 43%)]  Loss: 0.0277\n",
            "[38400/60000 ( 64%)]  Loss: 0.0094\n",
            "[51200/60000 ( 85%)]  Loss: 0.0593\n",
            "\n",
            "Average test loss: 0.0848  Accuracy: 9764/10000 (97.64%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0254\n",
            "[12800/60000 ( 21%)]  Loss: 0.0230\n",
            "[25600/60000 ( 43%)]  Loss: 0.0031\n",
            "[38400/60000 ( 64%)]  Loss: 0.0095\n",
            "[51200/60000 ( 85%)]  Loss: 0.0193\n",
            "\n",
            "Average test loss: 0.0889  Accuracy: 9756/10000 (97.56%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0135\n",
            "[12800/60000 ( 21%)]  Loss: 0.0173\n",
            "[25600/60000 ( 43%)]  Loss: 0.0045\n",
            "[38400/60000 ( 64%)]  Loss: 0.0212\n",
            "[51200/60000 ( 85%)]  Loss: 0.0080\n",
            "\n",
            "Average test loss: 0.0838  Accuracy: 9784/10000 (97.84%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0253\n",
            "[12800/60000 ( 21%)]  Loss: 0.0085\n",
            "[25600/60000 ( 43%)]  Loss: 0.0722\n",
            "[38400/60000 ( 64%)]  Loss: 0.0247\n",
            "[51200/60000 ( 85%)]  Loss: 0.0458\n",
            "\n",
            "Average test loss: 0.0789  Accuracy: 9785/10000 (97.85%)\n",
            "\n",
            "Execution time: 382.36 seconds\n",
            "dim 32 depth 12 heads 16 mlp_dim 256\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3114\n",
            "[12800/60000 ( 21%)]  Loss: 1.4867\n",
            "[25600/60000 ( 43%)]  Loss: 0.7159\n",
            "[38400/60000 ( 64%)]  Loss: 0.6112\n",
            "[51200/60000 ( 85%)]  Loss: 0.3810\n",
            "\n",
            "Average test loss: 0.3560  Accuracy: 8895/10000 (88.95%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.5383\n",
            "[12800/60000 ( 21%)]  Loss: 0.3726\n",
            "[25600/60000 ( 43%)]  Loss: 0.2347\n",
            "[38400/60000 ( 64%)]  Loss: 0.3367\n",
            "[51200/60000 ( 85%)]  Loss: 0.2923\n",
            "\n",
            "Average test loss: 0.1954  Accuracy: 9389/10000 (93.89%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.2200\n",
            "[12800/60000 ( 21%)]  Loss: 0.1568\n",
            "[25600/60000 ( 43%)]  Loss: 0.1964\n",
            "[38400/60000 ( 64%)]  Loss: 0.0852\n",
            "[51200/60000 ( 85%)]  Loss: 0.1162\n",
            "\n",
            "Average test loss: 0.1529  Accuracy: 9515/10000 (95.15%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1368\n",
            "[12800/60000 ( 21%)]  Loss: 0.1142\n",
            "[25600/60000 ( 43%)]  Loss: 0.1183\n",
            "[38400/60000 ( 64%)]  Loss: 0.0581\n",
            "[51200/60000 ( 85%)]  Loss: 0.1345\n",
            "\n",
            "Average test loss: 0.1220  Accuracy: 9618/10000 (96.18%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0766\n",
            "[12800/60000 ( 21%)]  Loss: 0.1176\n",
            "[25600/60000 ( 43%)]  Loss: 0.0873\n",
            "[38400/60000 ( 64%)]  Loss: 0.0553\n",
            "[51200/60000 ( 85%)]  Loss: 0.0739\n",
            "\n",
            "Average test loss: 0.1132  Accuracy: 9626/10000 (96.26%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0393\n",
            "[12800/60000 ( 21%)]  Loss: 0.0697\n",
            "[25600/60000 ( 43%)]  Loss: 0.0643\n",
            "[38400/60000 ( 64%)]  Loss: 0.0869\n",
            "[51200/60000 ( 85%)]  Loss: 0.1146\n",
            "\n",
            "Average test loss: 0.1151  Accuracy: 9656/10000 (96.56%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.1310\n",
            "[12800/60000 ( 21%)]  Loss: 0.0849\n",
            "[25600/60000 ( 43%)]  Loss: 0.0560\n",
            "[38400/60000 ( 64%)]  Loss: 0.1043\n",
            "[51200/60000 ( 85%)]  Loss: 0.1459\n",
            "\n",
            "Average test loss: 0.0908  Accuracy: 9713/10000 (97.13%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0361\n",
            "[12800/60000 ( 21%)]  Loss: 0.0369\n",
            "[25600/60000 ( 43%)]  Loss: 0.0698\n",
            "[38400/60000 ( 64%)]  Loss: 0.0933\n",
            "[51200/60000 ( 85%)]  Loss: 0.0980\n",
            "\n",
            "Average test loss: 0.0835  Accuracy: 9733/10000 (97.33%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0375\n",
            "[12800/60000 ( 21%)]  Loss: 0.0722\n",
            "[25600/60000 ( 43%)]  Loss: 0.0866\n",
            "[38400/60000 ( 64%)]  Loss: 0.0937\n",
            "[51200/60000 ( 85%)]  Loss: 0.0873\n",
            "\n",
            "Average test loss: 0.0724  Accuracy: 9766/10000 (97.66%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0170\n",
            "[12800/60000 ( 21%)]  Loss: 0.1050\n",
            "[25600/60000 ( 43%)]  Loss: 0.0840\n",
            "[38400/60000 ( 64%)]  Loss: 0.0919\n",
            "[51200/60000 ( 85%)]  Loss: 0.0717\n",
            "\n",
            "Average test loss: 0.0750  Accuracy: 9752/10000 (97.52%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0551\n",
            "[12800/60000 ( 21%)]  Loss: 0.0813\n",
            "[25600/60000 ( 43%)]  Loss: 0.0120\n",
            "[38400/60000 ( 64%)]  Loss: 0.0532\n",
            "[51200/60000 ( 85%)]  Loss: 0.1104\n",
            "\n",
            "Average test loss: 0.0697  Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0584\n",
            "[12800/60000 ( 21%)]  Loss: 0.1004\n",
            "[25600/60000 ( 43%)]  Loss: 0.0432\n",
            "[38400/60000 ( 64%)]  Loss: 0.0329\n",
            "[51200/60000 ( 85%)]  Loss: 0.0421\n",
            "\n",
            "Average test loss: 0.0697  Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0164\n",
            "[12800/60000 ( 21%)]  Loss: 0.0505\n",
            "[25600/60000 ( 43%)]  Loss: 0.0247\n",
            "[38400/60000 ( 64%)]  Loss: 0.0366\n",
            "[51200/60000 ( 85%)]  Loss: 0.0249\n",
            "\n",
            "Average test loss: 0.0616  Accuracy: 9815/10000 (98.15%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0340\n",
            "[12800/60000 ( 21%)]  Loss: 0.0351\n",
            "[25600/60000 ( 43%)]  Loss: 0.0795\n",
            "[38400/60000 ( 64%)]  Loss: 0.0175\n",
            "[51200/60000 ( 85%)]  Loss: 0.0229\n",
            "\n",
            "Average test loss: 0.0688  Accuracy: 9788/10000 (97.88%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0332\n",
            "[12800/60000 ( 21%)]  Loss: 0.0124\n",
            "[25600/60000 ( 43%)]  Loss: 0.0087\n",
            "[38400/60000 ( 64%)]  Loss: 0.0278\n",
            "[51200/60000 ( 85%)]  Loss: 0.0033\n",
            "\n",
            "Average test loss: 0.0649  Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0379\n",
            "[12800/60000 ( 21%)]  Loss: 0.0362\n",
            "[25600/60000 ( 43%)]  Loss: 0.0166\n",
            "[38400/60000 ( 64%)]  Loss: 0.0128\n",
            "[51200/60000 ( 85%)]  Loss: 0.0722\n",
            "\n",
            "Average test loss: 0.0610  Accuracy: 9827/10000 (98.27%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0195\n",
            "[12800/60000 ( 21%)]  Loss: 0.0284\n",
            "[25600/60000 ( 43%)]  Loss: 0.0007\n",
            "[38400/60000 ( 64%)]  Loss: 0.0116\n",
            "[51200/60000 ( 85%)]  Loss: 0.0195\n",
            "\n",
            "Average test loss: 0.0672  Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0163\n",
            "[12800/60000 ( 21%)]  Loss: 0.0031\n",
            "[25600/60000 ( 43%)]  Loss: 0.0017\n",
            "[38400/60000 ( 64%)]  Loss: 0.0190\n",
            "[51200/60000 ( 85%)]  Loss: 0.0103\n",
            "\n",
            "Average test loss: 0.0587  Accuracy: 9842/10000 (98.42%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0008\n",
            "[12800/60000 ( 21%)]  Loss: 0.0242\n",
            "[25600/60000 ( 43%)]  Loss: 0.0350\n",
            "[38400/60000 ( 64%)]  Loss: 0.0318\n",
            "[51200/60000 ( 85%)]  Loss: 0.0102\n",
            "\n",
            "Average test loss: 0.0591  Accuracy: 9840/10000 (98.40%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0053\n",
            "[12800/60000 ( 21%)]  Loss: 0.0015\n",
            "[25600/60000 ( 43%)]  Loss: 0.0158\n",
            "[38400/60000 ( 64%)]  Loss: 0.0050\n",
            "[51200/60000 ( 85%)]  Loss: 0.0226\n",
            "\n",
            "Average test loss: 0.0777  Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Execution time: 381.53 seconds\n",
            "dim 32 depth 12 heads 16 mlp_dim 512\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3284\n",
            "[12800/60000 ( 21%)]  Loss: 1.3044\n",
            "[25600/60000 ( 43%)]  Loss: 0.9693\n",
            "[38400/60000 ( 64%)]  Loss: 0.5831\n",
            "[51200/60000 ( 85%)]  Loss: 0.4239\n",
            "\n",
            "Average test loss: 0.3715  Accuracy: 8831/10000 (88.31%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.5193\n",
            "[12800/60000 ( 21%)]  Loss: 0.3075\n",
            "[25600/60000 ( 43%)]  Loss: 0.4222\n",
            "[38400/60000 ( 64%)]  Loss: 0.2749\n",
            "[51200/60000 ( 85%)]  Loss: 0.2664\n",
            "\n",
            "Average test loss: 0.1874  Accuracy: 9420/10000 (94.20%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.2831\n",
            "[12800/60000 ( 21%)]  Loss: 0.1968\n",
            "[25600/60000 ( 43%)]  Loss: 0.1849\n",
            "[38400/60000 ( 64%)]  Loss: 0.1791\n",
            "[51200/60000 ( 85%)]  Loss: 0.2243\n",
            "\n",
            "Average test loss: 0.1804  Accuracy: 9446/10000 (94.46%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.2061\n",
            "[12800/60000 ( 21%)]  Loss: 0.0829\n",
            "[25600/60000 ( 43%)]  Loss: 0.2315\n",
            "[38400/60000 ( 64%)]  Loss: 0.1382\n",
            "[51200/60000 ( 85%)]  Loss: 0.1085\n",
            "\n",
            "Average test loss: 0.1486  Accuracy: 9533/10000 (95.33%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.1323\n",
            "[12800/60000 ( 21%)]  Loss: 0.0846\n",
            "[25600/60000 ( 43%)]  Loss: 0.1468\n",
            "[38400/60000 ( 64%)]  Loss: 0.0603\n",
            "[51200/60000 ( 85%)]  Loss: 0.1708\n",
            "\n",
            "Average test loss: 0.1243  Accuracy: 9608/10000 (96.08%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.1009\n",
            "[12800/60000 ( 21%)]  Loss: 0.0721\n",
            "[25600/60000 ( 43%)]  Loss: 0.1004\n",
            "[38400/60000 ( 64%)]  Loss: 0.0963\n",
            "[51200/60000 ( 85%)]  Loss: 0.1768\n",
            "\n",
            "Average test loss: 0.1130  Accuracy: 9656/10000 (96.56%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.1069\n",
            "[12800/60000 ( 21%)]  Loss: 0.0835\n",
            "[25600/60000 ( 43%)]  Loss: 0.0855\n",
            "[38400/60000 ( 64%)]  Loss: 0.0886\n",
            "[51200/60000 ( 85%)]  Loss: 0.0800\n",
            "\n",
            "Average test loss: 0.0881  Accuracy: 9738/10000 (97.38%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0626\n",
            "[12800/60000 ( 21%)]  Loss: 0.0404\n",
            "[25600/60000 ( 43%)]  Loss: 0.0417\n",
            "[38400/60000 ( 64%)]  Loss: 0.0785\n",
            "[51200/60000 ( 85%)]  Loss: 0.0743\n",
            "\n",
            "Average test loss: 0.0957  Accuracy: 9704/10000 (97.04%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0549\n",
            "[12800/60000 ( 21%)]  Loss: 0.0362\n",
            "[25600/60000 ( 43%)]  Loss: 0.0532\n",
            "[38400/60000 ( 64%)]  Loss: 0.0372\n",
            "[51200/60000 ( 85%)]  Loss: 0.0520\n",
            "\n",
            "Average test loss: 0.0814  Accuracy: 9737/10000 (97.37%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0109\n",
            "[12800/60000 ( 21%)]  Loss: 0.0240\n",
            "[25600/60000 ( 43%)]  Loss: 0.0393\n",
            "[38400/60000 ( 64%)]  Loss: 0.0853\n",
            "[51200/60000 ( 85%)]  Loss: 0.0412\n",
            "\n",
            "Average test loss: 0.0819  Accuracy: 9735/10000 (97.35%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0215\n",
            "[12800/60000 ( 21%)]  Loss: 0.0748\n",
            "[25600/60000 ( 43%)]  Loss: 0.0354\n",
            "[38400/60000 ( 64%)]  Loss: 0.0604\n",
            "[51200/60000 ( 85%)]  Loss: 0.0506\n",
            "\n",
            "Average test loss: 0.0736  Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0847\n",
            "[12800/60000 ( 21%)]  Loss: 0.0571\n",
            "[25600/60000 ( 43%)]  Loss: 0.0117\n",
            "[38400/60000 ( 64%)]  Loss: 0.0560\n",
            "[51200/60000 ( 85%)]  Loss: 0.0704\n",
            "\n",
            "Average test loss: 0.0717  Accuracy: 9771/10000 (97.71%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0363\n",
            "[12800/60000 ( 21%)]  Loss: 0.0084\n",
            "[25600/60000 ( 43%)]  Loss: 0.0550\n",
            "[38400/60000 ( 64%)]  Loss: 0.0520\n",
            "[51200/60000 ( 85%)]  Loss: 0.0569\n",
            "\n",
            "Average test loss: 0.0773  Accuracy: 9775/10000 (97.75%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0532\n",
            "[12800/60000 ( 21%)]  Loss: 0.0269\n",
            "[25600/60000 ( 43%)]  Loss: 0.0368\n",
            "[38400/60000 ( 64%)]  Loss: 0.0245\n",
            "[51200/60000 ( 85%)]  Loss: 0.0432\n",
            "\n",
            "Average test loss: 0.0766  Accuracy: 9771/10000 (97.71%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0538\n",
            "[12800/60000 ( 21%)]  Loss: 0.0543\n",
            "[25600/60000 ( 43%)]  Loss: 0.0249\n",
            "[38400/60000 ( 64%)]  Loss: 0.0422\n",
            "[51200/60000 ( 85%)]  Loss: 0.0509\n",
            "\n",
            "Average test loss: 0.0615  Accuracy: 9810/10000 (98.10%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0593\n",
            "[12800/60000 ( 21%)]  Loss: 0.0287\n",
            "[25600/60000 ( 43%)]  Loss: 0.0123\n",
            "[38400/60000 ( 64%)]  Loss: 0.0114\n",
            "[51200/60000 ( 85%)]  Loss: 0.0211\n",
            "\n",
            "Average test loss: 0.0635  Accuracy: 9812/10000 (98.12%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0106\n",
            "[12800/60000 ( 21%)]  Loss: 0.0138\n",
            "[25600/60000 ( 43%)]  Loss: 0.0111\n",
            "[38400/60000 ( 64%)]  Loss: 0.0242\n",
            "[51200/60000 ( 85%)]  Loss: 0.0093\n",
            "\n",
            "Average test loss: 0.0628  Accuracy: 9812/10000 (98.12%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0161\n",
            "[12800/60000 ( 21%)]  Loss: 0.0106\n",
            "[25600/60000 ( 43%)]  Loss: 0.0123\n",
            "[38400/60000 ( 64%)]  Loss: 0.0029\n",
            "[51200/60000 ( 85%)]  Loss: 0.0199\n",
            "\n",
            "Average test loss: 0.0691  Accuracy: 9815/10000 (98.15%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0372\n",
            "[12800/60000 ( 21%)]  Loss: 0.0064\n",
            "[25600/60000 ( 43%)]  Loss: 0.0045\n",
            "[38400/60000 ( 64%)]  Loss: 0.0151\n",
            "[51200/60000 ( 85%)]  Loss: 0.0082\n",
            "\n",
            "Average test loss: 0.0639  Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0114\n",
            "[12800/60000 ( 21%)]  Loss: 0.0049\n",
            "[25600/60000 ( 43%)]  Loss: 0.0490\n",
            "[38400/60000 ( 64%)]  Loss: 0.0345\n",
            "[51200/60000 ( 85%)]  Loss: 0.0509\n",
            "\n",
            "Average test loss: 0.0702  Accuracy: 9815/10000 (98.15%)\n",
            "\n",
            "Execution time: 381.81 seconds\n",
            "dim 64 depth 4 heads 4 mlp_dim 128\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3460\n",
            "[12800/60000 ( 21%)]  Loss: 0.7955\n",
            "[25600/60000 ( 43%)]  Loss: 0.3654\n",
            "[38400/60000 ( 64%)]  Loss: 0.1749\n",
            "[51200/60000 ( 85%)]  Loss: 0.2526\n",
            "\n",
            "Average test loss: 0.2209  Accuracy: 9335/10000 (93.35%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.2586\n",
            "[12800/60000 ( 21%)]  Loss: 0.1963\n",
            "[25600/60000 ( 43%)]  Loss: 0.1421\n",
            "[38400/60000 ( 64%)]  Loss: 0.0646\n",
            "[51200/60000 ( 85%)]  Loss: 0.1440\n",
            "\n",
            "Average test loss: 0.1096  Accuracy: 9650/10000 (96.50%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1060\n",
            "[12800/60000 ( 21%)]  Loss: 0.1052\n",
            "[25600/60000 ( 43%)]  Loss: 0.0426\n",
            "[38400/60000 ( 64%)]  Loss: 0.0459\n",
            "[51200/60000 ( 85%)]  Loss: 0.0609\n",
            "\n",
            "Average test loss: 0.0911  Accuracy: 9716/10000 (97.16%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1974\n",
            "[12800/60000 ( 21%)]  Loss: 0.1023\n",
            "[25600/60000 ( 43%)]  Loss: 0.0355\n",
            "[38400/60000 ( 64%)]  Loss: 0.0499\n",
            "[51200/60000 ( 85%)]  Loss: 0.0811\n",
            "\n",
            "Average test loss: 0.0849  Accuracy: 9738/10000 (97.38%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.1091\n",
            "[12800/60000 ( 21%)]  Loss: 0.0814\n",
            "[25600/60000 ( 43%)]  Loss: 0.0595\n",
            "[38400/60000 ( 64%)]  Loss: 0.0637\n",
            "[51200/60000 ( 85%)]  Loss: 0.1454\n",
            "\n",
            "Average test loss: 0.0694  Accuracy: 9779/10000 (97.79%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0235\n",
            "[12800/60000 ( 21%)]  Loss: 0.0412\n",
            "[25600/60000 ( 43%)]  Loss: 0.0440\n",
            "[38400/60000 ( 64%)]  Loss: 0.0365\n",
            "[51200/60000 ( 85%)]  Loss: 0.0254\n",
            "\n",
            "Average test loss: 0.0703  Accuracy: 9789/10000 (97.89%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0238\n",
            "[12800/60000 ( 21%)]  Loss: 0.0336\n",
            "[25600/60000 ( 43%)]  Loss: 0.0623\n",
            "[38400/60000 ( 64%)]  Loss: 0.0792\n",
            "[51200/60000 ( 85%)]  Loss: 0.1321\n",
            "\n",
            "Average test loss: 0.0705  Accuracy: 9784/10000 (97.84%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0656\n",
            "[12800/60000 ( 21%)]  Loss: 0.0563\n",
            "[25600/60000 ( 43%)]  Loss: 0.0358\n",
            "[38400/60000 ( 64%)]  Loss: 0.0744\n",
            "[51200/60000 ( 85%)]  Loss: 0.0228\n",
            "\n",
            "Average test loss: 0.0713  Accuracy: 9775/10000 (97.75%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0467\n",
            "[12800/60000 ( 21%)]  Loss: 0.0480\n",
            "[25600/60000 ( 43%)]  Loss: 0.0150\n",
            "[38400/60000 ( 64%)]  Loss: 0.0191\n",
            "[51200/60000 ( 85%)]  Loss: 0.0144\n",
            "\n",
            "Average test loss: 0.0637  Accuracy: 9824/10000 (98.24%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0359\n",
            "[12800/60000 ( 21%)]  Loss: 0.0086\n",
            "[25600/60000 ( 43%)]  Loss: 0.0256\n",
            "[38400/60000 ( 64%)]  Loss: 0.0028\n",
            "[51200/60000 ( 85%)]  Loss: 0.0093\n",
            "\n",
            "Average test loss: 0.0703  Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0149\n",
            "[12800/60000 ( 21%)]  Loss: 0.0203\n",
            "[25600/60000 ( 43%)]  Loss: 0.0091\n",
            "[38400/60000 ( 64%)]  Loss: 0.0248\n",
            "[51200/60000 ( 85%)]  Loss: 0.0110\n",
            "\n",
            "Average test loss: 0.0686  Accuracy: 9827/10000 (98.27%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0399\n",
            "[12800/60000 ( 21%)]  Loss: 0.0044\n",
            "[25600/60000 ( 43%)]  Loss: 0.0060\n",
            "[38400/60000 ( 64%)]  Loss: 0.0039\n",
            "[51200/60000 ( 85%)]  Loss: 0.0337\n",
            "\n",
            "Average test loss: 0.0688  Accuracy: 9814/10000 (98.14%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0793\n",
            "[12800/60000 ( 21%)]  Loss: 0.0031\n",
            "[25600/60000 ( 43%)]  Loss: 0.0861\n",
            "[38400/60000 ( 64%)]  Loss: 0.0071\n",
            "[51200/60000 ( 85%)]  Loss: 0.0241\n",
            "\n",
            "Average test loss: 0.0631  Accuracy: 9835/10000 (98.35%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0054\n",
            "[12800/60000 ( 21%)]  Loss: 0.0140\n",
            "[25600/60000 ( 43%)]  Loss: 0.0114\n",
            "[38400/60000 ( 64%)]  Loss: 0.0126\n",
            "[51200/60000 ( 85%)]  Loss: 0.0091\n",
            "\n",
            "Average test loss: 0.0704  Accuracy: 9824/10000 (98.24%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0011\n",
            "[12800/60000 ( 21%)]  Loss: 0.0025\n",
            "[25600/60000 ( 43%)]  Loss: 0.0041\n",
            "[38400/60000 ( 64%)]  Loss: 0.0006\n",
            "[51200/60000 ( 85%)]  Loss: 0.0166\n",
            "\n",
            "Average test loss: 0.0780  Accuracy: 9806/10000 (98.06%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0038\n",
            "[12800/60000 ( 21%)]  Loss: 0.0017\n",
            "[25600/60000 ( 43%)]  Loss: 0.0107\n",
            "[38400/60000 ( 64%)]  Loss: 0.0093\n",
            "[51200/60000 ( 85%)]  Loss: 0.0042\n",
            "\n",
            "Average test loss: 0.0686  Accuracy: 9829/10000 (98.29%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0037\n",
            "[12800/60000 ( 21%)]  Loss: 0.0255\n",
            "[25600/60000 ( 43%)]  Loss: 0.0002\n",
            "[38400/60000 ( 64%)]  Loss: 0.0084\n",
            "[51200/60000 ( 85%)]  Loss: 0.0045\n",
            "\n",
            "Average test loss: 0.0624  Accuracy: 9849/10000 (98.49%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0006\n",
            "[12800/60000 ( 21%)]  Loss: 0.0103\n",
            "[25600/60000 ( 43%)]  Loss: 0.0066\n",
            "[38400/60000 ( 64%)]  Loss: 0.0041\n",
            "[51200/60000 ( 85%)]  Loss: 0.0063\n",
            "\n",
            "Average test loss: 0.0721  Accuracy: 9832/10000 (98.32%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0014\n",
            "[12800/60000 ( 21%)]  Loss: 0.0113\n",
            "[25600/60000 ( 43%)]  Loss: 0.0018\n",
            "[38400/60000 ( 64%)]  Loss: 0.0003\n",
            "[51200/60000 ( 85%)]  Loss: 0.0099\n",
            "\n",
            "Average test loss: 0.0690  Accuracy: 9857/10000 (98.57%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0041\n",
            "[12800/60000 ( 21%)]  Loss: 0.0057\n",
            "[25600/60000 ( 43%)]  Loss: 0.0010\n",
            "[38400/60000 ( 64%)]  Loss: 0.0038\n",
            "[51200/60000 ( 85%)]  Loss: 0.0053\n",
            "\n",
            "Average test loss: 0.0747  Accuracy: 9846/10000 (98.46%)\n",
            "\n",
            "Execution time: 225.17 seconds\n",
            "dim 64 depth 4 heads 4 mlp_dim 256\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3520\n",
            "[12800/60000 ( 21%)]  Loss: 0.5231\n",
            "[25600/60000 ( 43%)]  Loss: 0.3607\n",
            "[38400/60000 ( 64%)]  Loss: 0.2051\n",
            "[51200/60000 ( 85%)]  Loss: 0.1676\n",
            "\n",
            "Average test loss: 0.1777  Accuracy: 9430/10000 (94.30%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.1234\n",
            "[12800/60000 ( 21%)]  Loss: 0.2462\n",
            "[25600/60000 ( 43%)]  Loss: 0.0702\n",
            "[38400/60000 ( 64%)]  Loss: 0.1017\n",
            "[51200/60000 ( 85%)]  Loss: 0.1301\n",
            "\n",
            "Average test loss: 0.1170  Accuracy: 9621/10000 (96.21%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1029\n",
            "[12800/60000 ( 21%)]  Loss: 0.1608\n",
            "[25600/60000 ( 43%)]  Loss: 0.0841\n",
            "[38400/60000 ( 64%)]  Loss: 0.0489\n",
            "[51200/60000 ( 85%)]  Loss: 0.0615\n",
            "\n",
            "Average test loss: 0.0911  Accuracy: 9716/10000 (97.16%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1286\n",
            "[12800/60000 ( 21%)]  Loss: 0.0794\n",
            "[25600/60000 ( 43%)]  Loss: 0.1115\n",
            "[38400/60000 ( 64%)]  Loss: 0.0477\n",
            "[51200/60000 ( 85%)]  Loss: 0.1279\n",
            "\n",
            "Average test loss: 0.0716  Accuracy: 9768/10000 (97.68%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0714\n",
            "[12800/60000 ( 21%)]  Loss: 0.0383\n",
            "[25600/60000 ( 43%)]  Loss: 0.0433\n",
            "[38400/60000 ( 64%)]  Loss: 0.0567\n",
            "[51200/60000 ( 85%)]  Loss: 0.0195\n",
            "\n",
            "Average test loss: 0.0693  Accuracy: 9766/10000 (97.66%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0421\n",
            "[12800/60000 ( 21%)]  Loss: 0.0160\n",
            "[25600/60000 ( 43%)]  Loss: 0.0429\n",
            "[38400/60000 ( 64%)]  Loss: 0.0460\n",
            "[51200/60000 ( 85%)]  Loss: 0.0360\n",
            "\n",
            "Average test loss: 0.0764  Accuracy: 9759/10000 (97.59%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0178\n",
            "[12800/60000 ( 21%)]  Loss: 0.0131\n",
            "[25600/60000 ( 43%)]  Loss: 0.0204\n",
            "[38400/60000 ( 64%)]  Loss: 0.1506\n",
            "[51200/60000 ( 85%)]  Loss: 0.0326\n",
            "\n",
            "Average test loss: 0.0759  Accuracy: 9774/10000 (97.74%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0577\n",
            "[12800/60000 ( 21%)]  Loss: 0.0232\n",
            "[25600/60000 ( 43%)]  Loss: 0.0245\n",
            "[38400/60000 ( 64%)]  Loss: 0.0219\n",
            "[51200/60000 ( 85%)]  Loss: 0.0401\n",
            "\n",
            "Average test loss: 0.0647  Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0077\n",
            "[12800/60000 ( 21%)]  Loss: 0.0093\n",
            "[25600/60000 ( 43%)]  Loss: 0.0026\n",
            "[38400/60000 ( 64%)]  Loss: 0.0232\n",
            "[51200/60000 ( 85%)]  Loss: 0.0027\n",
            "\n",
            "Average test loss: 0.0705  Accuracy: 9789/10000 (97.89%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0598\n",
            "[12800/60000 ( 21%)]  Loss: 0.0459\n",
            "[25600/60000 ( 43%)]  Loss: 0.0418\n",
            "[38400/60000 ( 64%)]  Loss: 0.0138\n",
            "[51200/60000 ( 85%)]  Loss: 0.0059\n",
            "\n",
            "Average test loss: 0.0703  Accuracy: 9798/10000 (97.98%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0403\n",
            "[12800/60000 ( 21%)]  Loss: 0.0535\n",
            "[25600/60000 ( 43%)]  Loss: 0.0221\n",
            "[38400/60000 ( 64%)]  Loss: 0.0065\n",
            "[51200/60000 ( 85%)]  Loss: 0.0400\n",
            "\n",
            "Average test loss: 0.0633  Accuracy: 9816/10000 (98.16%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0131\n",
            "[12800/60000 ( 21%)]  Loss: 0.0036\n",
            "[25600/60000 ( 43%)]  Loss: 0.0014\n",
            "[38400/60000 ( 64%)]  Loss: 0.0118\n",
            "[51200/60000 ( 85%)]  Loss: 0.0561\n",
            "\n",
            "Average test loss: 0.0585  Accuracy: 9834/10000 (98.34%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0151\n",
            "[12800/60000 ( 21%)]  Loss: 0.0121\n",
            "[25600/60000 ( 43%)]  Loss: 0.0291\n",
            "[38400/60000 ( 64%)]  Loss: 0.0015\n",
            "[51200/60000 ( 85%)]  Loss: 0.0031\n",
            "\n",
            "Average test loss: 0.0778  Accuracy: 9782/10000 (97.82%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0009\n",
            "[12800/60000 ( 21%)]  Loss: 0.0015\n",
            "[25600/60000 ( 43%)]  Loss: 0.0032\n",
            "[38400/60000 ( 64%)]  Loss: 0.0144\n",
            "[51200/60000 ( 85%)]  Loss: 0.0026\n",
            "\n",
            "Average test loss: 0.0594  Accuracy: 9850/10000 (98.50%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0051\n",
            "[12800/60000 ( 21%)]  Loss: 0.0018\n",
            "[25600/60000 ( 43%)]  Loss: 0.0042\n",
            "[38400/60000 ( 64%)]  Loss: 0.0046\n",
            "[51200/60000 ( 85%)]  Loss: 0.0148\n",
            "\n",
            "Average test loss: 0.0602  Accuracy: 9839/10000 (98.39%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0031\n",
            "[12800/60000 ( 21%)]  Loss: 0.0010\n",
            "[25600/60000 ( 43%)]  Loss: 0.0009\n",
            "[38400/60000 ( 64%)]  Loss: 0.0041\n",
            "[51200/60000 ( 85%)]  Loss: 0.0092\n",
            "\n",
            "Average test loss: 0.0627  Accuracy: 9835/10000 (98.35%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0077\n",
            "[12800/60000 ( 21%)]  Loss: 0.0148\n",
            "[25600/60000 ( 43%)]  Loss: 0.0067\n",
            "[38400/60000 ( 64%)]  Loss: 0.0053\n",
            "[51200/60000 ( 85%)]  Loss: 0.0052\n",
            "\n",
            "Average test loss: 0.0665  Accuracy: 9828/10000 (98.28%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0303\n",
            "[12800/60000 ( 21%)]  Loss: 0.0034\n",
            "[25600/60000 ( 43%)]  Loss: 0.0022\n",
            "[38400/60000 ( 64%)]  Loss: 0.0082\n",
            "[51200/60000 ( 85%)]  Loss: 0.0038\n",
            "\n",
            "Average test loss: 0.0755  Accuracy: 9824/10000 (98.24%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0006\n",
            "[12800/60000 ( 21%)]  Loss: 0.0008\n",
            "[25600/60000 ( 43%)]  Loss: 0.0072\n",
            "[38400/60000 ( 64%)]  Loss: 0.0083\n",
            "[51200/60000 ( 85%)]  Loss: 0.0191\n",
            "\n",
            "Average test loss: 0.0657  Accuracy: 9838/10000 (98.38%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0025\n",
            "[12800/60000 ( 21%)]  Loss: 0.0024\n",
            "[25600/60000 ( 43%)]  Loss: 0.0007\n",
            "[38400/60000 ( 64%)]  Loss: 0.0014\n",
            "[51200/60000 ( 85%)]  Loss: 0.0007\n",
            "\n",
            "Average test loss: 0.0613  Accuracy: 9839/10000 (98.39%)\n",
            "\n",
            "Execution time: 226.41 seconds\n",
            "dim 64 depth 4 heads 4 mlp_dim 512\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3299\n",
            "[12800/60000 ( 21%)]  Loss: 0.8721\n",
            "[25600/60000 ( 43%)]  Loss: 0.3613\n",
            "[38400/60000 ( 64%)]  Loss: 0.3934\n",
            "[51200/60000 ( 85%)]  Loss: 0.1807\n",
            "\n",
            "Average test loss: 0.1907  Accuracy: 9403/10000 (94.03%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.3018\n",
            "[12800/60000 ( 21%)]  Loss: 0.2295\n",
            "[25600/60000 ( 43%)]  Loss: 0.2227\n",
            "[38400/60000 ( 64%)]  Loss: 0.1161\n",
            "[51200/60000 ( 85%)]  Loss: 0.1578\n",
            "\n",
            "Average test loss: 0.1196  Accuracy: 9626/10000 (96.26%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0745\n",
            "[12800/60000 ( 21%)]  Loss: 0.1086\n",
            "[25600/60000 ( 43%)]  Loss: 0.0727\n",
            "[38400/60000 ( 64%)]  Loss: 0.0568\n",
            "[51200/60000 ( 85%)]  Loss: 0.1207\n",
            "\n",
            "Average test loss: 0.0949  Accuracy: 9715/10000 (97.15%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0774\n",
            "[12800/60000 ( 21%)]  Loss: 0.1193\n",
            "[25600/60000 ( 43%)]  Loss: 0.0871\n",
            "[38400/60000 ( 64%)]  Loss: 0.0727\n",
            "[51200/60000 ( 85%)]  Loss: 0.1832\n",
            "\n",
            "Average test loss: 0.0811  Accuracy: 9742/10000 (97.42%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0210\n",
            "[12800/60000 ( 21%)]  Loss: 0.1340\n",
            "[25600/60000 ( 43%)]  Loss: 0.0338\n",
            "[38400/60000 ( 64%)]  Loss: 0.0169\n",
            "[51200/60000 ( 85%)]  Loss: 0.1445\n",
            "\n",
            "Average test loss: 0.0704  Accuracy: 9789/10000 (97.89%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0790\n",
            "[12800/60000 ( 21%)]  Loss: 0.1063\n",
            "[25600/60000 ( 43%)]  Loss: 0.0824\n",
            "[38400/60000 ( 64%)]  Loss: 0.1611\n",
            "[51200/60000 ( 85%)]  Loss: 0.0422\n",
            "\n",
            "Average test loss: 0.0782  Accuracy: 9770/10000 (97.70%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0154\n",
            "[12800/60000 ( 21%)]  Loss: 0.0469\n",
            "[25600/60000 ( 43%)]  Loss: 0.0209\n",
            "[38400/60000 ( 64%)]  Loss: 0.0413\n",
            "[51200/60000 ( 85%)]  Loss: 0.0431\n",
            "\n",
            "Average test loss: 0.0801  Accuracy: 9759/10000 (97.59%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.1535\n",
            "[12800/60000 ( 21%)]  Loss: 0.0145\n",
            "[25600/60000 ( 43%)]  Loss: 0.1362\n",
            "[38400/60000 ( 64%)]  Loss: 0.0157\n",
            "[51200/60000 ( 85%)]  Loss: 0.0240\n",
            "\n",
            "Average test loss: 0.0612  Accuracy: 9813/10000 (98.13%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0258\n",
            "[12800/60000 ( 21%)]  Loss: 0.0210\n",
            "[25600/60000 ( 43%)]  Loss: 0.0401\n",
            "[38400/60000 ( 64%)]  Loss: 0.0549\n",
            "[51200/60000 ( 85%)]  Loss: 0.0362\n",
            "\n",
            "Average test loss: 0.0695  Accuracy: 9794/10000 (97.94%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0688\n",
            "[12800/60000 ( 21%)]  Loss: 0.0117\n",
            "[25600/60000 ( 43%)]  Loss: 0.0120\n",
            "[38400/60000 ( 64%)]  Loss: 0.0039\n",
            "[51200/60000 ( 85%)]  Loss: 0.0078\n",
            "\n",
            "Average test loss: 0.0678  Accuracy: 9814/10000 (98.14%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0070\n",
            "[12800/60000 ( 21%)]  Loss: 0.0171\n",
            "[25600/60000 ( 43%)]  Loss: 0.0208\n",
            "[38400/60000 ( 64%)]  Loss: 0.0278\n",
            "[51200/60000 ( 85%)]  Loss: 0.0145\n",
            "\n",
            "Average test loss: 0.0717  Accuracy: 9795/10000 (97.95%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0202\n",
            "[12800/60000 ( 21%)]  Loss: 0.0504\n",
            "[25600/60000 ( 43%)]  Loss: 0.0153\n",
            "[38400/60000 ( 64%)]  Loss: 0.0093\n",
            "[51200/60000 ( 85%)]  Loss: 0.0059\n",
            "\n",
            "Average test loss: 0.0674  Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0160\n",
            "[12800/60000 ( 21%)]  Loss: 0.0174\n",
            "[25600/60000 ( 43%)]  Loss: 0.0514\n",
            "[38400/60000 ( 64%)]  Loss: 0.0265\n",
            "[51200/60000 ( 85%)]  Loss: 0.0099\n",
            "\n",
            "Average test loss: 0.0647  Accuracy: 9823/10000 (98.23%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0052\n",
            "[12800/60000 ( 21%)]  Loss: 0.0128\n",
            "[25600/60000 ( 43%)]  Loss: 0.0241\n",
            "[38400/60000 ( 64%)]  Loss: 0.0320\n",
            "[51200/60000 ( 85%)]  Loss: 0.0193\n",
            "\n",
            "Average test loss: 0.0682  Accuracy: 9821/10000 (98.21%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0218\n",
            "[12800/60000 ( 21%)]  Loss: 0.0130\n",
            "[25600/60000 ( 43%)]  Loss: 0.0029\n",
            "[38400/60000 ( 64%)]  Loss: 0.0152\n",
            "[51200/60000 ( 85%)]  Loss: 0.0242\n",
            "\n",
            "Average test loss: 0.0745  Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0404\n",
            "[12800/60000 ( 21%)]  Loss: 0.0166\n",
            "[25600/60000 ( 43%)]  Loss: 0.0169\n",
            "[38400/60000 ( 64%)]  Loss: 0.0030\n",
            "[51200/60000 ( 85%)]  Loss: 0.0057\n",
            "\n",
            "Average test loss: 0.0692  Accuracy: 9824/10000 (98.24%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0012\n",
            "[12800/60000 ( 21%)]  Loss: 0.0076\n",
            "[25600/60000 ( 43%)]  Loss: 0.0039\n",
            "[38400/60000 ( 64%)]  Loss: 0.0206\n",
            "[51200/60000 ( 85%)]  Loss: 0.0030\n",
            "\n",
            "Average test loss: 0.0739  Accuracy: 9815/10000 (98.15%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0029\n",
            "[12800/60000 ( 21%)]  Loss: 0.0001\n",
            "[25600/60000 ( 43%)]  Loss: 0.0455\n",
            "[38400/60000 ( 64%)]  Loss: 0.0018\n",
            "[51200/60000 ( 85%)]  Loss: 0.0015\n",
            "\n",
            "Average test loss: 0.0726  Accuracy: 9826/10000 (98.26%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0420\n",
            "[12800/60000 ( 21%)]  Loss: 0.0050\n",
            "[25600/60000 ( 43%)]  Loss: 0.0010\n",
            "[38400/60000 ( 64%)]  Loss: 0.0149\n",
            "[51200/60000 ( 85%)]  Loss: 0.0075\n",
            "\n",
            "Average test loss: 0.0726  Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0078\n",
            "[12800/60000 ( 21%)]  Loss: 0.0012\n",
            "[25600/60000 ( 43%)]  Loss: 0.0014\n",
            "[38400/60000 ( 64%)]  Loss: 0.0034\n",
            "[51200/60000 ( 85%)]  Loss: 0.0009\n",
            "\n",
            "Average test loss: 0.0749  Accuracy: 9836/10000 (98.36%)\n",
            "\n",
            "Execution time: 226.66 seconds\n",
            "dim 64 depth 4 heads 8 mlp_dim 128\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3958\n",
            "[12800/60000 ( 21%)]  Loss: 1.0984\n",
            "[25600/60000 ( 43%)]  Loss: 0.5243\n",
            "[38400/60000 ( 64%)]  Loss: 0.1740\n",
            "[51200/60000 ( 85%)]  Loss: 0.2083\n",
            "\n",
            "Average test loss: 0.2018  Accuracy: 9362/10000 (93.62%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.1333\n",
            "[12800/60000 ( 21%)]  Loss: 0.0687\n",
            "[25600/60000 ( 43%)]  Loss: 0.2313\n",
            "[38400/60000 ( 64%)]  Loss: 0.1156\n",
            "[51200/60000 ( 85%)]  Loss: 0.1850\n",
            "\n",
            "Average test loss: 0.1249  Accuracy: 9617/10000 (96.17%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0678\n",
            "[12800/60000 ( 21%)]  Loss: 0.1369\n",
            "[25600/60000 ( 43%)]  Loss: 0.1382\n",
            "[38400/60000 ( 64%)]  Loss: 0.2067\n",
            "[51200/60000 ( 85%)]  Loss: 0.1595\n",
            "\n",
            "Average test loss: 0.0957  Accuracy: 9687/10000 (96.87%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1042\n",
            "[12800/60000 ( 21%)]  Loss: 0.1160\n",
            "[25600/60000 ( 43%)]  Loss: 0.0290\n",
            "[38400/60000 ( 64%)]  Loss: 0.1446\n",
            "[51200/60000 ( 85%)]  Loss: 0.1451\n",
            "\n",
            "Average test loss: 0.0936  Accuracy: 9722/10000 (97.22%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0989\n",
            "[12800/60000 ( 21%)]  Loss: 0.0612\n",
            "[25600/60000 ( 43%)]  Loss: 0.1528\n",
            "[38400/60000 ( 64%)]  Loss: 0.0696\n",
            "[51200/60000 ( 85%)]  Loss: 0.0285\n",
            "\n",
            "Average test loss: 0.0831  Accuracy: 9748/10000 (97.48%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0373\n",
            "[12800/60000 ( 21%)]  Loss: 0.0825\n",
            "[25600/60000 ( 43%)]  Loss: 0.0589\n",
            "[38400/60000 ( 64%)]  Loss: 0.0435\n",
            "[51200/60000 ( 85%)]  Loss: 0.0856\n",
            "\n",
            "Average test loss: 0.0724  Accuracy: 9766/10000 (97.66%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0434\n",
            "[12800/60000 ( 21%)]  Loss: 0.0637\n",
            "[25600/60000 ( 43%)]  Loss: 0.0607\n",
            "[38400/60000 ( 64%)]  Loss: 0.0242\n",
            "[51200/60000 ( 85%)]  Loss: 0.0095\n",
            "\n",
            "Average test loss: 0.0620  Accuracy: 9798/10000 (97.98%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0266\n",
            "[12800/60000 ( 21%)]  Loss: 0.0563\n",
            "[25600/60000 ( 43%)]  Loss: 0.0810\n",
            "[38400/60000 ( 64%)]  Loss: 0.0183\n",
            "[51200/60000 ( 85%)]  Loss: 0.0203\n",
            "\n",
            "Average test loss: 0.0767  Accuracy: 9783/10000 (97.83%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0696\n",
            "[12800/60000 ( 21%)]  Loss: 0.0280\n",
            "[25600/60000 ( 43%)]  Loss: 0.0356\n",
            "[38400/60000 ( 64%)]  Loss: 0.0256\n",
            "[51200/60000 ( 85%)]  Loss: 0.0068\n",
            "\n",
            "Average test loss: 0.0630  Accuracy: 9823/10000 (98.23%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0089\n",
            "[12800/60000 ( 21%)]  Loss: 0.0127\n",
            "[25600/60000 ( 43%)]  Loss: 0.0214\n",
            "[38400/60000 ( 64%)]  Loss: 0.0064\n",
            "[51200/60000 ( 85%)]  Loss: 0.0263\n",
            "\n",
            "Average test loss: 0.0585  Accuracy: 9831/10000 (98.31%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0107\n",
            "[12800/60000 ( 21%)]  Loss: 0.0099\n",
            "[25600/60000 ( 43%)]  Loss: 0.0717\n",
            "[38400/60000 ( 64%)]  Loss: 0.0585\n",
            "[51200/60000 ( 85%)]  Loss: 0.0493\n",
            "\n",
            "Average test loss: 0.0582  Accuracy: 9823/10000 (98.23%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0084\n",
            "[12800/60000 ( 21%)]  Loss: 0.0029\n",
            "[25600/60000 ( 43%)]  Loss: 0.0157\n",
            "[38400/60000 ( 64%)]  Loss: 0.0228\n",
            "[51200/60000 ( 85%)]  Loss: 0.0245\n",
            "\n",
            "Average test loss: 0.0611  Accuracy: 9832/10000 (98.32%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0055\n",
            "[12800/60000 ( 21%)]  Loss: 0.0101\n",
            "[25600/60000 ( 43%)]  Loss: 0.0157\n",
            "[38400/60000 ( 64%)]  Loss: 0.0387\n",
            "[51200/60000 ( 85%)]  Loss: 0.0493\n",
            "\n",
            "Average test loss: 0.0740  Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0101\n",
            "[12800/60000 ( 21%)]  Loss: 0.0023\n",
            "[25600/60000 ( 43%)]  Loss: 0.0056\n",
            "[38400/60000 ( 64%)]  Loss: 0.0159\n",
            "[51200/60000 ( 85%)]  Loss: 0.0688\n",
            "\n",
            "Average test loss: 0.0739  Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0025\n",
            "[12800/60000 ( 21%)]  Loss: 0.0210\n",
            "[25600/60000 ( 43%)]  Loss: 0.0064\n",
            "[38400/60000 ( 64%)]  Loss: 0.0052\n",
            "[51200/60000 ( 85%)]  Loss: 0.0320\n",
            "\n",
            "Average test loss: 0.0673  Accuracy: 9839/10000 (98.39%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0008\n",
            "[12800/60000 ( 21%)]  Loss: 0.0008\n",
            "[25600/60000 ( 43%)]  Loss: 0.0112\n",
            "[38400/60000 ( 64%)]  Loss: 0.0021\n",
            "[51200/60000 ( 85%)]  Loss: 0.0052\n",
            "\n",
            "Average test loss: 0.0808  Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0025\n",
            "[12800/60000 ( 21%)]  Loss: 0.0008\n",
            "[25600/60000 ( 43%)]  Loss: 0.0085\n",
            "[38400/60000 ( 64%)]  Loss: 0.0013\n",
            "[51200/60000 ( 85%)]  Loss: 0.0250\n",
            "\n",
            "Average test loss: 0.0698  Accuracy: 9827/10000 (98.27%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0054\n",
            "[12800/60000 ( 21%)]  Loss: 0.0009\n",
            "[25600/60000 ( 43%)]  Loss: 0.0063\n",
            "[38400/60000 ( 64%)]  Loss: 0.0035\n",
            "[51200/60000 ( 85%)]  Loss: 0.0008\n",
            "\n",
            "Average test loss: 0.0722  Accuracy: 9824/10000 (98.24%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0077\n",
            "[12800/60000 ( 21%)]  Loss: 0.0009\n",
            "[25600/60000 ( 43%)]  Loss: 0.0041\n",
            "[38400/60000 ( 64%)]  Loss: 0.0019\n",
            "[51200/60000 ( 85%)]  Loss: 0.0012\n",
            "\n",
            "Average test loss: 0.0710  Accuracy: 9837/10000 (98.37%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0020\n",
            "[12800/60000 ( 21%)]  Loss: 0.0083\n",
            "[25600/60000 ( 43%)]  Loss: 0.0007\n",
            "[38400/60000 ( 64%)]  Loss: 0.0004\n",
            "[51200/60000 ( 85%)]  Loss: 0.0085\n",
            "\n",
            "Average test loss: 0.0711  Accuracy: 9845/10000 (98.45%)\n",
            "\n",
            "Execution time: 225.64 seconds\n",
            "dim 64 depth 4 heads 8 mlp_dim 256\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.4900\n",
            "[12800/60000 ( 21%)]  Loss: 0.8908\n",
            "[25600/60000 ( 43%)]  Loss: 0.3554\n",
            "[38400/60000 ( 64%)]  Loss: 0.2980\n",
            "[51200/60000 ( 85%)]  Loss: 0.1511\n",
            "\n",
            "Average test loss: 0.1964  Accuracy: 9414/10000 (94.14%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.2235\n",
            "[12800/60000 ( 21%)]  Loss: 0.2359\n",
            "[25600/60000 ( 43%)]  Loss: 0.1867\n",
            "[38400/60000 ( 64%)]  Loss: 0.1542\n",
            "[51200/60000 ( 85%)]  Loss: 0.3130\n",
            "\n",
            "Average test loss: 0.1169  Accuracy: 9628/10000 (96.28%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0959\n",
            "[12800/60000 ( 21%)]  Loss: 0.1887\n",
            "[25600/60000 ( 43%)]  Loss: 0.0922\n",
            "[38400/60000 ( 64%)]  Loss: 0.1399\n",
            "[51200/60000 ( 85%)]  Loss: 0.1527\n",
            "\n",
            "Average test loss: 0.0895  Accuracy: 9729/10000 (97.29%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0758\n",
            "[12800/60000 ( 21%)]  Loss: 0.0816\n",
            "[25600/60000 ( 43%)]  Loss: 0.0980\n",
            "[38400/60000 ( 64%)]  Loss: 0.1265\n",
            "[51200/60000 ( 85%)]  Loss: 0.0512\n",
            "\n",
            "Average test loss: 0.0866  Accuracy: 9756/10000 (97.56%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0309\n",
            "[12800/60000 ( 21%)]  Loss: 0.0265\n",
            "[25600/60000 ( 43%)]  Loss: 0.0204\n",
            "[38400/60000 ( 64%)]  Loss: 0.0426\n",
            "[51200/60000 ( 85%)]  Loss: 0.0645\n",
            "\n",
            "Average test loss: 0.0835  Accuracy: 9749/10000 (97.49%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0718\n",
            "[12800/60000 ( 21%)]  Loss: 0.0053\n",
            "[25600/60000 ( 43%)]  Loss: 0.0317\n",
            "[38400/60000 ( 64%)]  Loss: 0.0889\n",
            "[51200/60000 ( 85%)]  Loss: 0.0277\n",
            "\n",
            "Average test loss: 0.0771  Accuracy: 9773/10000 (97.73%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0068\n",
            "[12800/60000 ( 21%)]  Loss: 0.0173\n",
            "[25600/60000 ( 43%)]  Loss: 0.0152\n",
            "[38400/60000 ( 64%)]  Loss: 0.0276\n",
            "[51200/60000 ( 85%)]  Loss: 0.0197\n",
            "\n",
            "Average test loss: 0.0737  Accuracy: 9795/10000 (97.95%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0362\n",
            "[12800/60000 ( 21%)]  Loss: 0.0556\n",
            "[25600/60000 ( 43%)]  Loss: 0.0175\n",
            "[38400/60000 ( 64%)]  Loss: 0.0391\n",
            "[51200/60000 ( 85%)]  Loss: 0.0239\n",
            "\n",
            "Average test loss: 0.0830  Accuracy: 9748/10000 (97.48%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0567\n",
            "[12800/60000 ( 21%)]  Loss: 0.0309\n",
            "[25600/60000 ( 43%)]  Loss: 0.0162\n",
            "[38400/60000 ( 64%)]  Loss: 0.0078\n",
            "[51200/60000 ( 85%)]  Loss: 0.0226\n",
            "\n",
            "Average test loss: 0.0632  Accuracy: 9817/10000 (98.17%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0107\n",
            "[12800/60000 ( 21%)]  Loss: 0.0537\n",
            "[25600/60000 ( 43%)]  Loss: 0.0166\n",
            "[38400/60000 ( 64%)]  Loss: 0.0116\n",
            "[51200/60000 ( 85%)]  Loss: 0.0117\n",
            "\n",
            "Average test loss: 0.0633  Accuracy: 9823/10000 (98.23%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0024\n",
            "[12800/60000 ( 21%)]  Loss: 0.0386\n",
            "[25600/60000 ( 43%)]  Loss: 0.0210\n",
            "[38400/60000 ( 64%)]  Loss: 0.0820\n",
            "[51200/60000 ( 85%)]  Loss: 0.0072\n",
            "\n",
            "Average test loss: 0.0674  Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0029\n",
            "[12800/60000 ( 21%)]  Loss: 0.0221\n",
            "[25600/60000 ( 43%)]  Loss: 0.0094\n",
            "[38400/60000 ( 64%)]  Loss: 0.0060\n",
            "[51200/60000 ( 85%)]  Loss: 0.0028\n",
            "\n",
            "Average test loss: 0.0682  Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0051\n",
            "[12800/60000 ( 21%)]  Loss: 0.0040\n",
            "[25600/60000 ( 43%)]  Loss: 0.0729\n",
            "[38400/60000 ( 64%)]  Loss: 0.0108\n",
            "[51200/60000 ( 85%)]  Loss: 0.0771\n",
            "\n",
            "Average test loss: 0.0791  Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0245\n",
            "[12800/60000 ( 21%)]  Loss: 0.0061\n",
            "[25600/60000 ( 43%)]  Loss: 0.0298\n",
            "[38400/60000 ( 64%)]  Loss: 0.0538\n",
            "[51200/60000 ( 85%)]  Loss: 0.0164\n",
            "\n",
            "Average test loss: 0.0678  Accuracy: 9814/10000 (98.14%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0086\n",
            "[12800/60000 ( 21%)]  Loss: 0.0195\n",
            "[25600/60000 ( 43%)]  Loss: 0.0025\n",
            "[38400/60000 ( 64%)]  Loss: 0.0153\n",
            "[51200/60000 ( 85%)]  Loss: 0.0235\n",
            "\n",
            "Average test loss: 0.0839  Accuracy: 9789/10000 (97.89%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0062\n",
            "[12800/60000 ( 21%)]  Loss: 0.0043\n",
            "[25600/60000 ( 43%)]  Loss: 0.0202\n",
            "[38400/60000 ( 64%)]  Loss: 0.0153\n",
            "[51200/60000 ( 85%)]  Loss: 0.0027\n",
            "\n",
            "Average test loss: 0.0759  Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0214\n",
            "[12800/60000 ( 21%)]  Loss: 0.0015\n",
            "[25600/60000 ( 43%)]  Loss: 0.0097\n",
            "[38400/60000 ( 64%)]  Loss: 0.0060\n",
            "[51200/60000 ( 85%)]  Loss: 0.0169\n",
            "\n",
            "Average test loss: 0.0793  Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0008\n",
            "[12800/60000 ( 21%)]  Loss: 0.0152\n",
            "[25600/60000 ( 43%)]  Loss: 0.0657\n",
            "[38400/60000 ( 64%)]  Loss: 0.0020\n",
            "[51200/60000 ( 85%)]  Loss: 0.0069\n",
            "\n",
            "Average test loss: 0.1020  Accuracy: 9766/10000 (97.66%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0033\n",
            "[12800/60000 ( 21%)]  Loss: 0.0122\n",
            "[25600/60000 ( 43%)]  Loss: 0.0282\n",
            "[38400/60000 ( 64%)]  Loss: 0.0193\n",
            "[51200/60000 ( 85%)]  Loss: 0.0126\n",
            "\n",
            "Average test loss: 0.0745  Accuracy: 9830/10000 (98.30%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0013\n",
            "[12800/60000 ( 21%)]  Loss: 0.0044\n",
            "[25600/60000 ( 43%)]  Loss: 0.0034\n",
            "[38400/60000 ( 64%)]  Loss: 0.0163\n",
            "[51200/60000 ( 85%)]  Loss: 0.0141\n",
            "\n",
            "Average test loss: 0.0815  Accuracy: 9816/10000 (98.16%)\n",
            "\n",
            "Execution time: 225.69 seconds\n",
            "dim 64 depth 4 heads 8 mlp_dim 512\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3326\n",
            "[12800/60000 ( 21%)]  Loss: 1.1033\n",
            "[25600/60000 ( 43%)]  Loss: 0.3807\n",
            "[38400/60000 ( 64%)]  Loss: 0.2331\n",
            "[51200/60000 ( 85%)]  Loss: 0.1897\n",
            "\n",
            "Average test loss: 0.1971  Accuracy: 9348/10000 (93.48%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.1575\n",
            "[12800/60000 ( 21%)]  Loss: 0.1575\n",
            "[25600/60000 ( 43%)]  Loss: 0.2519\n",
            "[38400/60000 ( 64%)]  Loss: 0.2254\n",
            "[51200/60000 ( 85%)]  Loss: 0.2054\n",
            "\n",
            "Average test loss: 0.1509  Accuracy: 9528/10000 (95.28%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1267\n",
            "[12800/60000 ( 21%)]  Loss: 0.1148\n",
            "[25600/60000 ( 43%)]  Loss: 0.1327\n",
            "[38400/60000 ( 64%)]  Loss: 0.1268\n",
            "[51200/60000 ( 85%)]  Loss: 0.1682\n",
            "\n",
            "Average test loss: 0.1027  Accuracy: 9672/10000 (96.72%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0363\n",
            "[12800/60000 ( 21%)]  Loss: 0.1387\n",
            "[25600/60000 ( 43%)]  Loss: 0.1047\n",
            "[38400/60000 ( 64%)]  Loss: 0.0576\n",
            "[51200/60000 ( 85%)]  Loss: 0.0568\n",
            "\n",
            "Average test loss: 0.1137  Accuracy: 9657/10000 (96.57%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.1988\n",
            "[12800/60000 ( 21%)]  Loss: 0.1121\n",
            "[25600/60000 ( 43%)]  Loss: 0.0604\n",
            "[38400/60000 ( 64%)]  Loss: 0.0972\n",
            "[51200/60000 ( 85%)]  Loss: 0.0417\n",
            "\n",
            "Average test loss: 0.0825  Accuracy: 9741/10000 (97.41%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0408\n",
            "[12800/60000 ( 21%)]  Loss: 0.0423\n",
            "[25600/60000 ( 43%)]  Loss: 0.0754\n",
            "[38400/60000 ( 64%)]  Loss: 0.1242\n",
            "[51200/60000 ( 85%)]  Loss: 0.0417\n",
            "\n",
            "Average test loss: 0.0883  Accuracy: 9725/10000 (97.25%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0529\n",
            "[12800/60000 ( 21%)]  Loss: 0.0388\n",
            "[25600/60000 ( 43%)]  Loss: 0.1593\n",
            "[38400/60000 ( 64%)]  Loss: 0.0508\n",
            "[51200/60000 ( 85%)]  Loss: 0.0675\n",
            "\n",
            "Average test loss: 0.0905  Accuracy: 9712/10000 (97.12%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.1966\n",
            "[12800/60000 ( 21%)]  Loss: 0.0199\n",
            "[25600/60000 ( 43%)]  Loss: 0.0365\n",
            "[38400/60000 ( 64%)]  Loss: 0.0179\n",
            "[51200/60000 ( 85%)]  Loss: 0.0171\n",
            "\n",
            "Average test loss: 0.0663  Accuracy: 9797/10000 (97.97%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0378\n",
            "[12800/60000 ( 21%)]  Loss: 0.0109\n",
            "[25600/60000 ( 43%)]  Loss: 0.0411\n",
            "[38400/60000 ( 64%)]  Loss: 0.0131\n",
            "[51200/60000 ( 85%)]  Loss: 0.0167\n",
            "\n",
            "Average test loss: 0.0690  Accuracy: 9790/10000 (97.90%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0202\n",
            "[12800/60000 ( 21%)]  Loss: 0.0364\n",
            "[25600/60000 ( 43%)]  Loss: 0.0355\n",
            "[38400/60000 ( 64%)]  Loss: 0.0610\n",
            "[51200/60000 ( 85%)]  Loss: 0.0083\n",
            "\n",
            "Average test loss: 0.0752  Accuracy: 9791/10000 (97.91%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0395\n",
            "[12800/60000 ( 21%)]  Loss: 0.0415\n",
            "[25600/60000 ( 43%)]  Loss: 0.0064\n",
            "[38400/60000 ( 64%)]  Loss: 0.0360\n",
            "[51200/60000 ( 85%)]  Loss: 0.0641\n",
            "\n",
            "Average test loss: 0.0757  Accuracy: 9786/10000 (97.86%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0039\n",
            "[12800/60000 ( 21%)]  Loss: 0.0353\n",
            "[25600/60000 ( 43%)]  Loss: 0.0179\n",
            "[38400/60000 ( 64%)]  Loss: 0.0441\n",
            "[51200/60000 ( 85%)]  Loss: 0.0992\n",
            "\n",
            "Average test loss: 0.0823  Accuracy: 9759/10000 (97.59%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0621\n",
            "[12800/60000 ( 21%)]  Loss: 0.0106\n",
            "[25600/60000 ( 43%)]  Loss: 0.0072\n",
            "[38400/60000 ( 64%)]  Loss: 0.0030\n",
            "[51200/60000 ( 85%)]  Loss: 0.0180\n",
            "\n",
            "Average test loss: 0.0715  Accuracy: 9818/10000 (98.18%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0143\n",
            "[12800/60000 ( 21%)]  Loss: 0.0298\n",
            "[25600/60000 ( 43%)]  Loss: 0.0069\n",
            "[38400/60000 ( 64%)]  Loss: 0.0382\n",
            "[51200/60000 ( 85%)]  Loss: 0.0015\n",
            "\n",
            "Average test loss: 0.0705  Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0059\n",
            "[12800/60000 ( 21%)]  Loss: 0.0453\n",
            "[25600/60000 ( 43%)]  Loss: 0.0009\n",
            "[38400/60000 ( 64%)]  Loss: 0.0043\n",
            "[51200/60000 ( 85%)]  Loss: 0.0026\n",
            "\n",
            "Average test loss: 0.0749  Accuracy: 9816/10000 (98.16%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0053\n",
            "[12800/60000 ( 21%)]  Loss: 0.0029\n",
            "[25600/60000 ( 43%)]  Loss: 0.0318\n",
            "[38400/60000 ( 64%)]  Loss: 0.0341\n",
            "[51200/60000 ( 85%)]  Loss: 0.0083\n",
            "\n",
            "Average test loss: 0.0750  Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0025\n",
            "[12800/60000 ( 21%)]  Loss: 0.0015\n",
            "[25600/60000 ( 43%)]  Loss: 0.0001\n",
            "[38400/60000 ( 64%)]  Loss: 0.0130\n",
            "[51200/60000 ( 85%)]  Loss: 0.0040\n",
            "\n",
            "Average test loss: 0.0687  Accuracy: 9837/10000 (98.37%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0176\n",
            "[12800/60000 ( 21%)]  Loss: 0.0044\n",
            "[25600/60000 ( 43%)]  Loss: 0.0048\n",
            "[38400/60000 ( 64%)]  Loss: 0.0030\n",
            "[51200/60000 ( 85%)]  Loss: 0.0232\n",
            "\n",
            "Average test loss: 0.0794  Accuracy: 9818/10000 (98.18%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0080\n",
            "[12800/60000 ( 21%)]  Loss: 0.0120\n",
            "[25600/60000 ( 43%)]  Loss: 0.0012\n",
            "[38400/60000 ( 64%)]  Loss: 0.0001\n",
            "[51200/60000 ( 85%)]  Loss: 0.0006\n",
            "\n",
            "Average test loss: 0.0696  Accuracy: 9844/10000 (98.44%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0029\n",
            "[12800/60000 ( 21%)]  Loss: 0.0495\n",
            "[25600/60000 ( 43%)]  Loss: 0.0012\n",
            "[38400/60000 ( 64%)]  Loss: 0.0024\n",
            "[51200/60000 ( 85%)]  Loss: 0.0109\n",
            "\n",
            "Average test loss: 0.0803  Accuracy: 9830/10000 (98.30%)\n",
            "\n",
            "Execution time: 226.25 seconds\n",
            "dim 64 depth 4 heads 16 mlp_dim 128\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.4040\n",
            "[12800/60000 ( 21%)]  Loss: 0.9900\n",
            "[25600/60000 ( 43%)]  Loss: 0.4909\n",
            "[38400/60000 ( 64%)]  Loss: 0.2244\n",
            "[51200/60000 ( 85%)]  Loss: 0.2029\n",
            "\n",
            "Average test loss: 0.2138  Accuracy: 9318/10000 (93.18%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.1254\n",
            "[12800/60000 ( 21%)]  Loss: 0.1538\n",
            "[25600/60000 ( 43%)]  Loss: 0.1379\n",
            "[38400/60000 ( 64%)]  Loss: 0.1355\n",
            "[51200/60000 ( 85%)]  Loss: 0.0870\n",
            "\n",
            "Average test loss: 0.1216  Accuracy: 9633/10000 (96.33%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0897\n",
            "[12800/60000 ( 21%)]  Loss: 0.0999\n",
            "[25600/60000 ( 43%)]  Loss: 0.0899\n",
            "[38400/60000 ( 64%)]  Loss: 0.1093\n",
            "[51200/60000 ( 85%)]  Loss: 0.0972\n",
            "\n",
            "Average test loss: 0.1026  Accuracy: 9666/10000 (96.66%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1318\n",
            "[12800/60000 ( 21%)]  Loss: 0.0813\n",
            "[25600/60000 ( 43%)]  Loss: 0.0579\n",
            "[38400/60000 ( 64%)]  Loss: 0.0517\n",
            "[51200/60000 ( 85%)]  Loss: 0.0583\n",
            "\n",
            "Average test loss: 0.0792  Accuracy: 9764/10000 (97.64%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.1270\n",
            "[12800/60000 ( 21%)]  Loss: 0.0295\n",
            "[25600/60000 ( 43%)]  Loss: 0.0271\n",
            "[38400/60000 ( 64%)]  Loss: 0.0572\n",
            "[51200/60000 ( 85%)]  Loss: 0.1005\n",
            "\n",
            "Average test loss: 0.0757  Accuracy: 9752/10000 (97.52%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0400\n",
            "[12800/60000 ( 21%)]  Loss: 0.0229\n",
            "[25600/60000 ( 43%)]  Loss: 0.0505\n",
            "[38400/60000 ( 64%)]  Loss: 0.0846\n",
            "[51200/60000 ( 85%)]  Loss: 0.0273\n",
            "\n",
            "Average test loss: 0.0740  Accuracy: 9751/10000 (97.51%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0353\n",
            "[12800/60000 ( 21%)]  Loss: 0.0524\n",
            "[25600/60000 ( 43%)]  Loss: 0.0248\n",
            "[38400/60000 ( 64%)]  Loss: 0.0154\n",
            "[51200/60000 ( 85%)]  Loss: 0.0186\n",
            "\n",
            "Average test loss: 0.0904  Accuracy: 9732/10000 (97.32%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0109\n",
            "[12800/60000 ( 21%)]  Loss: 0.0564\n",
            "[25600/60000 ( 43%)]  Loss: 0.0058\n",
            "[38400/60000 ( 64%)]  Loss: 0.0167\n",
            "[51200/60000 ( 85%)]  Loss: 0.0136\n",
            "\n",
            "Average test loss: 0.0863  Accuracy: 9732/10000 (97.32%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.1217\n",
            "[12800/60000 ( 21%)]  Loss: 0.0286\n",
            "[25600/60000 ( 43%)]  Loss: 0.0655\n",
            "[38400/60000 ( 64%)]  Loss: 0.0176\n",
            "[51200/60000 ( 85%)]  Loss: 0.0137\n",
            "\n",
            "Average test loss: 0.0636  Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0161\n",
            "[12800/60000 ( 21%)]  Loss: 0.0074\n",
            "[25600/60000 ( 43%)]  Loss: 0.0469\n",
            "[38400/60000 ( 64%)]  Loss: 0.0061\n",
            "[51200/60000 ( 85%)]  Loss: 0.0063\n",
            "\n",
            "Average test loss: 0.0654  Accuracy: 9822/10000 (98.22%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0127\n",
            "[12800/60000 ( 21%)]  Loss: 0.0441\n",
            "[25600/60000 ( 43%)]  Loss: 0.0127\n",
            "[38400/60000 ( 64%)]  Loss: 0.0121\n",
            "[51200/60000 ( 85%)]  Loss: 0.0347\n",
            "\n",
            "Average test loss: 0.0700  Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0079\n",
            "[12800/60000 ( 21%)]  Loss: 0.0160\n",
            "[25600/60000 ( 43%)]  Loss: 0.0139\n",
            "[38400/60000 ( 64%)]  Loss: 0.0491\n",
            "[51200/60000 ( 85%)]  Loss: 0.0119\n",
            "\n",
            "Average test loss: 0.0745  Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0232\n",
            "[12800/60000 ( 21%)]  Loss: 0.0093\n",
            "[25600/60000 ( 43%)]  Loss: 0.0152\n",
            "[38400/60000 ( 64%)]  Loss: 0.0040\n",
            "[51200/60000 ( 85%)]  Loss: 0.0364\n",
            "\n",
            "Average test loss: 0.0660  Accuracy: 9806/10000 (98.06%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0106\n",
            "[12800/60000 ( 21%)]  Loss: 0.0071\n",
            "[25600/60000 ( 43%)]  Loss: 0.0029\n",
            "[38400/60000 ( 64%)]  Loss: 0.0113\n",
            "[51200/60000 ( 85%)]  Loss: 0.0315\n",
            "\n",
            "Average test loss: 0.0658  Accuracy: 9818/10000 (98.18%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0046\n",
            "[12800/60000 ( 21%)]  Loss: 0.0090\n",
            "[25600/60000 ( 43%)]  Loss: 0.0011\n",
            "[38400/60000 ( 64%)]  Loss: 0.0207\n",
            "[51200/60000 ( 85%)]  Loss: 0.0019\n",
            "\n",
            "Average test loss: 0.0618  Accuracy: 9826/10000 (98.26%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0207\n",
            "[12800/60000 ( 21%)]  Loss: 0.0080\n",
            "[25600/60000 ( 43%)]  Loss: 0.0224\n",
            "[38400/60000 ( 64%)]  Loss: 0.0020\n",
            "[51200/60000 ( 85%)]  Loss: 0.0007\n",
            "\n",
            "Average test loss: 0.0731  Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0082\n",
            "[12800/60000 ( 21%)]  Loss: 0.0074\n",
            "[25600/60000 ( 43%)]  Loss: 0.0008\n",
            "[38400/60000 ( 64%)]  Loss: 0.0006\n",
            "[51200/60000 ( 85%)]  Loss: 0.0025\n",
            "\n",
            "Average test loss: 0.0638  Accuracy: 9852/10000 (98.52%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0009\n",
            "[12800/60000 ( 21%)]  Loss: 0.0039\n",
            "[25600/60000 ( 43%)]  Loss: 0.0078\n",
            "[38400/60000 ( 64%)]  Loss: 0.0279\n",
            "[51200/60000 ( 85%)]  Loss: 0.0012\n",
            "\n",
            "Average test loss: 0.0642  Accuracy: 9833/10000 (98.33%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0025\n",
            "[12800/60000 ( 21%)]  Loss: 0.0091\n",
            "[25600/60000 ( 43%)]  Loss: 0.0008\n",
            "[38400/60000 ( 64%)]  Loss: 0.0114\n",
            "[51200/60000 ( 85%)]  Loss: 0.0103\n",
            "\n",
            "Average test loss: 0.0794  Accuracy: 9825/10000 (98.25%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0030\n",
            "[12800/60000 ( 21%)]  Loss: 0.0057\n",
            "[25600/60000 ( 43%)]  Loss: 0.0044\n",
            "[38400/60000 ( 64%)]  Loss: 0.0011\n",
            "[51200/60000 ( 85%)]  Loss: 0.0009\n",
            "\n",
            "Average test loss: 0.0744  Accuracy: 9822/10000 (98.22%)\n",
            "\n",
            "Execution time: 225.53 seconds\n",
            "dim 64 depth 4 heads 16 mlp_dim 256\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.4080\n",
            "[12800/60000 ( 21%)]  Loss: 1.1617\n",
            "[25600/60000 ( 43%)]  Loss: 0.5660\n",
            "[38400/60000 ( 64%)]  Loss: 0.3524\n",
            "[51200/60000 ( 85%)]  Loss: 0.2875\n",
            "\n",
            "Average test loss: 0.2295  Accuracy: 9260/10000 (92.60%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.2192\n",
            "[12800/60000 ( 21%)]  Loss: 0.2575\n",
            "[25600/60000 ( 43%)]  Loss: 0.1101\n",
            "[38400/60000 ( 64%)]  Loss: 0.1512\n",
            "[51200/60000 ( 85%)]  Loss: 0.0857\n",
            "\n",
            "Average test loss: 0.1283  Accuracy: 9620/10000 (96.20%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0904\n",
            "[12800/60000 ( 21%)]  Loss: 0.1266\n",
            "[25600/60000 ( 43%)]  Loss: 0.0944\n",
            "[38400/60000 ( 64%)]  Loss: 0.0549\n",
            "[51200/60000 ( 85%)]  Loss: 0.0330\n",
            "\n",
            "Average test loss: 0.1134  Accuracy: 9644/10000 (96.44%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1068\n",
            "[12800/60000 ( 21%)]  Loss: 0.1247\n",
            "[25600/60000 ( 43%)]  Loss: 0.0955\n",
            "[38400/60000 ( 64%)]  Loss: 0.0329\n",
            "[51200/60000 ( 85%)]  Loss: 0.1609\n",
            "\n",
            "Average test loss: 0.0833  Accuracy: 9730/10000 (97.30%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0748\n",
            "[12800/60000 ( 21%)]  Loss: 0.0338\n",
            "[25600/60000 ( 43%)]  Loss: 0.0434\n",
            "[38400/60000 ( 64%)]  Loss: 0.0763\n",
            "[51200/60000 ( 85%)]  Loss: 0.0882\n",
            "\n",
            "Average test loss: 0.0731  Accuracy: 9790/10000 (97.90%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0285\n",
            "[12800/60000 ( 21%)]  Loss: 0.0460\n",
            "[25600/60000 ( 43%)]  Loss: 0.0378\n",
            "[38400/60000 ( 64%)]  Loss: 0.1200\n",
            "[51200/60000 ( 85%)]  Loss: 0.0573\n",
            "\n",
            "Average test loss: 0.0736  Accuracy: 9777/10000 (97.77%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0762\n",
            "[12800/60000 ( 21%)]  Loss: 0.0382\n",
            "[25600/60000 ( 43%)]  Loss: 0.0471\n",
            "[38400/60000 ( 64%)]  Loss: 0.0225\n",
            "[51200/60000 ( 85%)]  Loss: 0.0377\n",
            "\n",
            "Average test loss: 0.0654  Accuracy: 9792/10000 (97.92%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0637\n",
            "[12800/60000 ( 21%)]  Loss: 0.0820\n",
            "[25600/60000 ( 43%)]  Loss: 0.0487\n",
            "[38400/60000 ( 64%)]  Loss: 0.0596\n",
            "[51200/60000 ( 85%)]  Loss: 0.0241\n",
            "\n",
            "Average test loss: 0.0858  Accuracy: 9737/10000 (97.37%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0214\n",
            "[12800/60000 ( 21%)]  Loss: 0.0249\n",
            "[25600/60000 ( 43%)]  Loss: 0.0245\n",
            "[38400/60000 ( 64%)]  Loss: 0.0189\n",
            "[51200/60000 ( 85%)]  Loss: 0.0275\n",
            "\n",
            "Average test loss: 0.0713  Accuracy: 9792/10000 (97.92%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0121\n",
            "[12800/60000 ( 21%)]  Loss: 0.0048\n",
            "[25600/60000 ( 43%)]  Loss: 0.0566\n",
            "[38400/60000 ( 64%)]  Loss: 0.0294\n",
            "[51200/60000 ( 85%)]  Loss: 0.0116\n",
            "\n",
            "Average test loss: 0.0648  Accuracy: 9815/10000 (98.15%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0052\n",
            "[12800/60000 ( 21%)]  Loss: 0.0255\n",
            "[25600/60000 ( 43%)]  Loss: 0.0086\n",
            "[38400/60000 ( 64%)]  Loss: 0.0027\n",
            "[51200/60000 ( 85%)]  Loss: 0.0141\n",
            "\n",
            "Average test loss: 0.0573  Accuracy: 9819/10000 (98.19%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0021\n",
            "[12800/60000 ( 21%)]  Loss: 0.0083\n",
            "[25600/60000 ( 43%)]  Loss: 0.0131\n",
            "[38400/60000 ( 64%)]  Loss: 0.0077\n",
            "[51200/60000 ( 85%)]  Loss: 0.0037\n",
            "\n",
            "Average test loss: 0.0571  Accuracy: 9830/10000 (98.30%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0042\n",
            "[12800/60000 ( 21%)]  Loss: 0.0108\n",
            "[25600/60000 ( 43%)]  Loss: 0.0267\n",
            "[38400/60000 ( 64%)]  Loss: 0.0265\n",
            "[51200/60000 ( 85%)]  Loss: 0.0162\n",
            "\n",
            "Average test loss: 0.0660  Accuracy: 9817/10000 (98.17%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0217\n",
            "[12800/60000 ( 21%)]  Loss: 0.0077\n",
            "[25600/60000 ( 43%)]  Loss: 0.0005\n",
            "[38400/60000 ( 64%)]  Loss: 0.0023\n",
            "[51200/60000 ( 85%)]  Loss: 0.0044\n",
            "\n",
            "Average test loss: 0.0616  Accuracy: 9839/10000 (98.39%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0149\n",
            "[12800/60000 ( 21%)]  Loss: 0.0265\n",
            "[25600/60000 ( 43%)]  Loss: 0.0030\n",
            "[38400/60000 ( 64%)]  Loss: 0.0123\n",
            "[51200/60000 ( 85%)]  Loss: 0.0297\n",
            "\n",
            "Average test loss: 0.0626  Accuracy: 9848/10000 (98.48%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0019\n",
            "[12800/60000 ( 21%)]  Loss: 0.0241\n",
            "[25600/60000 ( 43%)]  Loss: 0.0017\n",
            "[38400/60000 ( 64%)]  Loss: 0.0060\n",
            "[51200/60000 ( 85%)]  Loss: 0.0012\n",
            "\n",
            "Average test loss: 0.0592  Accuracy: 9847/10000 (98.47%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0025\n",
            "[12800/60000 ( 21%)]  Loss: 0.0008\n",
            "[25600/60000 ( 43%)]  Loss: 0.0035\n",
            "[38400/60000 ( 64%)]  Loss: 0.0003\n",
            "[51200/60000 ( 85%)]  Loss: 0.0080\n",
            "\n",
            "Average test loss: 0.0776  Accuracy: 9825/10000 (98.25%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0047\n",
            "[12800/60000 ( 21%)]  Loss: 0.0258\n",
            "[25600/60000 ( 43%)]  Loss: 0.0006\n",
            "[38400/60000 ( 64%)]  Loss: 0.0004\n",
            "[51200/60000 ( 85%)]  Loss: 0.0281\n",
            "\n",
            "Average test loss: 0.0770  Accuracy: 9835/10000 (98.35%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0006\n",
            "[12800/60000 ( 21%)]  Loss: 0.0058\n",
            "[25600/60000 ( 43%)]  Loss: 0.0097\n",
            "[38400/60000 ( 64%)]  Loss: 0.0030\n",
            "[51200/60000 ( 85%)]  Loss: 0.0164\n",
            "\n",
            "Average test loss: 0.0730  Accuracy: 9843/10000 (98.43%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0006\n",
            "[12800/60000 ( 21%)]  Loss: 0.0003\n",
            "[25600/60000 ( 43%)]  Loss: 0.0017\n",
            "[38400/60000 ( 64%)]  Loss: 0.0014\n",
            "[51200/60000 ( 85%)]  Loss: 0.0012\n",
            "\n",
            "Average test loss: 0.0679  Accuracy: 9838/10000 (98.38%)\n",
            "\n",
            "Execution time: 225.06 seconds\n",
            "dim 64 depth 4 heads 16 mlp_dim 512\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3162\n",
            "[12800/60000 ( 21%)]  Loss: 1.2228\n",
            "[25600/60000 ( 43%)]  Loss: 0.4832\n",
            "[38400/60000 ( 64%)]  Loss: 0.4902\n",
            "[51200/60000 ( 85%)]  Loss: 0.2428\n",
            "\n",
            "Average test loss: 0.1842  Accuracy: 9422/10000 (94.22%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.2011\n",
            "[12800/60000 ( 21%)]  Loss: 0.2067\n",
            "[25600/60000 ( 43%)]  Loss: 0.1707\n",
            "[38400/60000 ( 64%)]  Loss: 0.2519\n",
            "[51200/60000 ( 85%)]  Loss: 0.1622\n",
            "\n",
            "Average test loss: 0.1260  Accuracy: 9599/10000 (95.99%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1712\n",
            "[12800/60000 ( 21%)]  Loss: 0.1166\n",
            "[25600/60000 ( 43%)]  Loss: 0.1367\n",
            "[38400/60000 ( 64%)]  Loss: 0.1169\n",
            "[51200/60000 ( 85%)]  Loss: 0.0358\n",
            "\n",
            "Average test loss: 0.1094  Accuracy: 9620/10000 (96.20%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0685\n",
            "[12800/60000 ( 21%)]  Loss: 0.0768\n",
            "[25600/60000 ( 43%)]  Loss: 0.1065\n",
            "[38400/60000 ( 64%)]  Loss: 0.0909\n",
            "[51200/60000 ( 85%)]  Loss: 0.0389\n",
            "\n",
            "Average test loss: 0.0825  Accuracy: 9728/10000 (97.28%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.2025\n",
            "[12800/60000 ( 21%)]  Loss: 0.0118\n",
            "[25600/60000 ( 43%)]  Loss: 0.0529\n",
            "[38400/60000 ( 64%)]  Loss: 0.0971\n",
            "[51200/60000 ( 85%)]  Loss: 0.0206\n",
            "\n",
            "Average test loss: 0.0830  Accuracy: 9741/10000 (97.41%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0360\n",
            "[12800/60000 ( 21%)]  Loss: 0.0102\n",
            "[25600/60000 ( 43%)]  Loss: 0.0779\n",
            "[38400/60000 ( 64%)]  Loss: 0.0795\n",
            "[51200/60000 ( 85%)]  Loss: 0.0711\n",
            "\n",
            "Average test loss: 0.0817  Accuracy: 9737/10000 (97.37%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0583\n",
            "[12800/60000 ( 21%)]  Loss: 0.0262\n",
            "[25600/60000 ( 43%)]  Loss: 0.0360\n",
            "[38400/60000 ( 64%)]  Loss: 0.0415\n",
            "[51200/60000 ( 85%)]  Loss: 0.0398\n",
            "\n",
            "Average test loss: 0.0655  Accuracy: 9789/10000 (97.89%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0171\n",
            "[12800/60000 ( 21%)]  Loss: 0.0812\n",
            "[25600/60000 ( 43%)]  Loss: 0.0141\n",
            "[38400/60000 ( 64%)]  Loss: 0.0866\n",
            "[51200/60000 ( 85%)]  Loss: 0.0308\n",
            "\n",
            "Average test loss: 0.0704  Accuracy: 9773/10000 (97.73%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0267\n",
            "[12800/60000 ( 21%)]  Loss: 0.0272\n",
            "[25600/60000 ( 43%)]  Loss: 0.0348\n",
            "[38400/60000 ( 64%)]  Loss: 0.0304\n",
            "[51200/60000 ( 85%)]  Loss: 0.0378\n",
            "\n",
            "Average test loss: 0.0711  Accuracy: 9786/10000 (97.86%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0686\n",
            "[12800/60000 ( 21%)]  Loss: 0.0127\n",
            "[25600/60000 ( 43%)]  Loss: 0.0665\n",
            "[38400/60000 ( 64%)]  Loss: 0.0275\n",
            "[51200/60000 ( 85%)]  Loss: 0.0464\n",
            "\n",
            "Average test loss: 0.0706  Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0112\n",
            "[12800/60000 ( 21%)]  Loss: 0.0108\n",
            "[25600/60000 ( 43%)]  Loss: 0.0127\n",
            "[38400/60000 ( 64%)]  Loss: 0.0313\n",
            "[51200/60000 ( 85%)]  Loss: 0.0211\n",
            "\n",
            "Average test loss: 0.0646  Accuracy: 9801/10000 (98.01%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0021\n",
            "[12800/60000 ( 21%)]  Loss: 0.0095\n",
            "[25600/60000 ( 43%)]  Loss: 0.0121\n",
            "[38400/60000 ( 64%)]  Loss: 0.0086\n",
            "[51200/60000 ( 85%)]  Loss: 0.0276\n",
            "\n",
            "Average test loss: 0.0702  Accuracy: 9790/10000 (97.90%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0147\n",
            "[12800/60000 ( 21%)]  Loss: 0.0111\n",
            "[25600/60000 ( 43%)]  Loss: 0.0007\n",
            "[38400/60000 ( 64%)]  Loss: 0.0204\n",
            "[51200/60000 ( 85%)]  Loss: 0.0144\n",
            "\n",
            "Average test loss: 0.0669  Accuracy: 9832/10000 (98.32%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0029\n",
            "[12800/60000 ( 21%)]  Loss: 0.0016\n",
            "[25600/60000 ( 43%)]  Loss: 0.0024\n",
            "[38400/60000 ( 64%)]  Loss: 0.0353\n",
            "[51200/60000 ( 85%)]  Loss: 0.0179\n",
            "\n",
            "Average test loss: 0.0767  Accuracy: 9817/10000 (98.17%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0050\n",
            "[12800/60000 ( 21%)]  Loss: 0.0115\n",
            "[25600/60000 ( 43%)]  Loss: 0.0018\n",
            "[38400/60000 ( 64%)]  Loss: 0.0117\n",
            "[51200/60000 ( 85%)]  Loss: 0.0062\n",
            "\n",
            "Average test loss: 0.0755  Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0165\n",
            "[12800/60000 ( 21%)]  Loss: 0.0070\n",
            "[25600/60000 ( 43%)]  Loss: 0.0137\n",
            "[38400/60000 ( 64%)]  Loss: 0.0213\n",
            "[51200/60000 ( 85%)]  Loss: 0.0036\n",
            "\n",
            "Average test loss: 0.0644  Accuracy: 9823/10000 (98.23%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0007\n",
            "[12800/60000 ( 21%)]  Loss: 0.0014\n",
            "[25600/60000 ( 43%)]  Loss: 0.0003\n",
            "[38400/60000 ( 64%)]  Loss: 0.0130\n",
            "[51200/60000 ( 85%)]  Loss: 0.0009\n",
            "\n",
            "Average test loss: 0.0589  Accuracy: 9840/10000 (98.40%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0193\n",
            "[12800/60000 ( 21%)]  Loss: 0.0318\n",
            "[25600/60000 ( 43%)]  Loss: 0.0001\n",
            "[38400/60000 ( 64%)]  Loss: 0.0047\n",
            "[51200/60000 ( 85%)]  Loss: 0.0007\n",
            "\n",
            "Average test loss: 0.0693  Accuracy: 9833/10000 (98.33%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0038\n",
            "[12800/60000 ( 21%)]  Loss: 0.0055\n",
            "[25600/60000 ( 43%)]  Loss: 0.0237\n",
            "[38400/60000 ( 64%)]  Loss: 0.0038\n",
            "[51200/60000 ( 85%)]  Loss: 0.0060\n",
            "\n",
            "Average test loss: 0.0724  Accuracy: 9838/10000 (98.38%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0032\n",
            "[12800/60000 ( 21%)]  Loss: 0.0004\n",
            "[25600/60000 ( 43%)]  Loss: 0.0001\n",
            "[38400/60000 ( 64%)]  Loss: 0.0009\n",
            "[51200/60000 ( 85%)]  Loss: 0.0032\n",
            "\n",
            "Average test loss: 0.0695  Accuracy: 9843/10000 (98.43%)\n",
            "\n",
            "Execution time: 226.21 seconds\n",
            "dim 64 depth 6 heads 4 mlp_dim 128\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3580\n",
            "[12800/60000 ( 21%)]  Loss: 0.6623\n",
            "[25600/60000 ( 43%)]  Loss: 0.4475\n",
            "[38400/60000 ( 64%)]  Loss: 0.3829\n",
            "[51200/60000 ( 85%)]  Loss: 0.1007\n",
            "\n",
            "Average test loss: 0.1679  Accuracy: 9473/10000 (94.73%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.1791\n",
            "[12800/60000 ( 21%)]  Loss: 0.0779\n",
            "[25600/60000 ( 43%)]  Loss: 0.2764\n",
            "[38400/60000 ( 64%)]  Loss: 0.0747\n",
            "[51200/60000 ( 85%)]  Loss: 0.0987\n",
            "\n",
            "Average test loss: 0.1068  Accuracy: 9643/10000 (96.43%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0707\n",
            "[12800/60000 ( 21%)]  Loss: 0.1171\n",
            "[25600/60000 ( 43%)]  Loss: 0.0951\n",
            "[38400/60000 ( 64%)]  Loss: 0.1049\n",
            "[51200/60000 ( 85%)]  Loss: 0.0804\n",
            "\n",
            "Average test loss: 0.1048  Accuracy: 9653/10000 (96.53%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0655\n",
            "[12800/60000 ( 21%)]  Loss: 0.0962\n",
            "[25600/60000 ( 43%)]  Loss: 0.0695\n",
            "[38400/60000 ( 64%)]  Loss: 0.0966\n",
            "[51200/60000 ( 85%)]  Loss: 0.0566\n",
            "\n",
            "Average test loss: 0.0874  Accuracy: 9716/10000 (97.16%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0361\n",
            "[12800/60000 ( 21%)]  Loss: 0.0103\n",
            "[25600/60000 ( 43%)]  Loss: 0.0291\n",
            "[38400/60000 ( 64%)]  Loss: 0.0229\n",
            "[51200/60000 ( 85%)]  Loss: 0.0985\n",
            "\n",
            "Average test loss: 0.0872  Accuracy: 9737/10000 (97.37%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0781\n",
            "[12800/60000 ( 21%)]  Loss: 0.0785\n",
            "[25600/60000 ( 43%)]  Loss: 0.0246\n",
            "[38400/60000 ( 64%)]  Loss: 0.0538\n",
            "[51200/60000 ( 85%)]  Loss: 0.0340\n",
            "\n",
            "Average test loss: 0.0712  Accuracy: 9785/10000 (97.85%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0435\n",
            "[12800/60000 ( 21%)]  Loss: 0.0270\n",
            "[25600/60000 ( 43%)]  Loss: 0.0508\n",
            "[38400/60000 ( 64%)]  Loss: 0.0499\n",
            "[51200/60000 ( 85%)]  Loss: 0.0354\n",
            "\n",
            "Average test loss: 0.0756  Accuracy: 9776/10000 (97.76%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0133\n",
            "[12800/60000 ( 21%)]  Loss: 0.0365\n",
            "[25600/60000 ( 43%)]  Loss: 0.0360\n",
            "[38400/60000 ( 64%)]  Loss: 0.0830\n",
            "[51200/60000 ( 85%)]  Loss: 0.0193\n",
            "\n",
            "Average test loss: 0.0723  Accuracy: 9774/10000 (97.74%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0407\n",
            "[12800/60000 ( 21%)]  Loss: 0.0383\n",
            "[25600/60000 ( 43%)]  Loss: 0.0281\n",
            "[38400/60000 ( 64%)]  Loss: 0.0136\n",
            "[51200/60000 ( 85%)]  Loss: 0.0342\n",
            "\n",
            "Average test loss: 0.0633  Accuracy: 9816/10000 (98.16%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0082\n",
            "[12800/60000 ( 21%)]  Loss: 0.0318\n",
            "[25600/60000 ( 43%)]  Loss: 0.0501\n",
            "[38400/60000 ( 64%)]  Loss: 0.0189\n",
            "[51200/60000 ( 85%)]  Loss: 0.0699\n",
            "\n",
            "Average test loss: 0.0714  Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0595\n",
            "[12800/60000 ( 21%)]  Loss: 0.0072\n",
            "[25600/60000 ( 43%)]  Loss: 0.0034\n",
            "[38400/60000 ( 64%)]  Loss: 0.0288\n",
            "[51200/60000 ( 85%)]  Loss: 0.0374\n",
            "\n",
            "Average test loss: 0.0679  Accuracy: 9819/10000 (98.19%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0113\n",
            "[12800/60000 ( 21%)]  Loss: 0.0115\n",
            "[25600/60000 ( 43%)]  Loss: 0.0010\n",
            "[38400/60000 ( 64%)]  Loss: 0.0046\n",
            "[51200/60000 ( 85%)]  Loss: 0.0040\n",
            "\n",
            "Average test loss: 0.0640  Accuracy: 9822/10000 (98.22%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0397\n",
            "[12800/60000 ( 21%)]  Loss: 0.0109\n",
            "[25600/60000 ( 43%)]  Loss: 0.0065\n",
            "[38400/60000 ( 64%)]  Loss: 0.0053\n",
            "[51200/60000 ( 85%)]  Loss: 0.0525\n",
            "\n",
            "Average test loss: 0.0631  Accuracy: 9836/10000 (98.36%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0318\n",
            "[12800/60000 ( 21%)]  Loss: 0.0014\n",
            "[25600/60000 ( 43%)]  Loss: 0.0006\n",
            "[38400/60000 ( 64%)]  Loss: 0.0025\n",
            "[51200/60000 ( 85%)]  Loss: 0.0047\n",
            "\n",
            "Average test loss: 0.0730  Accuracy: 9817/10000 (98.17%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0138\n",
            "[12800/60000 ( 21%)]  Loss: 0.0023\n",
            "[25600/60000 ( 43%)]  Loss: 0.0049\n",
            "[38400/60000 ( 64%)]  Loss: 0.0124\n",
            "[51200/60000 ( 85%)]  Loss: 0.0113\n",
            "\n",
            "Average test loss: 0.0666  Accuracy: 9840/10000 (98.40%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0404\n",
            "[12800/60000 ( 21%)]  Loss: 0.0162\n",
            "[25600/60000 ( 43%)]  Loss: 0.0022\n",
            "[38400/60000 ( 64%)]  Loss: 0.0031\n",
            "[51200/60000 ( 85%)]  Loss: 0.0006\n",
            "\n",
            "Average test loss: 0.0603  Accuracy: 9838/10000 (98.38%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0123\n",
            "[12800/60000 ( 21%)]  Loss: 0.0056\n",
            "[25600/60000 ( 43%)]  Loss: 0.0185\n",
            "[38400/60000 ( 64%)]  Loss: 0.0315\n",
            "[51200/60000 ( 85%)]  Loss: 0.0038\n",
            "\n",
            "Average test loss: 0.0719  Accuracy: 9832/10000 (98.32%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0026\n",
            "[12800/60000 ( 21%)]  Loss: 0.0088\n",
            "[25600/60000 ( 43%)]  Loss: 0.0024\n",
            "[38400/60000 ( 64%)]  Loss: 0.0028\n",
            "[51200/60000 ( 85%)]  Loss: 0.0007\n",
            "\n",
            "Average test loss: 0.0657  Accuracy: 9828/10000 (98.28%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0005\n",
            "[12800/60000 ( 21%)]  Loss: 0.0064\n",
            "[25600/60000 ( 43%)]  Loss: 0.0009\n",
            "[38400/60000 ( 64%)]  Loss: 0.0014\n",
            "[51200/60000 ( 85%)]  Loss: 0.0004\n",
            "\n",
            "Average test loss: 0.0696  Accuracy: 9847/10000 (98.47%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0015\n",
            "[12800/60000 ( 21%)]  Loss: 0.0070\n",
            "[25600/60000 ( 43%)]  Loss: 0.0016\n",
            "[38400/60000 ( 64%)]  Loss: 0.0057\n",
            "[51200/60000 ( 85%)]  Loss: 0.0019\n",
            "\n",
            "Average test loss: 0.0786  Accuracy: 9832/10000 (98.32%)\n",
            "\n",
            "Execution time: 264.33 seconds\n",
            "dim 64 depth 6 heads 4 mlp_dim 256\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3153\n",
            "[12800/60000 ( 21%)]  Loss: 0.8458\n",
            "[25600/60000 ( 43%)]  Loss: 0.3255\n",
            "[38400/60000 ( 64%)]  Loss: 0.3887\n",
            "[51200/60000 ( 85%)]  Loss: 0.2818\n",
            "\n",
            "Average test loss: 0.2034  Accuracy: 9330/10000 (93.30%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.2761\n",
            "[12800/60000 ( 21%)]  Loss: 0.1022\n",
            "[25600/60000 ( 43%)]  Loss: 0.0797\n",
            "[38400/60000 ( 64%)]  Loss: 0.1508\n",
            "[51200/60000 ( 85%)]  Loss: 0.1343\n",
            "\n",
            "Average test loss: 0.1454  Accuracy: 9504/10000 (95.04%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0790\n",
            "[12800/60000 ( 21%)]  Loss: 0.0217\n",
            "[25600/60000 ( 43%)]  Loss: 0.1212\n",
            "[38400/60000 ( 64%)]  Loss: 0.1089\n",
            "[51200/60000 ( 85%)]  Loss: 0.0347\n",
            "\n",
            "Average test loss: 0.1177  Accuracy: 9630/10000 (96.30%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1491\n",
            "[12800/60000 ( 21%)]  Loss: 0.0688\n",
            "[25600/60000 ( 43%)]  Loss: 0.0515\n",
            "[38400/60000 ( 64%)]  Loss: 0.1008\n",
            "[51200/60000 ( 85%)]  Loss: 0.0507\n",
            "\n",
            "Average test loss: 0.0842  Accuracy: 9720/10000 (97.20%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0524\n",
            "[12800/60000 ( 21%)]  Loss: 0.1256\n",
            "[25600/60000 ( 43%)]  Loss: 0.0661\n",
            "[38400/60000 ( 64%)]  Loss: 0.0765\n",
            "[51200/60000 ( 85%)]  Loss: 0.0967\n",
            "\n",
            "Average test loss: 0.0799  Accuracy: 9742/10000 (97.42%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.1241\n",
            "[12800/60000 ( 21%)]  Loss: 0.0715\n",
            "[25600/60000 ( 43%)]  Loss: 0.0448\n",
            "[38400/60000 ( 64%)]  Loss: 0.0547\n",
            "[51200/60000 ( 85%)]  Loss: 0.0831\n",
            "\n",
            "Average test loss: 0.0667  Accuracy: 9806/10000 (98.06%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0286\n",
            "[12800/60000 ( 21%)]  Loss: 0.0210\n",
            "[25600/60000 ( 43%)]  Loss: 0.0540\n",
            "[38400/60000 ( 64%)]  Loss: 0.0176\n",
            "[51200/60000 ( 85%)]  Loss: 0.0723\n",
            "\n",
            "Average test loss: 0.0596  Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0157\n",
            "[12800/60000 ( 21%)]  Loss: 0.0140\n",
            "[25600/60000 ( 43%)]  Loss: 0.0551\n",
            "[38400/60000 ( 64%)]  Loss: 0.0165\n",
            "[51200/60000 ( 85%)]  Loss: 0.0281\n",
            "\n",
            "Average test loss: 0.0598  Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0273\n",
            "[12800/60000 ( 21%)]  Loss: 0.0154\n",
            "[25600/60000 ( 43%)]  Loss: 0.0332\n",
            "[38400/60000 ( 64%)]  Loss: 0.0189\n",
            "[51200/60000 ( 85%)]  Loss: 0.0321\n",
            "\n",
            "Average test loss: 0.0589  Accuracy: 9818/10000 (98.18%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0261\n",
            "[12800/60000 ( 21%)]  Loss: 0.0092\n",
            "[25600/60000 ( 43%)]  Loss: 0.0176\n",
            "[38400/60000 ( 64%)]  Loss: 0.0139\n",
            "[51200/60000 ( 85%)]  Loss: 0.0376\n",
            "\n",
            "Average test loss: 0.0705  Accuracy: 9795/10000 (97.95%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0212\n",
            "[12800/60000 ( 21%)]  Loss: 0.0286\n",
            "[25600/60000 ( 43%)]  Loss: 0.1012\n",
            "[38400/60000 ( 64%)]  Loss: 0.0304\n",
            "[51200/60000 ( 85%)]  Loss: 0.0209\n",
            "\n",
            "Average test loss: 0.0562  Accuracy: 9822/10000 (98.22%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0049\n",
            "[12800/60000 ( 21%)]  Loss: 0.0289\n",
            "[25600/60000 ( 43%)]  Loss: 0.0093\n",
            "[38400/60000 ( 64%)]  Loss: 0.0420\n",
            "[51200/60000 ( 85%)]  Loss: 0.0187\n",
            "\n",
            "Average test loss: 0.0708  Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0273\n",
            "[12800/60000 ( 21%)]  Loss: 0.0110\n",
            "[25600/60000 ( 43%)]  Loss: 0.0447\n",
            "[38400/60000 ( 64%)]  Loss: 0.0225\n",
            "[51200/60000 ( 85%)]  Loss: 0.0068\n",
            "\n",
            "Average test loss: 0.0615  Accuracy: 9828/10000 (98.28%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0145\n",
            "[12800/60000 ( 21%)]  Loss: 0.0227\n",
            "[25600/60000 ( 43%)]  Loss: 0.0094\n",
            "[38400/60000 ( 64%)]  Loss: 0.0045\n",
            "[51200/60000 ( 85%)]  Loss: 0.0075\n",
            "\n",
            "Average test loss: 0.0748  Accuracy: 9825/10000 (98.25%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0026\n",
            "[12800/60000 ( 21%)]  Loss: 0.0049\n",
            "[25600/60000 ( 43%)]  Loss: 0.0070\n",
            "[38400/60000 ( 64%)]  Loss: 0.0053\n",
            "[51200/60000 ( 85%)]  Loss: 0.0131\n",
            "\n",
            "Average test loss: 0.0639  Accuracy: 9841/10000 (98.41%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0063\n",
            "[12800/60000 ( 21%)]  Loss: 0.0153\n",
            "[25600/60000 ( 43%)]  Loss: 0.0061\n",
            "[38400/60000 ( 64%)]  Loss: 0.0137\n",
            "[51200/60000 ( 85%)]  Loss: 0.0254\n",
            "\n",
            "Average test loss: 0.0582  Accuracy: 9843/10000 (98.43%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0019\n",
            "[12800/60000 ( 21%)]  Loss: 0.0031\n",
            "[25600/60000 ( 43%)]  Loss: 0.0412\n",
            "[38400/60000 ( 64%)]  Loss: 0.0211\n",
            "[51200/60000 ( 85%)]  Loss: 0.0033\n",
            "\n",
            "Average test loss: 0.0744  Accuracy: 9828/10000 (98.28%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0069\n",
            "[12800/60000 ( 21%)]  Loss: 0.0011\n",
            "[25600/60000 ( 43%)]  Loss: 0.0215\n",
            "[38400/60000 ( 64%)]  Loss: 0.0015\n",
            "[51200/60000 ( 85%)]  Loss: 0.0013\n",
            "\n",
            "Average test loss: 0.0690  Accuracy: 9840/10000 (98.40%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0006\n",
            "[12800/60000 ( 21%)]  Loss: 0.0064\n",
            "[25600/60000 ( 43%)]  Loss: 0.0034\n",
            "[38400/60000 ( 64%)]  Loss: 0.0012\n",
            "[51200/60000 ( 85%)]  Loss: 0.0014\n",
            "\n",
            "Average test loss: 0.0672  Accuracy: 9838/10000 (98.38%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0006\n",
            "[12800/60000 ( 21%)]  Loss: 0.0001\n",
            "[25600/60000 ( 43%)]  Loss: 0.0008\n",
            "[38400/60000 ( 64%)]  Loss: 0.0111\n",
            "[51200/60000 ( 85%)]  Loss: 0.0142\n",
            "\n",
            "Average test loss: 0.0651  Accuracy: 9854/10000 (98.54%)\n",
            "\n",
            "Execution time: 265.57 seconds\n",
            "dim 64 depth 6 heads 4 mlp_dim 512\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3136\n",
            "[12800/60000 ( 21%)]  Loss: 1.0949\n",
            "[25600/60000 ( 43%)]  Loss: 0.4209\n",
            "[38400/60000 ( 64%)]  Loss: 0.2559\n",
            "[51200/60000 ( 85%)]  Loss: 0.2114\n",
            "\n",
            "Average test loss: 0.2109  Accuracy: 9325/10000 (93.25%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.2715\n",
            "[12800/60000 ( 21%)]  Loss: 0.2082\n",
            "[25600/60000 ( 43%)]  Loss: 0.1964\n",
            "[38400/60000 ( 64%)]  Loss: 0.1358\n",
            "[51200/60000 ( 85%)]  Loss: 0.1890\n",
            "\n",
            "Average test loss: 0.1532  Accuracy: 9511/10000 (95.11%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1350\n",
            "[12800/60000 ( 21%)]  Loss: 0.0711\n",
            "[25600/60000 ( 43%)]  Loss: 0.0687\n",
            "[38400/60000 ( 64%)]  Loss: 0.0345\n",
            "[51200/60000 ( 85%)]  Loss: 0.2228\n",
            "\n",
            "Average test loss: 0.0982  Accuracy: 9695/10000 (96.95%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0347\n",
            "[12800/60000 ( 21%)]  Loss: 0.1016\n",
            "[25600/60000 ( 43%)]  Loss: 0.0989\n",
            "[38400/60000 ( 64%)]  Loss: 0.0598\n",
            "[51200/60000 ( 85%)]  Loss: 0.1148\n",
            "\n",
            "Average test loss: 0.0824  Accuracy: 9754/10000 (97.54%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0069\n",
            "[12800/60000 ( 21%)]  Loss: 0.0510\n",
            "[25600/60000 ( 43%)]  Loss: 0.1384\n",
            "[38400/60000 ( 64%)]  Loss: 0.0594\n",
            "[51200/60000 ( 85%)]  Loss: 0.0714\n",
            "\n",
            "Average test loss: 0.0803  Accuracy: 9761/10000 (97.61%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0493\n",
            "[12800/60000 ( 21%)]  Loss: 0.0488\n",
            "[25600/60000 ( 43%)]  Loss: 0.0549\n",
            "[38400/60000 ( 64%)]  Loss: 0.0162\n",
            "[51200/60000 ( 85%)]  Loss: 0.1342\n",
            "\n",
            "Average test loss: 0.0724  Accuracy: 9771/10000 (97.71%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.1284\n",
            "[12800/60000 ( 21%)]  Loss: 0.0652\n",
            "[25600/60000 ( 43%)]  Loss: 0.0494\n",
            "[38400/60000 ( 64%)]  Loss: 0.0462\n",
            "[51200/60000 ( 85%)]  Loss: 0.0313\n",
            "\n",
            "Average test loss: 0.0729  Accuracy: 9786/10000 (97.86%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0306\n",
            "[12800/60000 ( 21%)]  Loss: 0.0274\n",
            "[25600/60000 ( 43%)]  Loss: 0.0602\n",
            "[38400/60000 ( 64%)]  Loss: 0.0389\n",
            "[51200/60000 ( 85%)]  Loss: 0.0419\n",
            "\n",
            "Average test loss: 0.0718  Accuracy: 9791/10000 (97.91%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0217\n",
            "[12800/60000 ( 21%)]  Loss: 0.0266\n",
            "[25600/60000 ( 43%)]  Loss: 0.0362\n",
            "[38400/60000 ( 64%)]  Loss: 0.0698\n",
            "[51200/60000 ( 85%)]  Loss: 0.0499\n",
            "\n",
            "Average test loss: 0.0656  Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0102\n",
            "[12800/60000 ( 21%)]  Loss: 0.0390\n",
            "[25600/60000 ( 43%)]  Loss: 0.0430\n",
            "[38400/60000 ( 64%)]  Loss: 0.0781\n",
            "[51200/60000 ( 85%)]  Loss: 0.0282\n",
            "\n",
            "Average test loss: 0.0689  Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0585\n",
            "[12800/60000 ( 21%)]  Loss: 0.0058\n",
            "[25600/60000 ( 43%)]  Loss: 0.0255\n",
            "[38400/60000 ( 64%)]  Loss: 0.0058\n",
            "[51200/60000 ( 85%)]  Loss: 0.0209\n",
            "\n",
            "Average test loss: 0.0648  Accuracy: 9825/10000 (98.25%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0073\n",
            "[12800/60000 ( 21%)]  Loss: 0.0035\n",
            "[25600/60000 ( 43%)]  Loss: 0.0246\n",
            "[38400/60000 ( 64%)]  Loss: 0.0137\n",
            "[51200/60000 ( 85%)]  Loss: 0.0367\n",
            "\n",
            "Average test loss: 0.0667  Accuracy: 9827/10000 (98.27%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0690\n",
            "[12800/60000 ( 21%)]  Loss: 0.0068\n",
            "[25600/60000 ( 43%)]  Loss: 0.0175\n",
            "[38400/60000 ( 64%)]  Loss: 0.0301\n",
            "[51200/60000 ( 85%)]  Loss: 0.0031\n",
            "\n",
            "Average test loss: 0.0624  Accuracy: 9840/10000 (98.40%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0897\n",
            "[12800/60000 ( 21%)]  Loss: 0.0030\n",
            "[25600/60000 ( 43%)]  Loss: 0.0035\n",
            "[38400/60000 ( 64%)]  Loss: 0.0037\n",
            "[51200/60000 ( 85%)]  Loss: 0.0295\n",
            "\n",
            "Average test loss: 0.0685  Accuracy: 9834/10000 (98.34%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0114\n",
            "[12800/60000 ( 21%)]  Loss: 0.0145\n",
            "[25600/60000 ( 43%)]  Loss: 0.0030\n",
            "[38400/60000 ( 64%)]  Loss: 0.0107\n",
            "[51200/60000 ( 85%)]  Loss: 0.0012\n",
            "\n",
            "Average test loss: 0.0616  Accuracy: 9850/10000 (98.50%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0306\n",
            "[12800/60000 ( 21%)]  Loss: 0.0097\n",
            "[25600/60000 ( 43%)]  Loss: 0.0192\n",
            "[38400/60000 ( 64%)]  Loss: 0.0027\n",
            "[51200/60000 ( 85%)]  Loss: 0.0238\n",
            "\n",
            "Average test loss: 0.0626  Accuracy: 9834/10000 (98.34%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0074\n",
            "[12800/60000 ( 21%)]  Loss: 0.0012\n",
            "[25600/60000 ( 43%)]  Loss: 0.0146\n",
            "[38400/60000 ( 64%)]  Loss: 0.0150\n",
            "[51200/60000 ( 85%)]  Loss: 0.0028\n",
            "\n",
            "Average test loss: 0.0705  Accuracy: 9829/10000 (98.29%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0008\n",
            "[12800/60000 ( 21%)]  Loss: 0.0013\n",
            "[25600/60000 ( 43%)]  Loss: 0.0043\n",
            "[38400/60000 ( 64%)]  Loss: 0.0012\n",
            "[51200/60000 ( 85%)]  Loss: 0.0004\n",
            "\n",
            "Average test loss: 0.0671  Accuracy: 9838/10000 (98.38%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0101\n",
            "[12800/60000 ( 21%)]  Loss: 0.0005\n",
            "[25600/60000 ( 43%)]  Loss: 0.0018\n",
            "[38400/60000 ( 64%)]  Loss: 0.0003\n",
            "[51200/60000 ( 85%)]  Loss: 0.0129\n",
            "\n",
            "Average test loss: 0.0759  Accuracy: 9819/10000 (98.19%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0131\n",
            "[12800/60000 ( 21%)]  Loss: 0.0370\n",
            "[25600/60000 ( 43%)]  Loss: 0.0010\n",
            "[38400/60000 ( 64%)]  Loss: 0.0015\n",
            "[51200/60000 ( 85%)]  Loss: 0.0005\n",
            "\n",
            "Average test loss: 0.0661  Accuracy: 9843/10000 (98.43%)\n",
            "\n",
            "Execution time: 266.98 seconds\n",
            "dim 64 depth 6 heads 8 mlp_dim 128\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3748\n",
            "[12800/60000 ( 21%)]  Loss: 1.0851\n",
            "[25600/60000 ( 43%)]  Loss: 0.6614\n",
            "[38400/60000 ( 64%)]  Loss: 0.2436\n",
            "[51200/60000 ( 85%)]  Loss: 0.2920\n",
            "\n",
            "Average test loss: 0.1926  Accuracy: 9409/10000 (94.09%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.2210\n",
            "[12800/60000 ( 21%)]  Loss: 0.2809\n",
            "[25600/60000 ( 43%)]  Loss: 0.1585\n",
            "[38400/60000 ( 64%)]  Loss: 0.0817\n",
            "[51200/60000 ( 85%)]  Loss: 0.1834\n",
            "\n",
            "Average test loss: 0.1382  Accuracy: 9581/10000 (95.81%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1292\n",
            "[12800/60000 ( 21%)]  Loss: 0.0896\n",
            "[25600/60000 ( 43%)]  Loss: 0.1445\n",
            "[38400/60000 ( 64%)]  Loss: 0.0715\n",
            "[51200/60000 ( 85%)]  Loss: 0.1075\n",
            "\n",
            "Average test loss: 0.1072  Accuracy: 9657/10000 (96.57%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1412\n",
            "[12800/60000 ( 21%)]  Loss: 0.1574\n",
            "[25600/60000 ( 43%)]  Loss: 0.0403\n",
            "[38400/60000 ( 64%)]  Loss: 0.0277\n",
            "[51200/60000 ( 85%)]  Loss: 0.1478\n",
            "\n",
            "Average test loss: 0.0792  Accuracy: 9735/10000 (97.35%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0702\n",
            "[12800/60000 ( 21%)]  Loss: 0.0278\n",
            "[25600/60000 ( 43%)]  Loss: 0.0620\n",
            "[38400/60000 ( 64%)]  Loss: 0.0571\n",
            "[51200/60000 ( 85%)]  Loss: 0.0556\n",
            "\n",
            "Average test loss: 0.0735  Accuracy: 9777/10000 (97.77%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0983\n",
            "[12800/60000 ( 21%)]  Loss: 0.0629\n",
            "[25600/60000 ( 43%)]  Loss: 0.0426\n",
            "[38400/60000 ( 64%)]  Loss: 0.0114\n",
            "[51200/60000 ( 85%)]  Loss: 0.1075\n",
            "\n",
            "Average test loss: 0.0663  Accuracy: 9792/10000 (97.92%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0705\n",
            "[12800/60000 ( 21%)]  Loss: 0.0547\n",
            "[25600/60000 ( 43%)]  Loss: 0.0461\n",
            "[38400/60000 ( 64%)]  Loss: 0.0793\n",
            "[51200/60000 ( 85%)]  Loss: 0.0810\n",
            "\n",
            "Average test loss: 0.0669  Accuracy: 9802/10000 (98.02%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0212\n",
            "[12800/60000 ( 21%)]  Loss: 0.0592\n",
            "[25600/60000 ( 43%)]  Loss: 0.0571\n",
            "[38400/60000 ( 64%)]  Loss: 0.0462\n",
            "[51200/60000 ( 85%)]  Loss: 0.0466\n",
            "\n",
            "Average test loss: 0.0564  Accuracy: 9829/10000 (98.29%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0303\n",
            "[12800/60000 ( 21%)]  Loss: 0.0138\n",
            "[25600/60000 ( 43%)]  Loss: 0.0128\n",
            "[38400/60000 ( 64%)]  Loss: 0.0296\n",
            "[51200/60000 ( 85%)]  Loss: 0.0317\n",
            "\n",
            "Average test loss: 0.0660  Accuracy: 9788/10000 (97.88%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0598\n",
            "[12800/60000 ( 21%)]  Loss: 0.0553\n",
            "[25600/60000 ( 43%)]  Loss: 0.0715\n",
            "[38400/60000 ( 64%)]  Loss: 0.0093\n",
            "[51200/60000 ( 85%)]  Loss: 0.0564\n",
            "\n",
            "Average test loss: 0.0676  Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0844\n",
            "[12800/60000 ( 21%)]  Loss: 0.0156\n",
            "[25600/60000 ( 43%)]  Loss: 0.0386\n",
            "[38400/60000 ( 64%)]  Loss: 0.0317\n",
            "[51200/60000 ( 85%)]  Loss: 0.0117\n",
            "\n",
            "Average test loss: 0.0572  Accuracy: 9820/10000 (98.20%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0030\n",
            "[12800/60000 ( 21%)]  Loss: 0.0005\n",
            "[25600/60000 ( 43%)]  Loss: 0.0034\n",
            "[38400/60000 ( 64%)]  Loss: 0.0016\n",
            "[51200/60000 ( 85%)]  Loss: 0.0968\n",
            "\n",
            "Average test loss: 0.0591  Accuracy: 9845/10000 (98.45%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0063\n",
            "[12800/60000 ( 21%)]  Loss: 0.0308\n",
            "[25600/60000 ( 43%)]  Loss: 0.0051\n",
            "[38400/60000 ( 64%)]  Loss: 0.0205\n",
            "[51200/60000 ( 85%)]  Loss: 0.0117\n",
            "\n",
            "Average test loss: 0.0679  Accuracy: 9822/10000 (98.22%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0763\n",
            "[12800/60000 ( 21%)]  Loss: 0.0006\n",
            "[25600/60000 ( 43%)]  Loss: 0.0043\n",
            "[38400/60000 ( 64%)]  Loss: 0.0229\n",
            "[51200/60000 ( 85%)]  Loss: 0.0366\n",
            "\n",
            "Average test loss: 0.0675  Accuracy: 9822/10000 (98.22%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0029\n",
            "[12800/60000 ( 21%)]  Loss: 0.0135\n",
            "[25600/60000 ( 43%)]  Loss: 0.0027\n",
            "[38400/60000 ( 64%)]  Loss: 0.0460\n",
            "[51200/60000 ( 85%)]  Loss: 0.0092\n",
            "\n",
            "Average test loss: 0.0608  Accuracy: 9824/10000 (98.24%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0103\n",
            "[12800/60000 ( 21%)]  Loss: 0.0018\n",
            "[25600/60000 ( 43%)]  Loss: 0.0034\n",
            "[38400/60000 ( 64%)]  Loss: 0.0174\n",
            "[51200/60000 ( 85%)]  Loss: 0.0299\n",
            "\n",
            "Average test loss: 0.0648  Accuracy: 9838/10000 (98.38%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0094\n",
            "[12800/60000 ( 21%)]  Loss: 0.0021\n",
            "[25600/60000 ( 43%)]  Loss: 0.0092\n",
            "[38400/60000 ( 64%)]  Loss: 0.0094\n",
            "[51200/60000 ( 85%)]  Loss: 0.0172\n",
            "\n",
            "Average test loss: 0.0666  Accuracy: 9836/10000 (98.36%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0030\n",
            "[12800/60000 ( 21%)]  Loss: 0.0011\n",
            "[25600/60000 ( 43%)]  Loss: 0.0064\n",
            "[38400/60000 ( 64%)]  Loss: 0.0004\n",
            "[51200/60000 ( 85%)]  Loss: 0.0005\n",
            "\n",
            "Average test loss: 0.0641  Accuracy: 9851/10000 (98.51%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0058\n",
            "[12800/60000 ( 21%)]  Loss: 0.0098\n",
            "[25600/60000 ( 43%)]  Loss: 0.0041\n",
            "[38400/60000 ( 64%)]  Loss: 0.0457\n",
            "[51200/60000 ( 85%)]  Loss: 0.0578\n",
            "\n",
            "Average test loss: 0.0640  Accuracy: 9838/10000 (98.38%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0030\n",
            "[12800/60000 ( 21%)]  Loss: 0.0001\n",
            "[25600/60000 ( 43%)]  Loss: 0.0004\n",
            "[38400/60000 ( 64%)]  Loss: 0.0011\n",
            "[51200/60000 ( 85%)]  Loss: 0.0056\n",
            "\n",
            "Average test loss: 0.0592  Accuracy: 9861/10000 (98.61%)\n",
            "\n",
            "Execution time: 264.94 seconds\n",
            "dim 64 depth 6 heads 8 mlp_dim 256\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3668\n",
            "[12800/60000 ( 21%)]  Loss: 1.1194\n",
            "[25600/60000 ( 43%)]  Loss: 0.4510\n",
            "[38400/60000 ( 64%)]  Loss: 0.5358\n",
            "[51200/60000 ( 85%)]  Loss: 0.2477\n",
            "\n",
            "Average test loss: 0.1865  Accuracy: 9413/10000 (94.13%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.0823\n",
            "[12800/60000 ( 21%)]  Loss: 0.1589\n",
            "[25600/60000 ( 43%)]  Loss: 0.1699\n",
            "[38400/60000 ( 64%)]  Loss: 0.1150\n",
            "[51200/60000 ( 85%)]  Loss: 0.1212\n",
            "\n",
            "Average test loss: 0.1428  Accuracy: 9537/10000 (95.37%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1028\n",
            "[12800/60000 ( 21%)]  Loss: 0.0928\n",
            "[25600/60000 ( 43%)]  Loss: 0.0727\n",
            "[38400/60000 ( 64%)]  Loss: 0.0509\n",
            "[51200/60000 ( 85%)]  Loss: 0.1296\n",
            "\n",
            "Average test loss: 0.1067  Accuracy: 9671/10000 (96.71%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0439\n",
            "[12800/60000 ( 21%)]  Loss: 0.0920\n",
            "[25600/60000 ( 43%)]  Loss: 0.0117\n",
            "[38400/60000 ( 64%)]  Loss: 0.1134\n",
            "[51200/60000 ( 85%)]  Loss: 0.0367\n",
            "\n",
            "Average test loss: 0.1072  Accuracy: 9658/10000 (96.58%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0597\n",
            "[12800/60000 ( 21%)]  Loss: 0.0790\n",
            "[25600/60000 ( 43%)]  Loss: 0.0268\n",
            "[38400/60000 ( 64%)]  Loss: 0.0845\n",
            "[51200/60000 ( 85%)]  Loss: 0.0644\n",
            "\n",
            "Average test loss: 0.0770  Accuracy: 9762/10000 (97.62%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0644\n",
            "[12800/60000 ( 21%)]  Loss: 0.0606\n",
            "[25600/60000 ( 43%)]  Loss: 0.0405\n",
            "[38400/60000 ( 64%)]  Loss: 0.0411\n",
            "[51200/60000 ( 85%)]  Loss: 0.0562\n",
            "\n",
            "Average test loss: 0.0758  Accuracy: 9770/10000 (97.70%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0348\n",
            "[12800/60000 ( 21%)]  Loss: 0.1065\n",
            "[25600/60000 ( 43%)]  Loss: 0.0123\n",
            "[38400/60000 ( 64%)]  Loss: 0.0332\n",
            "[51200/60000 ( 85%)]  Loss: 0.0693\n",
            "\n",
            "Average test loss: 0.0793  Accuracy: 9759/10000 (97.59%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0318\n",
            "[12800/60000 ( 21%)]  Loss: 0.0560\n",
            "[25600/60000 ( 43%)]  Loss: 0.0995\n",
            "[38400/60000 ( 64%)]  Loss: 0.0205\n",
            "[51200/60000 ( 85%)]  Loss: 0.0353\n",
            "\n",
            "Average test loss: 0.0774  Accuracy: 9759/10000 (97.59%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0186\n",
            "[12800/60000 ( 21%)]  Loss: 0.0303\n",
            "[25600/60000 ( 43%)]  Loss: 0.0274\n",
            "[38400/60000 ( 64%)]  Loss: 0.0250\n",
            "[51200/60000 ( 85%)]  Loss: 0.0519\n",
            "\n",
            "Average test loss: 0.0621  Accuracy: 9809/10000 (98.09%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0105\n",
            "[12800/60000 ( 21%)]  Loss: 0.0643\n",
            "[25600/60000 ( 43%)]  Loss: 0.0278\n",
            "[38400/60000 ( 64%)]  Loss: 0.0123\n",
            "[51200/60000 ( 85%)]  Loss: 0.0317\n",
            "\n",
            "Average test loss: 0.0721  Accuracy: 9806/10000 (98.06%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0135\n",
            "[12800/60000 ( 21%)]  Loss: 0.0028\n",
            "[25600/60000 ( 43%)]  Loss: 0.0089\n",
            "[38400/60000 ( 64%)]  Loss: 0.0058\n",
            "[51200/60000 ( 85%)]  Loss: 0.0126\n",
            "\n",
            "Average test loss: 0.0722  Accuracy: 9790/10000 (97.90%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0044\n",
            "[12800/60000 ( 21%)]  Loss: 0.0152\n",
            "[25600/60000 ( 43%)]  Loss: 0.0081\n",
            "[38400/60000 ( 64%)]  Loss: 0.0399\n",
            "[51200/60000 ( 85%)]  Loss: 0.0288\n",
            "\n",
            "Average test loss: 0.0677  Accuracy: 9798/10000 (97.98%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0102\n",
            "[12800/60000 ( 21%)]  Loss: 0.0305\n",
            "[25600/60000 ( 43%)]  Loss: 0.0187\n",
            "[38400/60000 ( 64%)]  Loss: 0.0126\n",
            "[51200/60000 ( 85%)]  Loss: 0.0073\n",
            "\n",
            "Average test loss: 0.0650  Accuracy: 9827/10000 (98.27%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0060\n",
            "[12800/60000 ( 21%)]  Loss: 0.0171\n",
            "[25600/60000 ( 43%)]  Loss: 0.0024\n",
            "[38400/60000 ( 64%)]  Loss: 0.0117\n",
            "[51200/60000 ( 85%)]  Loss: 0.0088\n",
            "\n",
            "Average test loss: 0.0848  Accuracy: 9787/10000 (97.87%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0050\n",
            "[12800/60000 ( 21%)]  Loss: 0.0023\n",
            "[25600/60000 ( 43%)]  Loss: 0.0221\n",
            "[38400/60000 ( 64%)]  Loss: 0.0058\n",
            "[51200/60000 ( 85%)]  Loss: 0.0040\n",
            "\n",
            "Average test loss: 0.0630  Accuracy: 9841/10000 (98.41%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0116\n",
            "[12800/60000 ( 21%)]  Loss: 0.0009\n",
            "[25600/60000 ( 43%)]  Loss: 0.0054\n",
            "[38400/60000 ( 64%)]  Loss: 0.0223\n",
            "[51200/60000 ( 85%)]  Loss: 0.0059\n",
            "\n",
            "Average test loss: 0.0766  Accuracy: 9823/10000 (98.23%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0149\n",
            "[12800/60000 ( 21%)]  Loss: 0.0025\n",
            "[25600/60000 ( 43%)]  Loss: 0.0113\n",
            "[38400/60000 ( 64%)]  Loss: 0.0053\n",
            "[51200/60000 ( 85%)]  Loss: 0.0028\n",
            "\n",
            "Average test loss: 0.0679  Accuracy: 9845/10000 (98.45%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0097\n",
            "[12800/60000 ( 21%)]  Loss: 0.0062\n",
            "[25600/60000 ( 43%)]  Loss: 0.0105\n",
            "[38400/60000 ( 64%)]  Loss: 0.0024\n",
            "[51200/60000 ( 85%)]  Loss: 0.0005\n",
            "\n",
            "Average test loss: 0.0764  Accuracy: 9835/10000 (98.35%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0007\n",
            "[12800/60000 ( 21%)]  Loss: 0.0112\n",
            "[25600/60000 ( 43%)]  Loss: 0.0008\n",
            "[38400/60000 ( 64%)]  Loss: 0.0050\n",
            "[51200/60000 ( 85%)]  Loss: 0.0203\n",
            "\n",
            "Average test loss: 0.0616  Accuracy: 9862/10000 (98.62%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0005\n",
            "[12800/60000 ( 21%)]  Loss: 0.0088\n",
            "[25600/60000 ( 43%)]  Loss: 0.0012\n",
            "[38400/60000 ( 64%)]  Loss: 0.0029\n",
            "[51200/60000 ( 85%)]  Loss: 0.0135\n",
            "\n",
            "Average test loss: 0.0681  Accuracy: 9844/10000 (98.44%)\n",
            "\n",
            "Execution time: 265.85 seconds\n",
            "dim 64 depth 6 heads 8 mlp_dim 512\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3647\n",
            "[12800/60000 ( 21%)]  Loss: 0.9164\n",
            "[25600/60000 ( 43%)]  Loss: 0.4850\n",
            "[38400/60000 ( 64%)]  Loss: 0.2901\n",
            "[51200/60000 ( 85%)]  Loss: 0.2072\n",
            "\n",
            "Average test loss: 0.2487  Accuracy: 9226/10000 (92.26%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.2122\n",
            "[12800/60000 ( 21%)]  Loss: 0.1930\n",
            "[25600/60000 ( 43%)]  Loss: 0.1584\n",
            "[38400/60000 ( 64%)]  Loss: 0.1626\n",
            "[51200/60000 ( 85%)]  Loss: 0.1285\n",
            "\n",
            "Average test loss: 0.1495  Accuracy: 9535/10000 (95.35%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1559\n",
            "[12800/60000 ( 21%)]  Loss: 0.0575\n",
            "[25600/60000 ( 43%)]  Loss: 0.1908\n",
            "[38400/60000 ( 64%)]  Loss: 0.1369\n",
            "[51200/60000 ( 85%)]  Loss: 0.1857\n",
            "\n",
            "Average test loss: 0.1268  Accuracy: 9604/10000 (96.04%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1854\n",
            "[12800/60000 ( 21%)]  Loss: 0.0976\n",
            "[25600/60000 ( 43%)]  Loss: 0.1054\n",
            "[38400/60000 ( 64%)]  Loss: 0.0554\n",
            "[51200/60000 ( 85%)]  Loss: 0.0447\n",
            "\n",
            "Average test loss: 0.0854  Accuracy: 9720/10000 (97.20%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0698\n",
            "[12800/60000 ( 21%)]  Loss: 0.1387\n",
            "[25600/60000 ( 43%)]  Loss: 0.0413\n",
            "[38400/60000 ( 64%)]  Loss: 0.1067\n",
            "[51200/60000 ( 85%)]  Loss: 0.0699\n",
            "\n",
            "Average test loss: 0.0806  Accuracy: 9731/10000 (97.31%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0297\n",
            "[12800/60000 ( 21%)]  Loss: 0.0664\n",
            "[25600/60000 ( 43%)]  Loss: 0.0196\n",
            "[38400/60000 ( 64%)]  Loss: 0.0471\n",
            "[51200/60000 ( 85%)]  Loss: 0.0431\n",
            "\n",
            "Average test loss: 0.0802  Accuracy: 9741/10000 (97.41%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0436\n",
            "[12800/60000 ( 21%)]  Loss: 0.0476\n",
            "[25600/60000 ( 43%)]  Loss: 0.0306\n",
            "[38400/60000 ( 64%)]  Loss: 0.0373\n",
            "[51200/60000 ( 85%)]  Loss: 0.0224\n",
            "\n",
            "Average test loss: 0.0839  Accuracy: 9762/10000 (97.62%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0283\n",
            "[12800/60000 ( 21%)]  Loss: 0.0264\n",
            "[25600/60000 ( 43%)]  Loss: 0.0595\n",
            "[38400/60000 ( 64%)]  Loss: 0.0552\n",
            "[51200/60000 ( 85%)]  Loss: 0.0582\n",
            "\n",
            "Average test loss: 0.0722  Accuracy: 9785/10000 (97.85%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0270\n",
            "[12800/60000 ( 21%)]  Loss: 0.0142\n",
            "[25600/60000 ( 43%)]  Loss: 0.0339\n",
            "[38400/60000 ( 64%)]  Loss: 0.0034\n",
            "[51200/60000 ( 85%)]  Loss: 0.0300\n",
            "\n",
            "Average test loss: 0.0728  Accuracy: 9782/10000 (97.82%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0387\n",
            "[12800/60000 ( 21%)]  Loss: 0.0156\n",
            "[25600/60000 ( 43%)]  Loss: 0.0153\n",
            "[38400/60000 ( 64%)]  Loss: 0.0323\n",
            "[51200/60000 ( 85%)]  Loss: 0.0480\n",
            "\n",
            "Average test loss: 0.0718  Accuracy: 9782/10000 (97.82%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0249\n",
            "[12800/60000 ( 21%)]  Loss: 0.0150\n",
            "[25600/60000 ( 43%)]  Loss: 0.0330\n",
            "[38400/60000 ( 64%)]  Loss: 0.0836\n",
            "[51200/60000 ( 85%)]  Loss: 0.0533\n",
            "\n",
            "Average test loss: 0.0665  Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0125\n",
            "[12800/60000 ( 21%)]  Loss: 0.0087\n",
            "[25600/60000 ( 43%)]  Loss: 0.0432\n",
            "[38400/60000 ( 64%)]  Loss: 0.0107\n",
            "[51200/60000 ( 85%)]  Loss: 0.0343\n",
            "\n",
            "Average test loss: 0.0557  Accuracy: 9829/10000 (98.29%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0043\n",
            "[12800/60000 ( 21%)]  Loss: 0.0105\n",
            "[25600/60000 ( 43%)]  Loss: 0.0055\n",
            "[38400/60000 ( 64%)]  Loss: 0.0015\n",
            "[51200/60000 ( 85%)]  Loss: 0.0424\n",
            "\n",
            "Average test loss: 0.0609  Accuracy: 9839/10000 (98.39%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0021\n",
            "[12800/60000 ( 21%)]  Loss: 0.0147\n",
            "[25600/60000 ( 43%)]  Loss: 0.0154\n",
            "[38400/60000 ( 64%)]  Loss: 0.0091\n",
            "[51200/60000 ( 85%)]  Loss: 0.0219\n",
            "\n",
            "Average test loss: 0.0609  Accuracy: 9824/10000 (98.24%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0159\n",
            "[12800/60000 ( 21%)]  Loss: 0.0191\n",
            "[25600/60000 ( 43%)]  Loss: 0.0276\n",
            "[38400/60000 ( 64%)]  Loss: 0.0024\n",
            "[51200/60000 ( 85%)]  Loss: 0.0124\n",
            "\n",
            "Average test loss: 0.0824  Accuracy: 9799/10000 (97.99%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0033\n",
            "[12800/60000 ( 21%)]  Loss: 0.0321\n",
            "[25600/60000 ( 43%)]  Loss: 0.0117\n",
            "[38400/60000 ( 64%)]  Loss: 0.0010\n",
            "[51200/60000 ( 85%)]  Loss: 0.0083\n",
            "\n",
            "Average test loss: 0.0583  Accuracy: 9849/10000 (98.49%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0139\n",
            "[12800/60000 ( 21%)]  Loss: 0.0217\n",
            "[25600/60000 ( 43%)]  Loss: 0.0331\n",
            "[38400/60000 ( 64%)]  Loss: 0.0400\n",
            "[51200/60000 ( 85%)]  Loss: 0.0130\n",
            "\n",
            "Average test loss: 0.0713  Accuracy: 9813/10000 (98.13%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0150\n",
            "[12800/60000 ( 21%)]  Loss: 0.0017\n",
            "[25600/60000 ( 43%)]  Loss: 0.0007\n",
            "[38400/60000 ( 64%)]  Loss: 0.0069\n",
            "[51200/60000 ( 85%)]  Loss: 0.0077\n",
            "\n",
            "Average test loss: 0.0769  Accuracy: 9835/10000 (98.35%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0584\n",
            "[12800/60000 ( 21%)]  Loss: 0.0030\n",
            "[25600/60000 ( 43%)]  Loss: 0.0005\n",
            "[38400/60000 ( 64%)]  Loss: 0.0018\n",
            "[51200/60000 ( 85%)]  Loss: 0.0338\n",
            "\n",
            "Average test loss: 0.0627  Accuracy: 9857/10000 (98.57%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0017\n",
            "[12800/60000 ( 21%)]  Loss: 0.0023\n",
            "[25600/60000 ( 43%)]  Loss: 0.0007\n",
            "[38400/60000 ( 64%)]  Loss: 0.0294\n",
            "[51200/60000 ( 85%)]  Loss: 0.0168\n",
            "\n",
            "Average test loss: 0.0678  Accuracy: 9849/10000 (98.49%)\n",
            "\n",
            "Execution time: 265.01 seconds\n",
            "dim 64 depth 6 heads 16 mlp_dim 128\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3494\n",
            "[12800/60000 ( 21%)]  Loss: 1.0261\n",
            "[25600/60000 ( 43%)]  Loss: 0.4509\n",
            "[38400/60000 ( 64%)]  Loss: 0.4465\n",
            "[51200/60000 ( 85%)]  Loss: 0.1688\n",
            "\n",
            "Average test loss: 0.1995  Accuracy: 9363/10000 (93.63%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.1808\n",
            "[12800/60000 ( 21%)]  Loss: 0.2966\n",
            "[25600/60000 ( 43%)]  Loss: 0.1901\n",
            "[38400/60000 ( 64%)]  Loss: 0.0974\n",
            "[51200/60000 ( 85%)]  Loss: 0.1049\n",
            "\n",
            "Average test loss: 0.1204  Accuracy: 9631/10000 (96.31%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0838\n",
            "[12800/60000 ( 21%)]  Loss: 0.1290\n",
            "[25600/60000 ( 43%)]  Loss: 0.1521\n",
            "[38400/60000 ( 64%)]  Loss: 0.0648\n",
            "[51200/60000 ( 85%)]  Loss: 0.0362\n",
            "\n",
            "Average test loss: 0.0964  Accuracy: 9700/10000 (97.00%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0621\n",
            "[12800/60000 ( 21%)]  Loss: 0.0663\n",
            "[25600/60000 ( 43%)]  Loss: 0.1354\n",
            "[38400/60000 ( 64%)]  Loss: 0.0748\n",
            "[51200/60000 ( 85%)]  Loss: 0.0943\n",
            "\n",
            "Average test loss: 0.0763  Accuracy: 9751/10000 (97.51%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0367\n",
            "[12800/60000 ( 21%)]  Loss: 0.0259\n",
            "[25600/60000 ( 43%)]  Loss: 0.0520\n",
            "[38400/60000 ( 64%)]  Loss: 0.0219\n",
            "[51200/60000 ( 85%)]  Loss: 0.0352\n",
            "\n",
            "Average test loss: 0.0782  Accuracy: 9747/10000 (97.47%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0462\n",
            "[12800/60000 ( 21%)]  Loss: 0.0773\n",
            "[25600/60000 ( 43%)]  Loss: 0.0850\n",
            "[38400/60000 ( 64%)]  Loss: 0.0300\n",
            "[51200/60000 ( 85%)]  Loss: 0.0085\n",
            "\n",
            "Average test loss: 0.0642  Accuracy: 9803/10000 (98.03%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0265\n",
            "[12800/60000 ( 21%)]  Loss: 0.0114\n",
            "[25600/60000 ( 43%)]  Loss: 0.0346\n",
            "[38400/60000 ( 64%)]  Loss: 0.0937\n",
            "[51200/60000 ( 85%)]  Loss: 0.0189\n",
            "\n",
            "Average test loss: 0.0845  Accuracy: 9747/10000 (97.47%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0708\n",
            "[12800/60000 ( 21%)]  Loss: 0.0073\n",
            "[25600/60000 ( 43%)]  Loss: 0.0082\n",
            "[38400/60000 ( 64%)]  Loss: 0.0334\n",
            "[51200/60000 ( 85%)]  Loss: 0.0189\n",
            "\n",
            "Average test loss: 0.0618  Accuracy: 9812/10000 (98.12%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0172\n",
            "[12800/60000 ( 21%)]  Loss: 0.0101\n",
            "[25600/60000 ( 43%)]  Loss: 0.0206\n",
            "[38400/60000 ( 64%)]  Loss: 0.0961\n",
            "[51200/60000 ( 85%)]  Loss: 0.0163\n",
            "\n",
            "Average test loss: 0.0619  Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0145\n",
            "[12800/60000 ( 21%)]  Loss: 0.0072\n",
            "[25600/60000 ( 43%)]  Loss: 0.0471\n",
            "[38400/60000 ( 64%)]  Loss: 0.0099\n",
            "[51200/60000 ( 85%)]  Loss: 0.0110\n",
            "\n",
            "Average test loss: 0.0620  Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0151\n",
            "[12800/60000 ( 21%)]  Loss: 0.0210\n",
            "[25600/60000 ( 43%)]  Loss: 0.0454\n",
            "[38400/60000 ( 64%)]  Loss: 0.0456\n",
            "[51200/60000 ( 85%)]  Loss: 0.0013\n",
            "\n",
            "Average test loss: 0.0615  Accuracy: 9818/10000 (98.18%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0040\n",
            "[12800/60000 ( 21%)]  Loss: 0.0030\n",
            "[25600/60000 ( 43%)]  Loss: 0.0211\n",
            "[38400/60000 ( 64%)]  Loss: 0.0090\n",
            "[51200/60000 ( 85%)]  Loss: 0.0022\n",
            "\n",
            "Average test loss: 0.0644  Accuracy: 9822/10000 (98.22%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0050\n",
            "[12800/60000 ( 21%)]  Loss: 0.0048\n",
            "[25600/60000 ( 43%)]  Loss: 0.0597\n",
            "[38400/60000 ( 64%)]  Loss: 0.0445\n",
            "[51200/60000 ( 85%)]  Loss: 0.0344\n",
            "\n",
            "Average test loss: 0.0584  Accuracy: 9833/10000 (98.33%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0047\n",
            "[12800/60000 ( 21%)]  Loss: 0.0033\n",
            "[25600/60000 ( 43%)]  Loss: 0.0095\n",
            "[38400/60000 ( 64%)]  Loss: 0.0137\n",
            "[51200/60000 ( 85%)]  Loss: 0.0085\n",
            "\n",
            "Average test loss: 0.0639  Accuracy: 9830/10000 (98.30%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0068\n",
            "[12800/60000 ( 21%)]  Loss: 0.0184\n",
            "[25600/60000 ( 43%)]  Loss: 0.0029\n",
            "[38400/60000 ( 64%)]  Loss: 0.0051\n",
            "[51200/60000 ( 85%)]  Loss: 0.0117\n",
            "\n",
            "Average test loss: 0.0659  Accuracy: 9820/10000 (98.20%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0161\n",
            "[12800/60000 ( 21%)]  Loss: 0.0240\n",
            "[25600/60000 ( 43%)]  Loss: 0.0012\n",
            "[38400/60000 ( 64%)]  Loss: 0.0009\n",
            "[51200/60000 ( 85%)]  Loss: 0.0361\n",
            "\n",
            "Average test loss: 0.0659  Accuracy: 9841/10000 (98.41%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0009\n",
            "[12800/60000 ( 21%)]  Loss: 0.0027\n",
            "[25600/60000 ( 43%)]  Loss: 0.0008\n",
            "[38400/60000 ( 64%)]  Loss: 0.0019\n",
            "[51200/60000 ( 85%)]  Loss: 0.0018\n",
            "\n",
            "Average test loss: 0.0743  Accuracy: 9830/10000 (98.30%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0083\n",
            "[12800/60000 ( 21%)]  Loss: 0.0008\n",
            "[25600/60000 ( 43%)]  Loss: 0.0008\n",
            "[38400/60000 ( 64%)]  Loss: 0.0049\n",
            "[51200/60000 ( 85%)]  Loss: 0.0004\n",
            "\n",
            "Average test loss: 0.0648  Accuracy: 9842/10000 (98.42%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0005\n",
            "[12800/60000 ( 21%)]  Loss: 0.0154\n",
            "[25600/60000 ( 43%)]  Loss: 0.0013\n",
            "[38400/60000 ( 64%)]  Loss: 0.0366\n",
            "[51200/60000 ( 85%)]  Loss: 0.0001\n",
            "\n",
            "Average test loss: 0.0758  Accuracy: 9822/10000 (98.22%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0020\n",
            "[12800/60000 ( 21%)]  Loss: 0.0004\n",
            "[25600/60000 ( 43%)]  Loss: 0.0009\n",
            "[38400/60000 ( 64%)]  Loss: 0.0086\n",
            "[51200/60000 ( 85%)]  Loss: 0.0004\n",
            "\n",
            "Average test loss: 0.0684  Accuracy: 9860/10000 (98.60%)\n",
            "\n",
            "Execution time: 265.32 seconds\n",
            "dim 64 depth 6 heads 16 mlp_dim 256\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3641\n",
            "[12800/60000 ( 21%)]  Loss: 1.0959\n",
            "[25600/60000 ( 43%)]  Loss: 0.6679\n",
            "[38400/60000 ( 64%)]  Loss: 0.3111\n",
            "[51200/60000 ( 85%)]  Loss: 0.3438\n",
            "\n",
            "Average test loss: 0.2305  Accuracy: 9269/10000 (92.69%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.2327\n",
            "[12800/60000 ( 21%)]  Loss: 0.0988\n",
            "[25600/60000 ( 43%)]  Loss: 0.1194\n",
            "[38400/60000 ( 64%)]  Loss: 0.2396\n",
            "[51200/60000 ( 85%)]  Loss: 0.2228\n",
            "\n",
            "Average test loss: 0.1593  Accuracy: 9487/10000 (94.87%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1442\n",
            "[12800/60000 ( 21%)]  Loss: 0.1252\n",
            "[25600/60000 ( 43%)]  Loss: 0.1433\n",
            "[38400/60000 ( 64%)]  Loss: 0.0579\n",
            "[51200/60000 ( 85%)]  Loss: 0.1066\n",
            "\n",
            "Average test loss: 0.1077  Accuracy: 9651/10000 (96.51%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0702\n",
            "[12800/60000 ( 21%)]  Loss: 0.1398\n",
            "[25600/60000 ( 43%)]  Loss: 0.1176\n",
            "[38400/60000 ( 64%)]  Loss: 0.0626\n",
            "[51200/60000 ( 85%)]  Loss: 0.1377\n",
            "\n",
            "Average test loss: 0.0912  Accuracy: 9715/10000 (97.15%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.1402\n",
            "[12800/60000 ( 21%)]  Loss: 0.0854\n",
            "[25600/60000 ( 43%)]  Loss: 0.0717\n",
            "[38400/60000 ( 64%)]  Loss: 0.0353\n",
            "[51200/60000 ( 85%)]  Loss: 0.0760\n",
            "\n",
            "Average test loss: 0.0892  Accuracy: 9707/10000 (97.07%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0692\n",
            "[12800/60000 ( 21%)]  Loss: 0.0184\n",
            "[25600/60000 ( 43%)]  Loss: 0.0300\n",
            "[38400/60000 ( 64%)]  Loss: 0.1155\n",
            "[51200/60000 ( 85%)]  Loss: 0.0691\n",
            "\n",
            "Average test loss: 0.0681  Accuracy: 9785/10000 (97.85%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0437\n",
            "[12800/60000 ( 21%)]  Loss: 0.0332\n",
            "[25600/60000 ( 43%)]  Loss: 0.0826\n",
            "[38400/60000 ( 64%)]  Loss: 0.0599\n",
            "[51200/60000 ( 85%)]  Loss: 0.0328\n",
            "\n",
            "Average test loss: 0.0608  Accuracy: 9805/10000 (98.05%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0230\n",
            "[12800/60000 ( 21%)]  Loss: 0.0969\n",
            "[25600/60000 ( 43%)]  Loss: 0.0144\n",
            "[38400/60000 ( 64%)]  Loss: 0.1271\n",
            "[51200/60000 ( 85%)]  Loss: 0.0517\n",
            "\n",
            "Average test loss: 0.0527  Accuracy: 9831/10000 (98.31%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0081\n",
            "[12800/60000 ( 21%)]  Loss: 0.0041\n",
            "[25600/60000 ( 43%)]  Loss: 0.0267\n",
            "[38400/60000 ( 64%)]  Loss: 0.0110\n",
            "[51200/60000 ( 85%)]  Loss: 0.0473\n",
            "\n",
            "Average test loss: 0.0774  Accuracy: 9771/10000 (97.71%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0419\n",
            "[12800/60000 ( 21%)]  Loss: 0.0261\n",
            "[25600/60000 ( 43%)]  Loss: 0.0572\n",
            "[38400/60000 ( 64%)]  Loss: 0.0094\n",
            "[51200/60000 ( 85%)]  Loss: 0.0237\n",
            "\n",
            "Average test loss: 0.0636  Accuracy: 9806/10000 (98.06%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0073\n",
            "[12800/60000 ( 21%)]  Loss: 0.0041\n",
            "[25600/60000 ( 43%)]  Loss: 0.0033\n",
            "[38400/60000 ( 64%)]  Loss: 0.0181\n",
            "[51200/60000 ( 85%)]  Loss: 0.0201\n",
            "\n",
            "Average test loss: 0.0535  Accuracy: 9835/10000 (98.35%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0132\n",
            "[12800/60000 ( 21%)]  Loss: 0.0083\n",
            "[25600/60000 ( 43%)]  Loss: 0.0105\n",
            "[38400/60000 ( 64%)]  Loss: 0.0144\n",
            "[51200/60000 ( 85%)]  Loss: 0.0692\n",
            "\n",
            "Average test loss: 0.0576  Accuracy: 9830/10000 (98.30%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0239\n",
            "[12800/60000 ( 21%)]  Loss: 0.0106\n",
            "[25600/60000 ( 43%)]  Loss: 0.0451\n",
            "[38400/60000 ( 64%)]  Loss: 0.0339\n",
            "[51200/60000 ( 85%)]  Loss: 0.0092\n",
            "\n",
            "Average test loss: 0.0647  Accuracy: 9834/10000 (98.34%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0137\n",
            "[12800/60000 ( 21%)]  Loss: 0.0031\n",
            "[25600/60000 ( 43%)]  Loss: 0.0301\n",
            "[38400/60000 ( 64%)]  Loss: 0.0802\n",
            "[51200/60000 ( 85%)]  Loss: 0.0176\n",
            "\n",
            "Average test loss: 0.0623  Accuracy: 9827/10000 (98.27%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0020\n",
            "[12800/60000 ( 21%)]  Loss: 0.0154\n",
            "[25600/60000 ( 43%)]  Loss: 0.0072\n",
            "[38400/60000 ( 64%)]  Loss: 0.0167\n",
            "[51200/60000 ( 85%)]  Loss: 0.0019\n",
            "\n",
            "Average test loss: 0.0575  Accuracy: 9850/10000 (98.50%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0016\n",
            "[12800/60000 ( 21%)]  Loss: 0.0006\n",
            "[25600/60000 ( 43%)]  Loss: 0.0005\n",
            "[38400/60000 ( 64%)]  Loss: 0.0010\n",
            "[51200/60000 ( 85%)]  Loss: 0.0125\n",
            "\n",
            "Average test loss: 0.0639  Accuracy: 9831/10000 (98.31%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0046\n",
            "[12800/60000 ( 21%)]  Loss: 0.0276\n",
            "[25600/60000 ( 43%)]  Loss: 0.0036\n",
            "[38400/60000 ( 64%)]  Loss: 0.0017\n",
            "[51200/60000 ( 85%)]  Loss: 0.0006\n",
            "\n",
            "Average test loss: 0.0650  Accuracy: 9832/10000 (98.32%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0071\n",
            "[12800/60000 ( 21%)]  Loss: 0.0146\n",
            "[25600/60000 ( 43%)]  Loss: 0.0007\n",
            "[38400/60000 ( 64%)]  Loss: 0.0012\n",
            "[51200/60000 ( 85%)]  Loss: 0.0038\n",
            "\n",
            "Average test loss: 0.0766  Accuracy: 9828/10000 (98.28%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0149\n",
            "[12800/60000 ( 21%)]  Loss: 0.0182\n",
            "[25600/60000 ( 43%)]  Loss: 0.0005\n",
            "[38400/60000 ( 64%)]  Loss: 0.0030\n",
            "[51200/60000 ( 85%)]  Loss: 0.0023\n",
            "\n",
            "Average test loss: 0.0758  Accuracy: 9826/10000 (98.26%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0290\n",
            "[12800/60000 ( 21%)]  Loss: 0.0122\n",
            "[25600/60000 ( 43%)]  Loss: 0.0001\n",
            "[38400/60000 ( 64%)]  Loss: 0.0056\n",
            "[51200/60000 ( 85%)]  Loss: 0.0162\n",
            "\n",
            "Average test loss: 0.0638  Accuracy: 9850/10000 (98.50%)\n",
            "\n",
            "Execution time: 266.27 seconds\n",
            "dim 64 depth 6 heads 16 mlp_dim 512\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3734\n",
            "[12800/60000 ( 21%)]  Loss: 1.6747\n",
            "[25600/60000 ( 43%)]  Loss: 0.6159\n",
            "[38400/60000 ( 64%)]  Loss: 0.3760\n",
            "[51200/60000 ( 85%)]  Loss: 0.2556\n",
            "\n",
            "Average test loss: 0.2908  Accuracy: 9032/10000 (90.32%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.3435\n",
            "[12800/60000 ( 21%)]  Loss: 0.0919\n",
            "[25600/60000 ( 43%)]  Loss: 0.1621\n",
            "[38400/60000 ( 64%)]  Loss: 0.1193\n",
            "[51200/60000 ( 85%)]  Loss: 0.1544\n",
            "\n",
            "Average test loss: 0.1558  Accuracy: 9501/10000 (95.01%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.1343\n",
            "[12800/60000 ( 21%)]  Loss: 0.2134\n",
            "[25600/60000 ( 43%)]  Loss: 0.0937\n",
            "[38400/60000 ( 64%)]  Loss: 0.1249\n",
            "[51200/60000 ( 85%)]  Loss: 0.0786\n",
            "\n",
            "Average test loss: 0.1035  Accuracy: 9662/10000 (96.62%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0681\n",
            "[12800/60000 ( 21%)]  Loss: 0.0869\n",
            "[25600/60000 ( 43%)]  Loss: 0.0935\n",
            "[38400/60000 ( 64%)]  Loss: 0.1124\n",
            "[51200/60000 ( 85%)]  Loss: 0.0549\n",
            "\n",
            "Average test loss: 0.0939  Accuracy: 9697/10000 (96.97%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0855\n",
            "[12800/60000 ( 21%)]  Loss: 0.1319\n",
            "[25600/60000 ( 43%)]  Loss: 0.0722\n",
            "[38400/60000 ( 64%)]  Loss: 0.0225\n",
            "[51200/60000 ( 85%)]  Loss: 0.1210\n",
            "\n",
            "Average test loss: 0.1027  Accuracy: 9682/10000 (96.82%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.1366\n",
            "[12800/60000 ( 21%)]  Loss: 0.1094\n",
            "[25600/60000 ( 43%)]  Loss: 0.0590\n",
            "[38400/60000 ( 64%)]  Loss: 0.1177\n",
            "[51200/60000 ( 85%)]  Loss: 0.0446\n",
            "\n",
            "Average test loss: 0.0743  Accuracy: 9759/10000 (97.59%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0597\n",
            "[12800/60000 ( 21%)]  Loss: 0.0438\n",
            "[25600/60000 ( 43%)]  Loss: 0.0729\n",
            "[38400/60000 ( 64%)]  Loss: 0.0674\n",
            "[51200/60000 ( 85%)]  Loss: 0.0390\n",
            "\n",
            "Average test loss: 0.0655  Accuracy: 9795/10000 (97.95%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0309\n",
            "[12800/60000 ( 21%)]  Loss: 0.0157\n",
            "[25600/60000 ( 43%)]  Loss: 0.0903\n",
            "[38400/60000 ( 64%)]  Loss: 0.0556\n",
            "[51200/60000 ( 85%)]  Loss: 0.0285\n",
            "\n",
            "Average test loss: 0.0738  Accuracy: 9776/10000 (97.76%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0553\n",
            "[12800/60000 ( 21%)]  Loss: 0.0142\n",
            "[25600/60000 ( 43%)]  Loss: 0.0090\n",
            "[38400/60000 ( 64%)]  Loss: 0.0962\n",
            "[51200/60000 ( 85%)]  Loss: 0.0211\n",
            "\n",
            "Average test loss: 0.0687  Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0274\n",
            "[12800/60000 ( 21%)]  Loss: 0.0755\n",
            "[25600/60000 ( 43%)]  Loss: 0.0081\n",
            "[38400/60000 ( 64%)]  Loss: 0.0660\n",
            "[51200/60000 ( 85%)]  Loss: 0.0185\n",
            "\n",
            "Average test loss: 0.0636  Accuracy: 9810/10000 (98.10%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0085\n",
            "[12800/60000 ( 21%)]  Loss: 0.0280\n",
            "[25600/60000 ( 43%)]  Loss: 0.0137\n",
            "[38400/60000 ( 64%)]  Loss: 0.0235\n",
            "[51200/60000 ( 85%)]  Loss: 0.0153\n",
            "\n",
            "Average test loss: 0.0696  Accuracy: 9791/10000 (97.91%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0509\n",
            "[12800/60000 ( 21%)]  Loss: 0.0043\n",
            "[25600/60000 ( 43%)]  Loss: 0.1361\n",
            "[38400/60000 ( 64%)]  Loss: 0.0096\n",
            "[51200/60000 ( 85%)]  Loss: 0.0021\n",
            "\n",
            "Average test loss: 0.0571  Accuracy: 9842/10000 (98.42%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0063\n",
            "[12800/60000 ( 21%)]  Loss: 0.0192\n",
            "[25600/60000 ( 43%)]  Loss: 0.0051\n",
            "[38400/60000 ( 64%)]  Loss: 0.0038\n",
            "[51200/60000 ( 85%)]  Loss: 0.0316\n",
            "\n",
            "Average test loss: 0.0582  Accuracy: 9847/10000 (98.47%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0205\n",
            "[12800/60000 ( 21%)]  Loss: 0.0030\n",
            "[25600/60000 ( 43%)]  Loss: 0.0034\n",
            "[38400/60000 ( 64%)]  Loss: 0.0313\n",
            "[51200/60000 ( 85%)]  Loss: 0.0052\n",
            "\n",
            "Average test loss: 0.0631  Accuracy: 9831/10000 (98.31%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0047\n",
            "[12800/60000 ( 21%)]  Loss: 0.0082\n",
            "[25600/60000 ( 43%)]  Loss: 0.0107\n",
            "[38400/60000 ( 64%)]  Loss: 0.0066\n",
            "[51200/60000 ( 85%)]  Loss: 0.0441\n",
            "\n",
            "Average test loss: 0.0740  Accuracy: 9821/10000 (98.21%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0206\n",
            "[12800/60000 ( 21%)]  Loss: 0.0022\n",
            "[25600/60000 ( 43%)]  Loss: 0.0007\n",
            "[38400/60000 ( 64%)]  Loss: 0.0071\n",
            "[51200/60000 ( 85%)]  Loss: 0.0443\n",
            "\n",
            "Average test loss: 0.0702  Accuracy: 9830/10000 (98.30%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0086\n",
            "[12800/60000 ( 21%)]  Loss: 0.0010\n",
            "[25600/60000 ( 43%)]  Loss: 0.0296\n",
            "[38400/60000 ( 64%)]  Loss: 0.0008\n",
            "[51200/60000 ( 85%)]  Loss: 0.0019\n",
            "\n",
            "Average test loss: 0.0609  Accuracy: 9860/10000 (98.60%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0018\n",
            "[12800/60000 ( 21%)]  Loss: 0.0005\n",
            "[25600/60000 ( 43%)]  Loss: 0.0011\n",
            "[38400/60000 ( 64%)]  Loss: 0.0079\n",
            "[51200/60000 ( 85%)]  Loss: 0.0091\n",
            "\n",
            "Average test loss: 0.0592  Accuracy: 9860/10000 (98.60%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0112\n",
            "[12800/60000 ( 21%)]  Loss: 0.0015\n",
            "[25600/60000 ( 43%)]  Loss: 0.0025\n",
            "[38400/60000 ( 64%)]  Loss: 0.0442\n",
            "[51200/60000 ( 85%)]  Loss: 0.0180\n",
            "\n",
            "Average test loss: 0.0739  Accuracy: 9844/10000 (98.44%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0010\n",
            "[12800/60000 ( 21%)]  Loss: 0.0004\n",
            "[25600/60000 ( 43%)]  Loss: 0.0095\n",
            "[38400/60000 ( 64%)]  Loss: 0.0009\n",
            "[51200/60000 ( 85%)]  Loss: 0.0022\n",
            "\n",
            "Average test loss: 0.0613  Accuracy: 9854/10000 (98.54%)\n",
            "\n",
            "Execution time: 264.70 seconds\n",
            "dim 64 depth 12 heads 4 mlp_dim 128\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3374\n",
            "[12800/60000 ( 21%)]  Loss: 0.7470\n",
            "[25600/60000 ( 43%)]  Loss: 0.4342\n",
            "[38400/60000 ( 64%)]  Loss: 0.2910\n",
            "[51200/60000 ( 85%)]  Loss: 0.1986\n",
            "\n",
            "Average test loss: 0.1919  Accuracy: 9403/10000 (94.03%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.1713\n",
            "[12800/60000 ( 21%)]  Loss: 0.1342\n",
            "[25600/60000 ( 43%)]  Loss: 0.1210\n",
            "[38400/60000 ( 64%)]  Loss: 0.1454\n",
            "[51200/60000 ( 85%)]  Loss: 0.0810\n",
            "\n",
            "Average test loss: 0.1282  Accuracy: 9623/10000 (96.23%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0769\n",
            "[12800/60000 ( 21%)]  Loss: 0.0635\n",
            "[25600/60000 ( 43%)]  Loss: 0.1049\n",
            "[38400/60000 ( 64%)]  Loss: 0.0737\n",
            "[51200/60000 ( 85%)]  Loss: 0.1455\n",
            "\n",
            "Average test loss: 0.0885  Accuracy: 9735/10000 (97.35%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0860\n",
            "[12800/60000 ( 21%)]  Loss: 0.0446\n",
            "[25600/60000 ( 43%)]  Loss: 0.1157\n",
            "[38400/60000 ( 64%)]  Loss: 0.1211\n",
            "[51200/60000 ( 85%)]  Loss: 0.0357\n",
            "\n",
            "Average test loss: 0.0797  Accuracy: 9761/10000 (97.61%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0530\n",
            "[12800/60000 ( 21%)]  Loss: 0.0182\n",
            "[25600/60000 ( 43%)]  Loss: 0.0764\n",
            "[38400/60000 ( 64%)]  Loss: 0.1412\n",
            "[51200/60000 ( 85%)]  Loss: 0.0523\n",
            "\n",
            "Average test loss: 0.0659  Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0352\n",
            "[12800/60000 ( 21%)]  Loss: 0.0214\n",
            "[25600/60000 ( 43%)]  Loss: 0.0239\n",
            "[38400/60000 ( 64%)]  Loss: 0.0551\n",
            "[51200/60000 ( 85%)]  Loss: 0.0541\n",
            "\n",
            "Average test loss: 0.0691  Accuracy: 9800/10000 (98.00%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0334\n",
            "[12800/60000 ( 21%)]  Loss: 0.0427\n",
            "[25600/60000 ( 43%)]  Loss: 0.0778\n",
            "[38400/60000 ( 64%)]  Loss: 0.0231\n",
            "[51200/60000 ( 85%)]  Loss: 0.0425\n",
            "\n",
            "Average test loss: 0.0760  Accuracy: 9786/10000 (97.86%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0457\n",
            "[12800/60000 ( 21%)]  Loss: 0.0321\n",
            "[25600/60000 ( 43%)]  Loss: 0.0584\n",
            "[38400/60000 ( 64%)]  Loss: 0.0600\n",
            "[51200/60000 ( 85%)]  Loss: 0.0291\n",
            "\n",
            "Average test loss: 0.0649  Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0283\n",
            "[12800/60000 ( 21%)]  Loss: 0.0056\n",
            "[25600/60000 ( 43%)]  Loss: 0.0117\n",
            "[38400/60000 ( 64%)]  Loss: 0.0452\n",
            "[51200/60000 ( 85%)]  Loss: 0.0353\n",
            "\n",
            "Average test loss: 0.0648  Accuracy: 9812/10000 (98.12%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0265\n",
            "[12800/60000 ( 21%)]  Loss: 0.0041\n",
            "[25600/60000 ( 43%)]  Loss: 0.0238\n",
            "[38400/60000 ( 64%)]  Loss: 0.0050\n",
            "[51200/60000 ( 85%)]  Loss: 0.0222\n",
            "\n",
            "Average test loss: 0.0566  Accuracy: 9829/10000 (98.29%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0121\n",
            "[12800/60000 ( 21%)]  Loss: 0.0142\n",
            "[25600/60000 ( 43%)]  Loss: 0.0610\n",
            "[38400/60000 ( 64%)]  Loss: 0.0182\n",
            "[51200/60000 ( 85%)]  Loss: 0.0213\n",
            "\n",
            "Average test loss: 0.0610  Accuracy: 9824/10000 (98.24%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0218\n",
            "[12800/60000 ( 21%)]  Loss: 0.0314\n",
            "[25600/60000 ( 43%)]  Loss: 0.0036\n",
            "[38400/60000 ( 64%)]  Loss: 0.0016\n",
            "[51200/60000 ( 85%)]  Loss: 0.0209\n",
            "\n",
            "Average test loss: 0.0612  Accuracy: 9837/10000 (98.37%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0157\n",
            "[12800/60000 ( 21%)]  Loss: 0.0017\n",
            "[25600/60000 ( 43%)]  Loss: 0.0056\n",
            "[38400/60000 ( 64%)]  Loss: 0.0134\n",
            "[51200/60000 ( 85%)]  Loss: 0.0241\n",
            "\n",
            "Average test loss: 0.0611  Accuracy: 9841/10000 (98.41%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0214\n",
            "[12800/60000 ( 21%)]  Loss: 0.0234\n",
            "[25600/60000 ( 43%)]  Loss: 0.0033\n",
            "[38400/60000 ( 64%)]  Loss: 0.0062\n",
            "[51200/60000 ( 85%)]  Loss: 0.0432\n",
            "\n",
            "Average test loss: 0.0697  Accuracy: 9833/10000 (98.33%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0101\n",
            "[12800/60000 ( 21%)]  Loss: 0.0015\n",
            "[25600/60000 ( 43%)]  Loss: 0.0246\n",
            "[38400/60000 ( 64%)]  Loss: 0.0188\n",
            "[51200/60000 ( 85%)]  Loss: 0.0035\n",
            "\n",
            "Average test loss: 0.0704  Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0032\n",
            "[12800/60000 ( 21%)]  Loss: 0.0072\n",
            "[25600/60000 ( 43%)]  Loss: 0.0067\n",
            "[38400/60000 ( 64%)]  Loss: 0.0017\n",
            "[51200/60000 ( 85%)]  Loss: 0.0089\n",
            "\n",
            "Average test loss: 0.0771  Accuracy: 9828/10000 (98.28%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0041\n",
            "[12800/60000 ( 21%)]  Loss: 0.0017\n",
            "[25600/60000 ( 43%)]  Loss: 0.0004\n",
            "[38400/60000 ( 64%)]  Loss: 0.0099\n",
            "[51200/60000 ( 85%)]  Loss: 0.0011\n",
            "\n",
            "Average test loss: 0.0715  Accuracy: 9842/10000 (98.42%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0008\n",
            "[12800/60000 ( 21%)]  Loss: 0.0043\n",
            "[25600/60000 ( 43%)]  Loss: 0.0007\n",
            "[38400/60000 ( 64%)]  Loss: 0.0571\n",
            "[51200/60000 ( 85%)]  Loss: 0.0058\n",
            "\n",
            "Average test loss: 0.0654  Accuracy: 9851/10000 (98.51%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0054\n",
            "[12800/60000 ( 21%)]  Loss: 0.0019\n",
            "[25600/60000 ( 43%)]  Loss: 0.0008\n",
            "[38400/60000 ( 64%)]  Loss: 0.0169\n",
            "[51200/60000 ( 85%)]  Loss: 0.0203\n",
            "\n",
            "Average test loss: 0.0631  Accuracy: 9859/10000 (98.59%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0173\n",
            "[12800/60000 ( 21%)]  Loss: 0.0049\n",
            "[25600/60000 ( 43%)]  Loss: 0.0008\n",
            "[38400/60000 ( 64%)]  Loss: 0.0007\n",
            "[51200/60000 ( 85%)]  Loss: 0.0003\n",
            "\n",
            "Average test loss: 0.0707  Accuracy: 9839/10000 (98.39%)\n",
            "\n",
            "Execution time: 382.95 seconds\n",
            "dim 64 depth 12 heads 4 mlp_dim 256\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3372\n",
            "[12800/60000 ( 21%)]  Loss: 1.1000\n",
            "[25600/60000 ( 43%)]  Loss: 0.5242\n",
            "[38400/60000 ( 64%)]  Loss: 0.3652\n",
            "[51200/60000 ( 85%)]  Loss: 0.2805\n",
            "\n",
            "Average test loss: 0.1956  Accuracy: 9356/10000 (93.56%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.3118\n",
            "[12800/60000 ( 21%)]  Loss: 0.3717\n",
            "[25600/60000 ( 43%)]  Loss: 0.1529\n",
            "[38400/60000 ( 64%)]  Loss: 0.1138\n",
            "[51200/60000 ( 85%)]  Loss: 0.0885\n",
            "\n",
            "Average test loss: 0.1264  Accuracy: 9604/10000 (96.04%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0713\n",
            "[12800/60000 ( 21%)]  Loss: 0.1421\n",
            "[25600/60000 ( 43%)]  Loss: 0.0932\n",
            "[38400/60000 ( 64%)]  Loss: 0.0570\n",
            "[51200/60000 ( 85%)]  Loss: 0.1389\n",
            "\n",
            "Average test loss: 0.1010  Accuracy: 9690/10000 (96.90%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1075\n",
            "[12800/60000 ( 21%)]  Loss: 0.1335\n",
            "[25600/60000 ( 43%)]  Loss: 0.0527\n",
            "[38400/60000 ( 64%)]  Loss: 0.1957\n",
            "[51200/60000 ( 85%)]  Loss: 0.0716\n",
            "\n",
            "Average test loss: 0.0862  Accuracy: 9725/10000 (97.25%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0555\n",
            "[12800/60000 ( 21%)]  Loss: 0.0842\n",
            "[25600/60000 ( 43%)]  Loss: 0.0366\n",
            "[38400/60000 ( 64%)]  Loss: 0.0242\n",
            "[51200/60000 ( 85%)]  Loss: 0.0824\n",
            "\n",
            "Average test loss: 0.0888  Accuracy: 9721/10000 (97.21%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.1359\n",
            "[12800/60000 ( 21%)]  Loss: 0.0120\n",
            "[25600/60000 ( 43%)]  Loss: 0.0517\n",
            "[38400/60000 ( 64%)]  Loss: 0.0416\n",
            "[51200/60000 ( 85%)]  Loss: 0.0339\n",
            "\n",
            "Average test loss: 0.0681  Accuracy: 9783/10000 (97.83%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0960\n",
            "[12800/60000 ( 21%)]  Loss: 0.0072\n",
            "[25600/60000 ( 43%)]  Loss: 0.0099\n",
            "[38400/60000 ( 64%)]  Loss: 0.0152\n",
            "[51200/60000 ( 85%)]  Loss: 0.0789\n",
            "\n",
            "Average test loss: 0.0626  Accuracy: 9816/10000 (98.16%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0884\n",
            "[12800/60000 ( 21%)]  Loss: 0.0472\n",
            "[25600/60000 ( 43%)]  Loss: 0.0404\n",
            "[38400/60000 ( 64%)]  Loss: 0.1392\n",
            "[51200/60000 ( 85%)]  Loss: 0.0103\n",
            "\n",
            "Average test loss: 0.0602  Accuracy: 9829/10000 (98.29%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0061\n",
            "[12800/60000 ( 21%)]  Loss: 0.0763\n",
            "[25600/60000 ( 43%)]  Loss: 0.0535\n",
            "[38400/60000 ( 64%)]  Loss: 0.0510\n",
            "[51200/60000 ( 85%)]  Loss: 0.0216\n",
            "\n",
            "Average test loss: 0.0678  Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0152\n",
            "[12800/60000 ( 21%)]  Loss: 0.0494\n",
            "[25600/60000 ( 43%)]  Loss: 0.0758\n",
            "[38400/60000 ( 64%)]  Loss: 0.0184\n",
            "[51200/60000 ( 85%)]  Loss: 0.0765\n",
            "\n",
            "Average test loss: 0.0615  Accuracy: 9822/10000 (98.22%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0561\n",
            "[12800/60000 ( 21%)]  Loss: 0.0040\n",
            "[25600/60000 ( 43%)]  Loss: 0.0653\n",
            "[38400/60000 ( 64%)]  Loss: 0.0210\n",
            "[51200/60000 ( 85%)]  Loss: 0.0412\n",
            "\n",
            "Average test loss: 0.0605  Accuracy: 9829/10000 (98.29%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0244\n",
            "[12800/60000 ( 21%)]  Loss: 0.0101\n",
            "[25600/60000 ( 43%)]  Loss: 0.0051\n",
            "[38400/60000 ( 64%)]  Loss: 0.0284\n",
            "[51200/60000 ( 85%)]  Loss: 0.0392\n",
            "\n",
            "Average test loss: 0.0731  Accuracy: 9801/10000 (98.01%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0510\n",
            "[12800/60000 ( 21%)]  Loss: 0.0067\n",
            "[25600/60000 ( 43%)]  Loss: 0.0234\n",
            "[38400/60000 ( 64%)]  Loss: 0.0006\n",
            "[51200/60000 ( 85%)]  Loss: 0.0458\n",
            "\n",
            "Average test loss: 0.0719  Accuracy: 9808/10000 (98.08%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0360\n",
            "[12800/60000 ( 21%)]  Loss: 0.0252\n",
            "[25600/60000 ( 43%)]  Loss: 0.0029\n",
            "[38400/60000 ( 64%)]  Loss: 0.0361\n",
            "[51200/60000 ( 85%)]  Loss: 0.0315\n",
            "\n",
            "Average test loss: 0.0793  Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0497\n",
            "[12800/60000 ( 21%)]  Loss: 0.0040\n",
            "[25600/60000 ( 43%)]  Loss: 0.0022\n",
            "[38400/60000 ( 64%)]  Loss: 0.0079\n",
            "[51200/60000 ( 85%)]  Loss: 0.0215\n",
            "\n",
            "Average test loss: 0.0635  Accuracy: 9844/10000 (98.44%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0033\n",
            "[12800/60000 ( 21%)]  Loss: 0.0034\n",
            "[25600/60000 ( 43%)]  Loss: 0.0119\n",
            "[38400/60000 ( 64%)]  Loss: 0.0079\n",
            "[51200/60000 ( 85%)]  Loss: 0.0068\n",
            "\n",
            "Average test loss: 0.0589  Accuracy: 9856/10000 (98.56%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0053\n",
            "[12800/60000 ( 21%)]  Loss: 0.0333\n",
            "[25600/60000 ( 43%)]  Loss: 0.0002\n",
            "[38400/60000 ( 64%)]  Loss: 0.0022\n",
            "[51200/60000 ( 85%)]  Loss: 0.0013\n",
            "\n",
            "Average test loss: 0.0754  Accuracy: 9839/10000 (98.39%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0003\n",
            "[12800/60000 ( 21%)]  Loss: 0.0011\n",
            "[25600/60000 ( 43%)]  Loss: 0.0004\n",
            "[38400/60000 ( 64%)]  Loss: 0.0233\n",
            "[51200/60000 ( 85%)]  Loss: 0.0180\n",
            "\n",
            "Average test loss: 0.0653  Accuracy: 9844/10000 (98.44%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0096\n",
            "[12800/60000 ( 21%)]  Loss: 0.0023\n",
            "[25600/60000 ( 43%)]  Loss: 0.0033\n",
            "[38400/60000 ( 64%)]  Loss: 0.0006\n",
            "[51200/60000 ( 85%)]  Loss: 0.0230\n",
            "\n",
            "Average test loss: 0.0813  Accuracy: 9835/10000 (98.35%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0011\n",
            "[12800/60000 ( 21%)]  Loss: 0.0199\n",
            "[25600/60000 ( 43%)]  Loss: 0.0010\n",
            "[38400/60000 ( 64%)]  Loss: 0.0018\n",
            "[51200/60000 ( 85%)]  Loss: 0.0272\n",
            "\n",
            "Average test loss: 0.0680  Accuracy: 9857/10000 (98.57%)\n",
            "\n",
            "Execution time: 384.96 seconds\n",
            "dim 64 depth 12 heads 4 mlp_dim 512\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3022\n",
            "[12800/60000 ( 21%)]  Loss: 0.7778\n",
            "[25600/60000 ( 43%)]  Loss: 0.3756\n",
            "[38400/60000 ( 64%)]  Loss: 0.2999\n",
            "[51200/60000 ( 85%)]  Loss: 0.3117\n",
            "\n",
            "Average test loss: 0.2088  Accuracy: 9354/10000 (93.54%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.1869\n",
            "[12800/60000 ( 21%)]  Loss: 0.1612\n",
            "[25600/60000 ( 43%)]  Loss: 0.1857\n",
            "[38400/60000 ( 64%)]  Loss: 0.1102\n",
            "[51200/60000 ( 85%)]  Loss: 0.0639\n",
            "\n",
            "Average test loss: 0.1316  Accuracy: 9601/10000 (96.01%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0918\n",
            "[12800/60000 ( 21%)]  Loss: 0.0711\n",
            "[25600/60000 ( 43%)]  Loss: 0.0720\n",
            "[38400/60000 ( 64%)]  Loss: 0.1395\n",
            "[51200/60000 ( 85%)]  Loss: 0.0437\n",
            "\n",
            "Average test loss: 0.0881  Accuracy: 9732/10000 (97.32%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.1039\n",
            "[12800/60000 ( 21%)]  Loss: 0.0648\n",
            "[25600/60000 ( 43%)]  Loss: 0.0674\n",
            "[38400/60000 ( 64%)]  Loss: 0.1027\n",
            "[51200/60000 ( 85%)]  Loss: 0.2181\n",
            "\n",
            "Average test loss: 0.0802  Accuracy: 9768/10000 (97.68%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0549\n",
            "[12800/60000 ( 21%)]  Loss: 0.0778\n",
            "[25600/60000 ( 43%)]  Loss: 0.0779\n",
            "[38400/60000 ( 64%)]  Loss: 0.0296\n",
            "[51200/60000 ( 85%)]  Loss: 0.0409\n",
            "\n",
            "Average test loss: 0.0682  Accuracy: 9792/10000 (97.92%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0383\n",
            "[12800/60000 ( 21%)]  Loss: 0.0840\n",
            "[25600/60000 ( 43%)]  Loss: 0.0341\n",
            "[38400/60000 ( 64%)]  Loss: 0.0490\n",
            "[51200/60000 ( 85%)]  Loss: 0.0564\n",
            "\n",
            "Average test loss: 0.0775  Accuracy: 9766/10000 (97.66%)\n",
            "\n",
            "Epoch: 7 LR: [0.0007350918906249997]\n",
            "[    0/60000 (  0%)]  Loss: 0.0635\n",
            "[12800/60000 ( 21%)]  Loss: 0.0362\n",
            "[25600/60000 ( 43%)]  Loss: 0.0152\n",
            "[38400/60000 ( 64%)]  Loss: 0.0776\n",
            "[51200/60000 ( 85%)]  Loss: 0.0146\n",
            "\n",
            "Average test loss: 0.0678  Accuracy: 9793/10000 (97.93%)\n",
            "\n",
            "Epoch: 8 LR: [0.0006983372960937497]\n",
            "[    0/60000 (  0%)]  Loss: 0.0050\n",
            "[12800/60000 ( 21%)]  Loss: 0.0476\n",
            "[25600/60000 ( 43%)]  Loss: 0.0239\n",
            "[38400/60000 ( 64%)]  Loss: 0.0798\n",
            "[51200/60000 ( 85%)]  Loss: 0.0846\n",
            "\n",
            "Average test loss: 0.0781  Accuracy: 9763/10000 (97.63%)\n",
            "\n",
            "Epoch: 9 LR: [0.0006634204312890621]\n",
            "[    0/60000 (  0%)]  Loss: 0.0520\n",
            "[12800/60000 ( 21%)]  Loss: 0.0122\n",
            "[25600/60000 ( 43%)]  Loss: 0.0588\n",
            "[38400/60000 ( 64%)]  Loss: 0.0136\n",
            "[51200/60000 ( 85%)]  Loss: 0.0453\n",
            "\n",
            "Average test loss: 0.0740  Accuracy: 9796/10000 (97.96%)\n",
            "\n",
            "Epoch: 10 LR: [0.000630249409724609]\n",
            "[    0/60000 (  0%)]  Loss: 0.0627\n",
            "[12800/60000 ( 21%)]  Loss: 0.0644\n",
            "[25600/60000 ( 43%)]  Loss: 0.0369\n",
            "[38400/60000 ( 64%)]  Loss: 0.0900\n",
            "[51200/60000 ( 85%)]  Loss: 0.0506\n",
            "\n",
            "Average test loss: 0.0664  Accuracy: 9817/10000 (98.17%)\n",
            "\n",
            "Epoch: 11 LR: [0.0005987369392383785]\n",
            "[    0/60000 (  0%)]  Loss: 0.0118\n",
            "[12800/60000 ( 21%)]  Loss: 0.0021\n",
            "[25600/60000 ( 43%)]  Loss: 0.0088\n",
            "[38400/60000 ( 64%)]  Loss: 0.0537\n",
            "[51200/60000 ( 85%)]  Loss: 0.0249\n",
            "\n",
            "Average test loss: 0.0885  Accuracy: 9765/10000 (97.65%)\n",
            "\n",
            "Epoch: 12 LR: [0.0005688000922764595]\n",
            "[    0/60000 (  0%)]  Loss: 0.0355\n",
            "[12800/60000 ( 21%)]  Loss: 0.0107\n",
            "[25600/60000 ( 43%)]  Loss: 0.0081\n",
            "[38400/60000 ( 64%)]  Loss: 0.0024\n",
            "[51200/60000 ( 85%)]  Loss: 0.0307\n",
            "\n",
            "Average test loss: 0.0669  Accuracy: 9823/10000 (98.23%)\n",
            "\n",
            "Epoch: 13 LR: [0.0005403600876626365]\n",
            "[    0/60000 (  0%)]  Loss: 0.0419\n",
            "[12800/60000 ( 21%)]  Loss: 0.0231\n",
            "[25600/60000 ( 43%)]  Loss: 0.0266\n",
            "[38400/60000 ( 64%)]  Loss: 0.0807\n",
            "[51200/60000 ( 85%)]  Loss: 0.0056\n",
            "\n",
            "Average test loss: 0.0616  Accuracy: 9845/10000 (98.45%)\n",
            "\n",
            "Epoch: 14 LR: [0.0005133420832795047]\n",
            "[    0/60000 (  0%)]  Loss: 0.0352\n",
            "[12800/60000 ( 21%)]  Loss: 0.0236\n",
            "[25600/60000 ( 43%)]  Loss: 0.0170\n",
            "[38400/60000 ( 64%)]  Loss: 0.0025\n",
            "[51200/60000 ( 85%)]  Loss: 0.0086\n",
            "\n",
            "Average test loss: 0.0567  Accuracy: 9841/10000 (98.41%)\n",
            "\n",
            "Epoch: 15 LR: [0.00048767497911552944]\n",
            "[    0/60000 (  0%)]  Loss: 0.0425\n",
            "[12800/60000 ( 21%)]  Loss: 0.0232\n",
            "[25600/60000 ( 43%)]  Loss: 0.0359\n",
            "[38400/60000 ( 64%)]  Loss: 0.0347\n",
            "[51200/60000 ( 85%)]  Loss: 0.0036\n",
            "\n",
            "Average test loss: 0.0618  Accuracy: 9835/10000 (98.35%)\n",
            "\n",
            "Epoch: 16 LR: [0.00046329123015975297]\n",
            "[    0/60000 (  0%)]  Loss: 0.0054\n",
            "[12800/60000 ( 21%)]  Loss: 0.0046\n",
            "[25600/60000 ( 43%)]  Loss: 0.0130\n",
            "[38400/60000 ( 64%)]  Loss: 0.0013\n",
            "[51200/60000 ( 85%)]  Loss: 0.0102\n",
            "\n",
            "Average test loss: 0.0719  Accuracy: 9834/10000 (98.34%)\n",
            "\n",
            "Epoch: 17 LR: [0.0004401266686517653]\n",
            "[    0/60000 (  0%)]  Loss: 0.0147\n",
            "[12800/60000 ( 21%)]  Loss: 0.0014\n",
            "[25600/60000 ( 43%)]  Loss: 0.0003\n",
            "[38400/60000 ( 64%)]  Loss: 0.0038\n",
            "[51200/60000 ( 85%)]  Loss: 0.0348\n",
            "\n",
            "Average test loss: 0.0620  Accuracy: 9837/10000 (98.37%)\n",
            "\n",
            "Epoch: 18 LR: [0.00041812033521917703]\n",
            "[    0/60000 (  0%)]  Loss: 0.0014\n",
            "[12800/60000 ( 21%)]  Loss: 0.0099\n",
            "[25600/60000 ( 43%)]  Loss: 0.0001\n",
            "[38400/60000 ( 64%)]  Loss: 0.0023\n",
            "[51200/60000 ( 85%)]  Loss: 0.0029\n",
            "\n",
            "Average test loss: 0.0701  Accuracy: 9840/10000 (98.40%)\n",
            "\n",
            "Epoch: 19 LR: [0.00039721431845821814]\n",
            "[    0/60000 (  0%)]  Loss: 0.0036\n",
            "[12800/60000 ( 21%)]  Loss: 0.0001\n",
            "[25600/60000 ( 43%)]  Loss: 0.0136\n",
            "[38400/60000 ( 64%)]  Loss: 0.0060\n",
            "[51200/60000 ( 85%)]  Loss: 0.0005\n",
            "\n",
            "Average test loss: 0.0615  Accuracy: 9844/10000 (98.44%)\n",
            "\n",
            "Epoch: 20 LR: [0.0003773536025353072]\n",
            "[    0/60000 (  0%)]  Loss: 0.0335\n",
            "[12800/60000 ( 21%)]  Loss: 0.0003\n",
            "[25600/60000 ( 43%)]  Loss: 0.0005\n",
            "[38400/60000 ( 64%)]  Loss: 0.0013\n",
            "[51200/60000 ( 85%)]  Loss: 0.0199\n",
            "\n",
            "Average test loss: 0.0810  Accuracy: 9836/10000 (98.36%)\n",
            "\n",
            "Execution time: 383.42 seconds\n",
            "dim 64 depth 12 heads 8 mlp_dim 128\n",
            "Epoch: 1 LR: [0.001]\n",
            "[    0/60000 (  0%)]  Loss: 2.3275\n",
            "[12800/60000 ( 21%)]  Loss: 1.2053\n",
            "[25600/60000 ( 43%)]  Loss: 0.7319\n",
            "[38400/60000 ( 64%)]  Loss: 0.4036\n",
            "[51200/60000 ( 85%)]  Loss: 0.2828\n",
            "\n",
            "Average test loss: 0.2309  Accuracy: 9296/10000 (92.96%)\n",
            "\n",
            "Epoch: 2 LR: [0.00095]\n",
            "[    0/60000 (  0%)]  Loss: 0.2475\n",
            "[12800/60000 ( 21%)]  Loss: 0.2023\n",
            "[25600/60000 ( 43%)]  Loss: 0.1061\n",
            "[38400/60000 ( 64%)]  Loss: 0.1430\n",
            "[51200/60000 ( 85%)]  Loss: 0.1438\n",
            "\n",
            "Average test loss: 0.1231  Accuracy: 9627/10000 (96.27%)\n",
            "\n",
            "Epoch: 3 LR: [0.0009025]\n",
            "[    0/60000 (  0%)]  Loss: 0.0918\n",
            "[12800/60000 ( 21%)]  Loss: 0.0823\n",
            "[25600/60000 ( 43%)]  Loss: 0.1141\n",
            "[38400/60000 ( 64%)]  Loss: 0.0871\n",
            "[51200/60000 ( 85%)]  Loss: 0.0272\n",
            "\n",
            "Average test loss: 0.0878  Accuracy: 9719/10000 (97.19%)\n",
            "\n",
            "Epoch: 4 LR: [0.000857375]\n",
            "[    0/60000 (  0%)]  Loss: 0.0984\n",
            "[12800/60000 ( 21%)]  Loss: 0.1073\n",
            "[25600/60000 ( 43%)]  Loss: 0.1698\n",
            "[38400/60000 ( 64%)]  Loss: 0.0722\n",
            "[51200/60000 ( 85%)]  Loss: 0.0579\n",
            "\n",
            "Average test loss: 0.0848  Accuracy: 9732/10000 (97.32%)\n",
            "\n",
            "Epoch: 5 LR: [0.0008145062499999999]\n",
            "[    0/60000 (  0%)]  Loss: 0.0574\n",
            "[12800/60000 ( 21%)]  Loss: 0.1473\n",
            "[25600/60000 ( 43%)]  Loss: 0.0440\n",
            "[38400/60000 ( 64%)]  Loss: 0.0435\n",
            "[51200/60000 ( 85%)]  Loss: 0.0418\n",
            "\n",
            "Average test loss: 0.0729  Accuracy: 9757/10000 (97.57%)\n",
            "\n",
            "Epoch: 6 LR: [0.0007737809374999998]\n",
            "[    0/60000 (  0%)]  Loss: 0.0849\n",
            "[12800/60000 ( 21%)]  Loss: 0.0449\n",
            "[25600/60000 ( 43%)]  Loss: 0.0558\n",
            "[38400/60000 ( 64%)]  Loss: 0.1116\n",
            "[51200/60000 ( 85%)]  Loss: 0.0154\n"
          ]
        }
      ],
      "source": [
        "skip=True\n",
        "for dim in [32, 64, 128, 256]:\n",
        "    for depth in [4, 6, 12]:\n",
        "        for heads in [4, 8, 16]:\n",
        "            for mlp_dim in [128, 256, 512]:\n",
        "                if dim == 32 and depth == 12 and heads == 4 and mlp_dim == 256:\n",
        "                    skip = False\n",
        "                if skip:\n",
        "                    continue\n",
        "                print(\"dim\", dim, \"depth\", depth, \"heads\", heads,\n",
        "                      \"mlp_dim\", mlp_dim)\n",
        "\n",
        "                # You can change the architecture here\n",
        "                model = ViT(image_size=28, patch_size=7, num_classes=10, channels=1,\n",
        "                            dim=dim, depth=depth, heads=heads, mlp_dim=mlp_dim)\n",
        "                model = model.cuda()\n",
        "                # We also print the network architecture\n",
        "                model\n",
        "\n",
        "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "                train_loss_history, test_loss_history = [], []\n",
        "\n",
        "                N_EPOCHS = 20\n",
        "\n",
        "                train_loader, test_loader = get_mnist_loader(batch_size=128, shuffle=True)\n",
        "\n",
        "                # Gradually reduce the learning rate while training\n",
        "                scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "                start_time = time.time()\n",
        "                for epoch in range(1, N_EPOCHS + 1):\n",
        "                    print('Epoch:', epoch,'LR:', scheduler.get_last_lr())\n",
        "                    train_epoch(model, optimizer, train_loader, train_loss_history)\n",
        "                    evaluate(model, test_loader, test_loss_history)\n",
        "                    scheduler.step()\n",
        "\n",
        "                print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVtBMZiB5LnH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}